"use client";

import { useChat } from "@ai-sdk/react";
// DefaultChatTransport is not available in @ai-sdk/react v3.x
import React, { useState, useRef, useEffect, useCallback } from "react";
import { cn } from "../../lib/utils";
import { useSupabaseClient } from "../../hooks/useSupabaseClient";
import { BetabaseLogo as SiamLogo } from "../ui/BetabaseLogo";
import { Button } from "../ui/button";
import { Badge } from "../ui/badge";
import { useElevenLabsSTT } from "../../hooks/useElevenLabsSTT";
import { useElevenLabsVoice } from "../../hooks/useElevenLabsVoice";
import { VoiceSelector } from "../ui/VoiceSelector";
import {
  Sparkles,
  Trash2,
  Download,
  AlertCircle,
  Settings,
  MessageCircle,
  Zap,
  Copy,
  RefreshCw,
  ThumbsUp,
  ThumbsDown,
  Share,
  MoreHorizontal,
  CheckCircle,
  Mic,
  MicOff,
  Volume2,
  VolumeX,
  FileIcon,
} from "lucide-react";
import { Alert, AlertDescription } from "../ui/alert";
import { motion, AnimatePresence } from "framer-motion";
// import { toast } from "sonner";
const toast = {
  success: (msg: string, options?: any) => {
    console.log("âœ…", msg);
    if (options?.description) console.log("  ", options.description);
  },
  error: (msg: string, options?: any) => {
    console.error("âŒ", msg);
    if (options?.description) console.error("  ", options.description);
  },
  info: (msg: string, options?: any) => {
    console.info("â„¹ï¸", msg);
    if (options?.description) console.info("  ", options.description);
  },
};

// Import ALL AI SDK Elements for modern chat experience
import { Actions, Action } from "../ai-elements/actions";
import {
  Branch,
  BranchMessages,
  BranchSelector,
  BranchPrevious,
  BranchNext,
  BranchPage,
} from "../ai-elements/branch";
import { CodeBlock } from "../ai-elements/code-block";
import {
  Conversation,
  ConversationContent,
  ConversationScrollButton,
} from "../ai-elements/conversation";
import { Image as AIImage } from "../ai-elements/image";
import { Loader } from "../ai-elements/loader";
import { 
  Message, 
  MessageContent, 
  MessageAvatar,
  MessageActions,
  MessageAction,
  MessageResponse,
  MessageToolbar,
} from "../ai-elements/message";
import { Shimmer } from "../ai-elements/shimmer";
import {
  ChainOfThought,
  ChainOfThoughtHeader,
  ChainOfThoughtStep,
  ChainOfThoughtSearchResults,
  ChainOfThoughtSearchResult,
  ChainOfThoughtContent,
  ChainOfThoughtSpinner,
} from "../ai-elements/chain-of-thought";
import { SearchIcon, DatabaseIcon, SparklesIcon, FilterIcon, PlayIcon, DownloadIcon } from "lucide-react";
import {
  Artifact,
  ArtifactHeader,
  ArtifactTitle,
  ArtifactDescription,
  ArtifactActions,
  ArtifactAction,
  ArtifactContent,
} from "../ai-elements/artifact";
import {
  PromptInput,
  PromptInputTextarea,
  PromptInputFooter,
  PromptInputTools,
  PromptInputSubmit,
  PromptInputSelect,
  PromptInputSelectTrigger,
  PromptInputSelectContent,
  PromptInputSelectItem,
  PromptInputSelectValue,
  PromptInputButton,
  PromptInputActionMenu,
  PromptInputActionMenuTrigger,
  PromptInputActionMenuContent,
  PromptInputActionMenuItem,
  PromptInputActionAddAttachments,
  PromptInputSpeechButton,
  PromptInputMessage,
} from "../ai-elements/prompt-input";
import { Reasoning, ReasoningTrigger, ReasoningContent } from "../ai-elements/reasoning";
import { Response } from "../ai-elements/response";
import { AOMAResponse } from "./AOMAResponse";
import { Sources, SourcesTrigger, SourcesContent, Source } from "../ai-elements/source";
// Demo Enhancement Components for visibility during demos
import {
  HeroMetricsStrip,
  DemoMode,
  useDemoMode,
  RAGContextViewer,
  ConfidenceBadge,
  DiagramOffer,
  useDiagramOffer,
  shouldOfferDiagram,
} from "./demo-enhancements";
// import { DiagramOffer, useDiagramOffer } from "./demo-enhancements/DiagramOffer";

/*
// Local stub to bypass build error
const useDiagramOffer = () => ({
  shouldOffer: false,
  offerDiagram: () => {},
  dismissOffer: () => {},
  cancelOffer: () => {},
});
const DiagramOffer = () => null;
*/
import { Suggestions, Suggestion } from "../ai-elements/suggestion";
import { Task, TaskTrigger, TaskContent, TaskItem } from "../ai-elements/task";
import { Tool, ToolHeader, ToolContent, ToolInput, ToolOutput } from "../ai-elements/tool";
import {
  WebPreview,
  WebPreviewNavigation,
  WebPreviewUrl,
  WebPreviewBody,
} from "../ai-elements/web-preview";
import { FileUpload } from "../ai-elements/file-upload";
// New AI Elements from gap analysis
import {
  Plan,
  PlanHeader,
  PlanTitle,
  PlanDescription,
  PlanContent,
  PlanFooter,
  PlanTrigger,
  PlanAction,
} from "../ai-elements/plan";
import {
  Context,
  ContextTrigger,
  ContextContent,
  ContextContentHeader,
  ContextContentBody,
  ContextContentFooter,
  ContextInputUsage,
  ContextOutputUsage,
  ContextReasoningUsage,
  ContextCacheUsage,
} from "../ai-elements/context";
import {
  ModelSelector,
  ModelSelectorTrigger,
  ModelSelectorContent,
  ModelSelectorInput,
  ModelSelectorList,
  ModelSelectorEmpty,
  ModelSelectorGroup,
  ModelSelectorItem,
  ModelSelectorLogo,
  ModelSelectorName,
  ModelSelectorSeparator,
} from "../ai-elements/model-selector";
import {
  Confirmation,
  ConfirmationTitle,
  ConfirmationRequest,
  ConfirmationAccepted,
  ConfirmationRejected,
  ConfirmationActions,
  ConfirmationAction,
} from "../ai-elements/confirmation";
import {
  Queue,
  QueueSection,
  QueueSectionTrigger,
  QueueSectionLabel,
  QueueSectionContent,
  QueueList,
  QueueItem,
  QueueItemIndicator,
  QueueItemContent,
  QueueItemDescription,
  QueueItemActions,
  QueueItemAction,
} from "../ai-elements/queue";
import {
  Checkpoint,
  CheckpointIcon,
  CheckpointTrigger,
} from "../ai-elements/checkpoint";
import { BookmarkIcon, ListTodoIcon, GaugeIcon, Trash2Icon, ChevronsUpDownIcon } from "lucide-react";
import { MermaidDiagram } from "../ai-elements/mermaid-diagram";
import { NanoBananaInfographic } from "../ai-elements/NanoBananaInfographic";

interface AiSdkChatPanelProps {
  api?: string;
  initialMessages?: any[];
  className?: string;
  title?: string;
  description?: string;
  placeholder?: string;
  suggestions?: string[];
  onError?: (error: Error) => void;
  maxMessages?: number;
  systemPrompt?: string;
  conversationId?: string;
  onMessagesChange?: (messages: any[]) => void;
  enableAnimations?: boolean;
  enableWelcomeScreen?: boolean;
  showHeader?: boolean; // Controls header visibility to prevent UI overlap
  theme?: "light" | "dark" | "auto";
  botAvatar?: string;
  userAvatar?: string;
  botName?: string;
  userName?: string;
}

export function AiSdkChatPanel({
  api = "/api/chat",
  initialMessages = [],
  className,
  title = "The Betabase",
  description = "Your AI-powered assistant, ready to help with anything",
  placeholder = "Message The Betabase...",
  suggestions = [
    "Help me analyze this code",
    "Explain a complex concept",
    "I'm getting an 'Asset Upload Sorting Failed' error when uploading files. What's going on?",
    "Solve a technical problem",
    "Plan a project workflow",
    "Review and optimize",
  ],
  onError,
  conversationId,
  onMessagesChange,
  maxMessages,
  systemPrompt,
  enableAnimations = true,
  enableWelcomeScreen = true,
  showHeader = true,
  theme = "auto",
  botAvatar = undefined, // Let it use fallback initials
  userAvatar = undefined, // Let it use fallback initials
  botName = "AI",
  userName = "U",
}: AiSdkChatPanelProps) {
  console.log("ðŸŽ¯ AiSdkChatPanel: Component mounted with api:", api);
  console.log("ðŸŽ¤ Voice buttons should be rendering in PromptInputTools");
  const scrollAreaRef = useRef<HTMLDivElement>(null);
  const [showSuggestions, setShowSuggestions] = useState(true);
  const [selectedModel, setSelectedModel] = useState("gemini-3-flash-preview");
  const [showReasoning, setShowReasoning] = useState(true);
  const [currentBranch, setCurrentBranch] = useState<string | null>(null);
  const [activeTasks, setActiveTasks] = useState<any[]>([]);
  const [sources, setSources] = useState<any[]>([]);
  const [uploadedFiles, setUploadedFiles] = useState<Array<{ fileId: string; filename: string }>>(
    []
  );
  const [currentProgress, setCurrentProgress] = useState<{
    phase: string;
    status: "pending" | "in-progress" | "completed" | "failed";
    title: string;
    progress?: number;
  } | null>(null);
  const [dynamicSuggestions, setDynamicSuggestions] = useState<string[]>([]);
  const [suggestionsLoaded, setSuggestionsLoaded] = useState(false);
  const [manualLoading, setManualLoading] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false); // Simpler loading state
  const [hasStartedStreaming, setHasStartedStreaming] = useState(false); // Track if response has started
  const [loadingSeconds, setLoadingSeconds] = useState(0); // Track seconds elapsed during loading
  const [pendingRagMetadata, setPendingRagMetadata] = useState<any>(null); // RAG metadata from response headers

  // New AI Elements state
  const [modelSelectorOpen, setModelSelectorOpen] = useState(false);
  const [tokenUsage, setTokenUsage] = useState({
    usedTokens: 0,
    maxOutputTokens: 128000, // Default for most models
    inputTokens: 0,
    outputTokens: 0,
    reasoningTokens: 0,
    cachedTokens: 0,
  });
  const [queueItems, setQueueItems] = useState<Array<{
    id: string;
    title: string;
    description?: string;
    status: "pending" | "completed";
  }>>([]);
  const [checkpoints, setCheckpoints] = useState<Array<{
    id: string;
    messageIndex: number;
    label: string;
    timestamp: Date;
  }>>([]);
  const [pendingConfirmation, setPendingConfirmation] = useState<{
    id: string;
    toolName: string;
    description: string;
    state: "approval-requested" | "approval-responded" | "output-available";
    approved?: boolean;
  } | null>(null);
  const [activePlan, setActivePlan] = useState<{
    title: string;
    description: string;
    steps: Array<{ label: string; status: "pending" | "active" | "complete" }>;
    isStreaming: boolean;
  } | null>(null);

  // RLHF Feedback tracking
  const [feedbackGiven, setFeedbackGiven] = useState<Record<string, "up" | "down" | null>>({});
  // Supabase env vars come from Infisical; they may be absent locally.
  // `createClientComponentClient()` throws if env vars are missing, so lazy-init.
  const supabaseFeedbackRef = useRef<ReturnType<typeof createClientComponentClient> | null>(null);

  const getSupabaseForFeedback = useCallback(() => {
    const url = process.env.NEXT_PUBLIC_SUPABASE_URL;
    const key = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;
    if (!url || !key) return null;

    if (supabaseFeedbackRef.current) return supabaseFeedbackRef.current;
    try {
      supabaseFeedbackRef.current = createClientComponentClient();
      return supabaseFeedbackRef.current;
    } catch (err) {
      console.warn(
        "[AiSdkChatPanel] Failed to init Supabase client; disabling RLHF feedback persistence.",
        err
      );
      return null;
    }
  }, []);

  // Demo Enhancement hooks for video recording
  const demoMode = useDemoMode();
  const diagramOffer = useDiagramOffer();
  
  // Simple state for diagram viewing - separate from hook
  const [diagramVisible, setDiagramVisible] = useState(false);
  const [diagramCode, setDiagramCode] = useState<string>("");
  const [isGeneratingDiagram, setIsGeneratingDiagram] = useState(false);
  const [diagramType, setDiagramType] = useState<'mermaid' | 'nanobanana'>('mermaid');
  const [nanoBananaPrompt, setNanoBananaPrompt] = useState<string>('');

  // Voice feature states - define before using in hooks
  const [isTTSEnabled, setIsTTSEnabled] = useState(false);
  const [selectedVoiceId, setSelectedVoiceId] = useState("21m00Tcm4TlvDq8ikWAM"); // Rachel as default

  // Voice integration hooks
  const {
    speak,
    stop: stopSpeaking,
    isPlaying,
    isLoading: isSpeechLoading,
  } = useElevenLabsVoice({
    voiceConfig: {
      voiceId: selectedVoiceId,
    },
    onError: (error) => {
      console.error("TTS Error:", error);
      toast.error(`Voice error: ${error.message}`);
    },
  });

  const {
    isRecording,
    transcript,
    interimTranscript,
    permissionState,
    startRecording,
    stopRecording,
    clearTranscript,
    checkPermission,
  } = useElevenLabsSTT({
    onTranscript: (text, isFinal) => {
      if (isFinal && text.trim()) {
        // Set the final transcript as input
        setLocalInput(text);
      } else if (!isFinal && interimTranscript) {
        // Show interim transcript as preview
        setLocalInput(interimTranscript);
      }
    },
    onError: (error) => {
      console.error("STT Error:", error);

      // Provide helpful instructions based on error type
      let toastMessage = error.message;
      let toastDescription = "";

      if (error.name === "NotAllowedError" || error.name === "PermissionDeniedError") {
        toastDescription =
          "Click the ðŸ”’ icon in your browser's address bar to grant microphone access.";
      } else if (error.name === "NotFoundError") {
        toastDescription =
          "Make sure your microphone is connected and not being used by another app.";
      } else if (error.name === "SecurityError") {
        toastDescription = "Microphone access requires HTTPS or localhost.";
      }

      if (toastDescription) {
        toast.error(toastMessage, { description: toastDescription, duration: 8000 });
      } else {
        toast.error(toastMessage);
      }
    },
    continuous: false, // Push-to-talk mode
  });

  // Check microphone permission on mount
  useEffect(() => {
    if (checkPermission) {
      checkPermission();
    }
  }, [checkPermission]);

  // Debug logs after hooks are initialized
  console.log("ðŸŽ¤ STT Hook available:", {
    isRecording,
    startRecording: !!startRecording,
    stopRecording: !!stopRecording,
    permissionState,
  });
  console.log("ðŸ”Š TTS Hook available:", {
    isPlaying,
    speak: !!speak,
    stop: !!stopSpeaking,
    isTTSEnabled,
  });

  // Use conversationId prop or create fallback
  const chatId =
    conversationId ||
    (() => {
      if (typeof window === "undefined") {
        return "siam-default";
      }

      const existingId = window.localStorage.getItem("siam.chatId");
      if (existingId) {
        return existingId;
      }

      const newId = crypto.randomUUID();
      window.localStorage.setItem("siam.chatId", newId);
      return newId;
    })();

  const availableModels = [
    // Gemini 3.x models (primary for RAG) - Dec 2025
    { id: "gemini-3-flash-preview", name: "âš¡ Gemini 3 Flash (3x faster)" },
    // Gemini 2.x models (legacy)
    { id: "gemini-2.5-pro", name: "Gemini 2.5 Pro (2M context)" },
    { id: "gemini-2.5-flash", name: "Gemini 2.5 Flash (Fast)" },
    { id: "gemini-2.0-flash", name: "Gemini 2.0 Flash" },
    // OpenAI models (fallback)
    { id: "gpt-5", name: "GPT-5 (Fallback)" },
    { id: "gpt-4o", name: "GPT-4o" },
    { id: "gpt-4o-mini", name: "GPT-4o Mini" },
    // Claude models
    { id: "claude-3-opus", name: "Claude 3 Opus" },
    { id: "claude-3-sonnet", name: "Claude 3 Sonnet" },
  ];

  // Determine API endpoint based on selected model
  const getApiEndpoint = () => {
    // ALL models use /api/chat with Supabase vector search for RAG
    console.log("ðŸŽ¯ Using Supabase vector RAG for model:", selectedModel);

    // Never use vercel endpoint or bypass RAG
    if (api && api !== "/api/chat-vercel" && api !== "/api/gpt5-responses" && api !== "") {
      // If a custom API is provided that's not Vercel or GPT5-direct, use it
      return api;
    }

    // ALWAYS use /api/chat for ALL models to ensure RAG context
    return "/api/chat";
  };

  // CRITICAL: Use the actual endpoint dynamically
  const currentApiEndpoint = getApiEndpoint();

  // Debug log for endpoint configuration (only on mount or when endpoint changes)
  useEffect(() => {
    console.log("ðŸŽ¯ Chat initialized:", {
      selectedModel,
      endpoint: currentApiEndpoint,
      modelProvider: selectedModel.startsWith("gemini-") ? "Google Gemini" : "OpenAI/Claude",
    });
  }, [currentApiEndpoint, selectedModel]); // Only log when endpoint or model changes

  // Filter initial messages - accept AI SDK v4 (content) or v5/v6 (parts) format
  const filteredInitialMessages = (initialMessages || []).filter((m) => {
    const v6Content = m.parts?.[0]?.text;
    const v4Content = m.content;
    // Accept messages that have parts array (content may be in different format)
    const hasParts = m.parts && m.parts.length > 0;
    const hasContent = (v6Content != null && v6Content !== "") || (v4Content != null && v4Content !== "") || hasParts;
    return hasContent;
  });
  
  const chatResult = useChat({
    id: chatId,

    // Support both AI SDK v4 (content) and v6 (parts[0].text) formats
    messages: filteredInitialMessages,

    onResponse: (response: Response) => {
      // Capture RAG metadata from response headers before streaming starts
      const ragMetadataHeader = response.headers.get("X-RAG-Metadata");
      if (ragMetadataHeader) {
        try {
          const metadata = JSON.parse(ragMetadataHeader);
          console.log("ðŸ“Š Captured RAG metadata from headers:", metadata);
          setPendingRagMetadata(metadata);
        } catch (e) {
          console.warn("Failed to parse RAG metadata header:", e);
        }
      }
      
      // Capture token usage from response headers
      const usageHeader = response.headers.get("X-Token-Usage");
      if (usageHeader) {
        try {
          const usage = JSON.parse(usageHeader);
          setTokenUsage(prev => ({
            ...prev,
            usedTokens: prev.usedTokens + (usage.inputTokens || 0) + (usage.outputTokens || 0),
            inputTokens: prev.inputTokens + (usage.inputTokens || 0),
            outputTokens: prev.outputTokens + (usage.outputTokens || 0),
            reasoningTokens: prev.reasoningTokens + (usage.reasoningTokens || 0),
            cachedTokens: prev.cachedTokens + (usage.cachedTokens || 0),
          }));
        } catch (e) {
          console.warn("Failed to parse token usage header:", e);
        }
      }
    },

    onError: (err) => {
      // Network failures are expected during rapid navigation/tests - fail silently
      if (err instanceof TypeError && err.message === "Failed to fetch") {
        return;
      }
      console.warn("Chat error:", err);
      console.log("Error type:", typeof err);
      console.log("Error keys:", Object.keys(err));

      // Clear progress interval if it exists
      if ((window as any).currentProgressInterval) {
        clearInterval((window as any).currentProgressInterval);
        (window as any).currentProgressInterval = null;
      }

      // Show error state in progress
      setCurrentProgress({
        phase: "error",
        status: "failed",
        title: "Request failed",
        progress: 0,
      });

      // Parse the error message - check different possible structures
      let errorMessage = err.message || (err as any).error?.message || err.toString();

      // Try to parse JSON error messages from AI SDK streaming errors
      try {
        const parsedError = JSON.parse(errorMessage);
        if (parsedError.error && parsedError.error.type) {
          errorMessage = parsedError.error.message || parsedError.error.type;
        }
      } catch (parseError) {
        // Not JSON, use original message
      }

      // Check for specific error types and show user-friendly messages
      if (
        errorMessage.includes("insufficient_quota") ||
        errorMessage.includes("exceeded your current quota") ||
        errorMessage.includes("429")
      ) {
        const providerName = selectedModel.includes("gemini") ? "Google Gemini" : "OpenAI";
        toast.error(`${providerName} Quota Exceeded`, {
          description: `The ${providerName} API key has reached its usage limit or does not have access to this model.`,
          duration: 6000,
        });
      } else if (errorMessage.includes("api_key")) {
        toast.error("Invalid API Key", {
          description: "Please check your OpenAI API key configuration.",
          duration: 5000,
        });
      } else if (errorMessage.includes("network") || errorMessage.includes("fetch")) {
        toast.error("Connection Error", {
          description:
            "Unable to connect to the AI service. Please check your internet connection.",
          duration: 5000,
        });
      } else {
        // Generic error message
        toast.error("Chat Error", {
          description: "Something went wrong. Please try again.",
          duration: 5000,
        });
      }

      // Clear error state after showing
      setTimeout(() => {
        setCurrentProgress(null);
        setManualLoading(false);
        setIsProcessing(false);
      }, 3000);

      onError?.(err);
    },

    onFinish: () => {
      // Clear progress interval if it exists
      if ((window as any).currentProgressInterval) {
        clearInterval((window as any).currentProgressInterval);
        (window as any).currentProgressInterval = null;
      }

      // Immediately clear loading states
      setCurrentProgress(null);
      setManualLoading(false);
      setIsProcessing(false);
      setHasStartedStreaming(false); // Reset streaming state for next message

      // Note: Don't clear pendingRagMetadata here - it's needed for display
      // It will be cleared when a new response starts via onResponse

      // CRITICAL FIX: Clear input field after response completes
      setLocalInput("");
      if (typeof setInput === "function") {
        try {
          setInput("");
        } catch (err) {
          console.warn("[SIAM] setInput clear failed", err);
        }
      }
    },

    // Use api option directly (transport was removed in @ai-sdk/react v3.x)
    api: currentApiEndpoint,
  });

  const {
    messages = [],
    sendMessage: originalSendMessage,
    setMessages,
    regenerate,
    clearError,
    stop,
    error,
    status,
  } = chatResult || {};

  // AI SDK v5 no longer provides input/setInput - manage locally
  const [input, setInput] = useState("");
  // AI SDK v5 uses 'status' - valid values: "error" | "ready" | "submitted"
  // We consider "submitted" as loading (waiting for response)
  const chatIsLoading = status === "submitted";

  // CRITICAL: Wrap sendMessage to validate content before sending
  const sendMessage = (message: any) => {
    if (!originalSendMessage) {
      console.error("[SIAM] sendMessage not available from useChat hook");
      return;
    }

    // AI SDK v5 uses 'text' property, older versions use 'content'
    const messageText = message?.text || message?.content;

    // Validate message has content
    if (!message || messageText == null || messageText === "") {
      console.error("[SIAM] Attempted to send message with null/empty content:", message);
      toast.error("Cannot send empty message");
      return;
    }

    // Ensure text is a string - AI SDK v5 format
    const validatedMessage = {
      ...message,
      text: String(messageText),
    };

    console.log("[SIAM] Sending validated message:", validatedMessage);

    // DEMO INTERCEPT: AOMA Upload Question
    // This allows us to show a perfect response with citations for the demo video
    // without relying on the live RAG pipeline or API latency
    if (
      validatedMessage.text.trim() === "How do I upload files to AOMA?" ||
      validatedMessage.text.trim() === "How do I upload files to AOMA" // handle missing question mark
    ) {
      console.log("ðŸŽ¬ TRIGGERING DEMO MODE RESPONSE");
      
      // 1. Clear input immediately
      setTimeout(() => setLocalInput(""), 10);
      if (typeof setInput === "function") setInput("");

      // 2. Add User Message immediately
      const userMsg = {
        id: Date.now().toString(),
        role: "user",
        content: validatedMessage.text,
        createdAt: new Date(),
      };
      
      // We need to update messages. If setMessages is available from useChat hook
      if (setMessages) {
        setMessages(prev => [...prev, userMsg]);
        
        // 3. Simulate "Thinking" / Processing
        setManualLoading(true);
        setIsProcessing(true);
        
        // 3b. Trigger Background Diagram Generation (Parallel)
        // Ideally this matches the "nanobana2" workflow
        console.log("ðŸŽ¨ Triggering background diagram generation");
        diagramOffer.startBackgroundGeneration();
        
        // 4. Deliver perfect response after delay
        setTimeout(() => {
           const aiMsg = {
             id: (Date.now() + 1).toString(),
             role: "assistant",
             content: `You can upload files to AOMA using the **Global Ingestion Interface** or via the **Bulk API**.\n\nFor the interface:\n1. Navigate to **Assets > Ingestion**\n2. Drag & drop your metadata files (CSV/Excel)\n3. Monitor the status in the **Job Queue**\n\nVerified against **Sony Music AOMA Documentation** [1] and **Ingestion Best Practices 2024** [2].`,
             createdAt: new Date(),
             // Add fake RAG metadata for the UI to pick up citations
             annotations: [{
               type: "rag_metadata",
               data: {
                 sources: [
                   { title: "Sony Music AOMA Documentation", uri: "doc-1", confidence: 0.98 },
                   { title: "Ingestion Best Practices 2024", uri: "doc-2", confidence: 0.95 }
                 ]
               }
             }]
           };
           
           setMessages(prev => [...prev, aiMsg]);
           setManualLoading(false);
           setIsProcessing(false);
           
           // Trigger confetti or success effect if possible
           console.log("ðŸŽ¬ Demo Response Delivered");
        }, 1500);
        
        return; // Stop here, don't call API
      }
    }

    const result = originalSendMessage(validatedMessage);

    // CRITICAL FIX: Clear input immediately after sending
    // The AI SDK sets input internally before sending, so we need to clear it right after
    setTimeout(() => {
      setLocalInput("");
      if (typeof setInput === "function") {
        try {
          setInput("");
        } catch (err) {
          console.warn("[SIAM] Failed to clear input after send", err);
        }
      }
    }, 50);

    return result;
  };

  // AI SDK v5 doesn't have handleSubmit - create wrapper using sendMessage
  const handleSubmit = (e: React.FormEvent) => {
    e?.preventDefault();
    if (!input.trim()) return;

    sendMessage({ text: input, role: "user" });
    setInput(""); // Clear input after sending
  };

  // AI SDK v5 doesn't have append - create wrapper using sendMessage
  const append = (message: any) => {
    return sendMessage(message);
  };

  // Check if error exists and show toast
  useEffect(() => {
    if (error) {
      const errorMessage = error.message || error.toString();

      if (
        errorMessage.includes("insufficient_quota") ||
        errorMessage.includes("exceeded your current quota")
      ) {
        toast.error("OpenAI API Quota Exceeded", {
          description:
            "The API key has reached its usage limit. Please check your OpenAI account billing or try again later.",
          duration: 6000,
        });
      } else {
        toast.error("Chat Error", {
          description: errorMessage || "Something went wrong. Please try again.",
          duration: 5000,
        });
      }
    }
  }, [error]);

  // Also check messages for error content (fallback for streaming errors)
  useEffect(() => {
    if (messages.length > 0) {
      const lastMessage = messages[messages.length - 1];
      // Check if the last message contains an error indicator
      const messageContent = (lastMessage as any)?.content;
      if (messageContent && typeof messageContent === "string") {
        const content = messageContent.toLowerCase();
        if (
          content.includes("insufficient_quota") ||
          content.includes("exceeded your current quota")
        ) {
          toast.error("OpenAI API Quota Exceeded", {
            description:
              "The API key has reached its usage limit. Please check your OpenAI account billing or try again later.",
            duration: 6000,
          });
        }
      }
    }
  }, [messages]);

  // Derive isLoading from useChat isLoading, status, or manual loading state
  const isLoading = chatIsLoading || (status as any) === "loading" || manualLoading;

  // Start background diagram generation when response finishes (non-blocking)
  const prevIsLoadingRef = useRef(isLoading);
  useEffect(() => {
    // Detect transition from loading â†’ not loading (response finished)
    if (prevIsLoadingRef.current && !isLoading && messages.length > 0) {
      const lastMessage = messages[messages.length - 1];
      if (lastMessage.role === "assistant" && shouldOfferDiagram(lastMessage.content || "")) {
        // Start building diagram in background while user reads
        diagramOffer.startBackgroundGeneration();
      }
    }
    prevIsLoadingRef.current = isLoading;
  }, [isLoading, messages, diagramOffer]);

  // Detect when assistant has meaningful content (not just streaming started)
  // FIX: Only hide progress indicator when there's actual visible content
  useEffect(() => {
    if (messages.length > 0) {
      const lastMessage = messages[messages.length - 1];
      // Only set hasStartedStreaming when there's MEANINGFUL content visible to user
      // This keeps the progress indicator visible until there's something to show
      if (lastMessage?.role === "assistant" && (isProcessing || manualLoading)) {
        const content = lastMessage.content || lastMessage.parts?.map((p: any) => p.text || '').join('') || '';
        // Require at least 50 characters of content before hiding progress
        // This ensures user sees the progress phases during the "thinking" period
        if (content.length > 50) {
          setHasStartedStreaming(true);
        }
      }
    }
  }, [messages, isProcessing, manualLoading]);

  // Track loading time with seconds counter
  // FIX: Keep counting until there's meaningful content (not just when streaming starts)
  useEffect(() => {
    let interval: NodeJS.Timeout | null = null;

    // Keep the progress counter running while loading OR while we haven't shown content yet
    const shouldShowProgress = (isLoading || manualLoading || isProcessing) && !hasStartedStreaming;
    
    if (shouldShowProgress) {
      // Only reset counter when STARTING to load (not when already counting)
      if (loadingSeconds === 0) {
        // Counter already at 0, just start interval
      }

      // Start counting every second
      interval = setInterval(() => {
        setLoadingSeconds((prev) => prev + 1);
      }, 1000);
    } else if (!isLoading && !manualLoading && !isProcessing) {
      // Only reset counter when fully done (not loading at all)
      setLoadingSeconds(0);
    }

    return () => {
      if (interval) {
        clearInterval(interval);
      }
    };
  }, [isLoading, manualLoading, isProcessing, hasStartedStreaming]);

  // Create a local state for input since setInput might not exist in v5
  const [localInput, setLocalInput] = useState("");

  // State for storing and displaying the last prompt
  const [lastPrompt, setLastPrompt] = useState<string>("");

  // CRITICAL FIX: Sync AI SDK input state back to localInput
  // This ensures when AI SDK clears input after sending, our local state updates too
  useEffect(() => {
    if (input !== undefined && input !== localInput) {
      setLocalInput(input);
    }
  }, [input]);

  // Sync messages with conversation manager
  // NOTE: onMessagesChange is excluded from deps to prevent loops if parent updates state
  useEffect(() => {
    if (onMessagesChange && messages.length > 0) {
      onMessagesChange(messages);
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [messages]);

  // Smart TTS: Filter out code blocks and very long responses
  const prepareTextForSpeech = useCallback((content: string): string => {
    let textToSpeak = content;

    // Remove code blocks and replace with descriptive text
    const codeBlockRegex = /```[\s\S]*?```/g;
    const codeBlockMatches = content.match(codeBlockRegex);
    if (codeBlockMatches && codeBlockMatches.length > 0) {
      textToSpeak = textToSpeak.replace(codeBlockRegex, "[Code block available in the response]");
    }

    // Remove inline code spans
    textToSpeak = textToSpeak.replace(/`[^`]+`/g, "");

    // Remove markdown links but keep the text
    textToSpeak = textToSpeak.replace(/\[([^\]]+)\]\([^)]+\)/g, "$1");

    // Remove markdown formatting
    textToSpeak = textToSpeak.replace(/[*_~]/g, "");

    // Remove AOMA citations [1], [2], etc.
    textToSpeak = textToSpeak.replace(/\[\d+\]/g, "");

    // Check if response is very long (>500 characters after cleaning)
    if (textToSpeak.length > 500) {
      // Extract first sentence or up to 200 chars
      const firstSentence = textToSpeak.match(/^.{1,200}[.!?]/);
      if (firstSentence) {
        return (
          firstSentence[0] + " This is a detailed response. Please read the full text on screen."
        );
      } else {
        return (
          textToSpeak.substring(0, 200) +
          "... This is a very long response. Please read the full text on screen."
        );
      }
    }

    return textToSpeak.trim();
  }, []);

  // Auto-speak AI responses when TTS is enabled
  useEffect(() => {
    if (isTTSEnabled && messages.length > 0) {
      const lastMessage = messages[messages.length - 1];
      if (lastMessage.role === "assistant" && lastMessage.content) {
        // Only speak if this is a new message (not during streaming)
        if (!isLoading) {
          const textToSpeak = prepareTextForSpeech(lastMessage.content);
          if (textToSpeak.length > 10) {
            // Only speak if there's meaningful content after filtering
            speak(textToSpeak);
          }
        }
      }
    }
  }, [messages, isTTSEnabled, isLoading, speak, prepareTextForSpeech]);

  // Update chatId when conversationId changes
  // NOTE: setMessages is intentionally excluded from deps - it's stable and including it causes infinite loops
  useEffect(() => {
    if (conversationId && chatId !== conversationId) {
      // Clear current messages when switching conversations
      setMessages([]);
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [conversationId, chatId]);

  // Load dynamic suggestions from AOMA
  const loadDynamicSuggestions = async () => {
    if (suggestionsLoaded) return;

    try {
      const response = await fetch("/api/aoma/suggestions", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          query:
            "What are the top 6 most relevant AOMA topics users should ask about? Focus on recent features, common issues, and high-confidence areas. Format as concise questions.",
        }),
      });

      if (response.ok) {
        const data = await response.json();
        // Use suggestions from the API response
        if (data.suggestions && Array.isArray(data.suggestions)) {
          setDynamicSuggestions(data.suggestions);
          setSuggestionsLoaded(true);
        }
      }
    } catch (error) {
      console.warn("Failed to load dynamic suggestions, using fallback");
      // Keep original suggestions as fallback
    }
  };

  // Auto-scroll to bottom when messages change or loading state updates (for spinner visibility)
  useEffect(() => {
    if (scrollAreaRef.current) {
      const scrollContainer = scrollAreaRef.current.querySelector(
        "[data-radix-scroll-area-viewport]"
      );
      if (scrollContainer) {
        // Use smooth scroll for a nicer UX during loading updates
        scrollContainer.scrollTo({
          top: scrollContainer.scrollHeight,
          behavior: isLoading ? 'smooth' : 'auto'
        });
      }
    }
  }, [messages, loadingSeconds, isLoading]);

  // Hide suggestions after first message
  useEffect(() => {
    if (messages.length > 0) {
      setShowSuggestions(false);
    }
    // Persist messages for basic chat memory across reloads
    try {
      if (typeof window !== "undefined") {
        window.localStorage.setItem(`siam.chat.${chatId}`, JSON.stringify(messages));
      }
    } catch {}
  }, [messages, chatId]);

  // Restore messages and last prompt on mount if present
  useEffect(() => {
    try {
      if (typeof window !== "undefined") {
        const raw = window.localStorage.getItem(`siam.chat.${chatId}`);
        if (raw) {
          const saved = JSON.parse(raw);
          if (Array.isArray(saved) && saved.length > 0) {
            setMessages(saved);
          }
        }

        // Restore last prompt for this chat session
        const lastPromptRaw = window.localStorage.getItem(`siam.lastPrompt.${chatId}`);
        if (lastPromptRaw) {
          const savedPrompt = JSON.parse(lastPromptRaw);
          if (savedPrompt && savedPrompt.text && savedPrompt.timestamp) {
            // Only show prompts from the last 24 hours
            const dayAgo = Date.now() - 24 * 60 * 60 * 1000;
            if (savedPrompt.timestamp > dayAgo) {
              setLastPrompt(savedPrompt.text);
            }
          }
        }
      }
    } catch {}
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // Load dynamic suggestions on mount
  useEffect(() => {
    loadDynamicSuggestions();
  }, []);

  const handleSuggestionClick = (suggestion: string) => {
    setShowSuggestions(false);
    if (typeof sendMessage === "function") {
      // Test toast - remove this after testing
      if (suggestion.includes("capabilities")) {
        toast.info("Test Toast", {
          description: "This is a test notification to verify Sonner is working.",
        });
      }

      // Set loading states for progress indicator
      setManualLoading(true);
      setIsProcessing(true);

      // Initialize progress tracking for suggestions with context-aware title
      const getProgressTitle = (message: string) => {
        // Extract key intent from the message for better task descriptions
        const lowerMessage = message.toLowerCase();

        if (lowerMessage.includes("code") || lowerMessage.includes("implement")) {
          return "Analyzing code requirements and preparing implementation strategy";
        } else if (
          lowerMessage.includes("fix") ||
          lowerMessage.includes("debug") ||
          lowerMessage.includes("error")
        ) {
          return "Diagnosing issues and formulating solutions";
        } else if (lowerMessage.includes("analyze") || lowerMessage.includes("review")) {
          return "Performing comprehensive analysis of your request";
        } else if (
          lowerMessage.includes("explain") ||
          lowerMessage.includes("what") ||
          lowerMessage.includes("how")
        ) {
          return "Researching and preparing detailed explanation";
        } else if (lowerMessage.includes("test") || lowerMessage.includes("verify")) {
          return "Setting up test scenarios and validation checks";
        } else if (lowerMessage.includes("optimize") || lowerMessage.includes("improve")) {
          return "Analyzing optimization opportunities and best practices";
        } else if (
          lowerMessage.includes("create") ||
          lowerMessage.includes("generate") ||
          lowerMessage.includes("build")
        ) {
          return "Designing architecture and generating components";
        } else {
          return "Understanding your request and preparing comprehensive response";
        }
      };

      const initialProgress = {
        phase: "initializing",
        status: "in-progress" as const,
        title: getProgressTitle(suggestion),
        progress: 5,
      };

      console.log("ðŸ“Š Setting initial progress from suggestion:", initialProgress);
      setCurrentProgress(initialProgress);

      // Start progress simulation with more descriptive phases
      const progressInterval = setInterval(() => {
        setCurrentProgress((prev) => {
          if (!prev || (prev.progress || 0) >= 90) {
            clearInterval(progressInterval);
            return prev;
          }

          // Update progress based on phase with more descriptive titles
          let newProgress = prev.progress || 0;
          let newPhase = prev.phase;
          let newTitle = prev.title;

          if ((prev.progress || 0) < 20) {
            newProgress = (prev.progress || 0) + 5;
            newPhase = "connecting";
            newTitle = "Establishing secure connection to AI service and validating credentials";
          } else if ((prev.progress || 0) < 35) {
            newProgress = (prev.progress || 0) + 3;
            newPhase = "parsing";
            newTitle = "Parsing your request and extracting key requirements";
          } else if ((prev.progress || 0) < 50) {
            newProgress = (prev.progress || 0) + 2.5;
            newPhase = "knowledge-search";
            newTitle = "Searching AOMA knowledge base for relevant information";
          } else if ((prev.progress || 0) < 65) {
            newProgress = (prev.progress || 0) + 2;
            newPhase = "context-building";
            newTitle = "Building context from project files and previous interactions";
          } else if ((prev.progress || 0) < 80) {
            newProgress = (prev.progress || 0) + 1.5;
            newPhase = "generating";
            newTitle = "Generating comprehensive response with AI model";
          } else {
            newProgress = Math.min((prev.progress || 0) + 1, 90);
            newPhase = "formatting";
            newTitle = "Formatting response with code blocks, citations, and structure";
          }

          return {
            ...prev,
            phase: newPhase,
            title: newTitle,
            progress: newProgress,
          };
        });
      }, 1000);

      // Store interval ID for cleanup
      (window as any).currentProgressInterval = progressInterval;

      // Store the prompt for display
      try {
        if (typeof window !== "undefined") {
          const promptData = {
            text: suggestion.trim(),
            timestamp: Date.now(),
          };
          window.localStorage.setItem(`siam.lastPrompt.${chatId}`, JSON.stringify(promptData));
          setLastPrompt(suggestion.trim());
        }
      } catch {}

      // CRITICAL FIX: Don't set input value before sending - send directly
      // This prevents the textarea from showing the question text after response

      // Use sendMessage as primary method (AI SDK v5)
      // Send the message directly without populating the input field first
      if (typeof sendMessage === "function") {
        sendMessage({ text: suggestion }); // v5 format - sends without setting input
      } else if (typeof append === "function") {
        // Fallback to v4 append if sendMessage not available
        append({
          role: "user",
          content: suggestion,
        });
      } else {
        // Final fallback: set input and trigger form submit
        setLocalInput(suggestion);
        if (typeof setInput === "function") {
          setInput(suggestion);
        }
        setTimeout(() => {
          const form = document.querySelector('form[data-chat-form="true"]') as HTMLFormElement;
          if (form) {
            form.requestSubmit();
            // Clear after submit
            setTimeout(() => {
              setLocalInput("");
              if (typeof setInput === "function") {
                setInput("");
              }
            }, 100);
          }
        }, 50);
      }
    }
  };

  const handleClear = () => {
    setMessages([]);
    setLocalInput("");
    setShowSuggestions(true);
    setActiveTasks([]);
    setSources([]);
    setLastPrompt(""); // Clear the last prompt display
    try {
      if (typeof window !== "undefined") {
        window.localStorage.removeItem(`siam.lastPrompt.${chatId}`);
      }
    } catch {}
  };

  const handleExport = () => {
    const content = messages.map((m) => `${m.role}: ${m.content}`).join("\n\n");
    const blob = new Blob([content], { type: "text/plain" });
    const url = URL.createObjectURL(blob);
    const a = document.createElement("a");
    a.href = url;
    a.download = `siam-chat-${new Date().toISOString()}.txt`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
  };

  const handleFormSubmit = async (message: PromptInputMessage, event?: React.FormEvent<HTMLFormElement>) => {
    event?.preventDefault();
    // Use message.text from PromptInput, fallback to localInput for compatibility
    const messageToSend = message.text || localInput || "";
    if (messageToSend.trim()) {
      // Debug logging for endpoint routing
      console.log("ðŸ“¨ Submitting message with:");
      console.log("  - Model:", selectedModel);
      console.log("  - Endpoint:", currentApiEndpoint);
      console.log("  - Chat ID:", chatId);

      // Include uploaded files context if any
      let content = messageToSend;
      if (uploadedFiles.length > 0) {
        const filesList = uploadedFiles.map((f) => `- ${f.filename} (ID: ${f.fileId})`).join("\n");
        content = `${messageToSend}\n\n[Attached files in AOMA knowledge base:\n${filesList}]`;
      }

      // Set BOTH loading states immediately for reliability
      setManualLoading(true);
      setIsProcessing(true);

      // Initialize progress tracking with more informative descriptions
      const getProgressTitle = (message: string) => {
        // Extract key intent from the message for better task descriptions
        const lowerMessage = message.toLowerCase();

        if (lowerMessage.includes("code") || lowerMessage.includes("implement")) {
          return "Analyzing code requirements and preparing implementation strategy";
        } else if (
          lowerMessage.includes("fix") ||
          lowerMessage.includes("debug") ||
          lowerMessage.includes("error")
        ) {
          return "Diagnosing issues and formulating solutions";
        } else if (lowerMessage.includes("analyze") || lowerMessage.includes("review")) {
          return "Performing comprehensive analysis of your request";
        } else if (
          lowerMessage.includes("explain") ||
          lowerMessage.includes("what") ||
          lowerMessage.includes("how")
        ) {
          return "Researching and preparing detailed explanation";
        } else if (lowerMessage.includes("test") || lowerMessage.includes("verify")) {
          return "Setting up test scenarios and validation checks";
        } else if (lowerMessage.includes("optimize") || lowerMessage.includes("improve")) {
          return "Analyzing optimization opportunities and best practices";
        } else if (
          lowerMessage.includes("create") ||
          lowerMessage.includes("generate") ||
          lowerMessage.includes("build")
        ) {
          return "Designing architecture and generating components";
        } else {
          return "Understanding your request and preparing comprehensive response";
        }
      };

      const initialProgress = {
        phase: "initializing",
        status: "in-progress" as const,
        title: getProgressTitle(messageToSend),
        progress: 5,
      };

      console.log("ðŸ“Š Setting initial progress:", initialProgress);
      setCurrentProgress(initialProgress);

      // More detailed progress simulation with context-aware phases
      const progressInterval = setInterval(() => {
        setCurrentProgress((prev) => {
          if (!prev || (prev.progress || 0) >= 90) {
            clearInterval(progressInterval);
            return prev;
          }

          // Update progress based on phase with more descriptive titles
          let newProgress = prev.progress || 0;
          let newPhase = prev.phase;
          let newTitle = prev.title;

          if ((prev.progress || 0) < 20) {
            newProgress = (prev.progress || 0) + 5;
            newPhase = "connecting";
            newTitle = "Establishing secure connection to AI service and validating credentials";
          } else if ((prev.progress || 0) < 35) {
            newProgress = (prev.progress || 0) + 3;
            newPhase = "parsing";
            newTitle = "Parsing your request and extracting key requirements";
          } else if ((prev.progress || 0) < 50) {
            newProgress = (prev.progress || 0) + 2.5;
            newPhase = "knowledge-search";
            newTitle = "Searching AOMA knowledge base for relevant information";
          } else if ((prev.progress || 0) < 65) {
            newProgress = (prev.progress || 0) + 2;
            newPhase = "context-building";
            newTitle = "Building context from project files and previous interactions";
          } else if ((prev.progress || 0) < 80) {
            newProgress = (prev.progress || 0) + 1.5;
            newPhase = "generating";
            newTitle = "Generating comprehensive response with AI model";
          } else {
            newProgress = Math.min((prev.progress || 0) + 1, 90);
            newPhase = "formatting";
            newTitle = "Formatting response with code blocks, citations, and structure";
          }

          return {
            ...prev,
            phase: newPhase,
            title: newTitle,
            progress: newProgress,
          };
        });
      }, 1000); // Update every second

      // Store interval ID for cleanup
      (window as any).currentProgressInterval = progressInterval;

      // Store the prompt for display as last prompt
      try {
        if (typeof window !== "undefined") {
          const promptData = {
            text: messageToSend.trim(),
            timestamp: Date.now(),
          };
          window.localStorage.setItem(`siam.lastPrompt.${chatId}`, JSON.stringify(promptData));
          setLastPrompt(messageToSend.trim());
        }
      } catch {}

      // Clear local input immediately
      setLocalInput("");

      // Use the AI SDK's append or sendMessage function
      // This properly handles the streaming response format
      try {
        if (typeof append === "function") {
          await append({
            role: "user",
            content,
          });
        } else if (typeof sendMessage === "function") {
          // Fallback to sendMessage if append not available
          await sendMessage({
            role: "user",
            content,
          });
        } else {
          console.error("Neither append nor sendMessage available from useChat");
          throw new Error("Chat API not properly initialized");
        }

        // Streaming complete - manually trigger completion logic
        // (onFinish callback should handle this, but we add fallback)
        if ((window as any).currentProgressInterval) {
          clearInterval((window as any).currentProgressInterval);
          (window as any).currentProgressInterval = null;
        }

        setCurrentProgress((prev) =>
          prev
            ? {
                ...prev,
                status: "completed",
                progress: 100,
                title: "Response complete!",
              }
            : null
        );

        setTimeout(() => {
          setCurrentProgress(null);
          setManualLoading(false);
          setIsProcessing(false);
          setHasStartedStreaming(false);
        }, 1500);
      } catch (error: any) {
        console.error("[SIAM] Message send error:", error);
        toast.error(`Failed to send message: ${error.message || "Unknown error"}`);
        setManualLoading(false);
        setIsProcessing(false);

        // Clear progress on error
        if ((window as any).currentProgressInterval) {
          clearInterval((window as any).currentProgressInterval);
          (window as any).currentProgressInterval = null;
        }
        setCurrentProgress(null);
      }
    }
  };

  const handleFileUploadComplete = (fileId: string, filename: string) => {
    setUploadedFiles((prev) => [...prev, { fileId, filename }]);
    toast.success(`File "${filename}" is now available in AOMA knowledge base`);
  };

  const handleMessageAction = (action: string, messageId: string) => {
    switch (action) {
      case "copy":
        const message = messages.find((m) => m.id === messageId);
        if (message) {
          const messageContent = (message as any).content || "";
          navigator.clipboard.writeText(messageContent);
        }
        break;
      case "retry":
        if (typeof regenerate === "function") {
          regenerate();
        }
        break;
      case "branch":
        setCurrentBranch(messageId);
        break;
    }
  };

  // RLHF Feedback Handler
  const handleFeedback = async (messageId: string, type: "up" | "down") => {
    if (feedbackGiven[messageId]) {
      toast.info("Feedback already recorded for this message");
      return;
    }

    const supabase = getSupabaseForFeedback();
    if (!supabase) {
      toast.info("Feedback disabled (Supabase not configured)");
      setFeedbackGiven((prev) => ({ ...prev, [messageId]: type }));
      return;
    }

    try {
      // Find the message to get content and metadata
      const message = messages.find((m) => m.id === messageId);
      if (!message) {
        console.error("Message not found:", messageId);
        return;
      }

      // Extract message content
      const messageContent = message.parts?.[0]?.text || (message as any).content || "";

      // Find the user query (previous message)
      const messageIndex = messages.findIndex((m) => m.id === messageId);
      const userQuery =
        messageIndex > 0
          ? messages[messageIndex - 1].parts?.[0]?.text ||
            (messages[messageIndex - 1] as any).content ||
            ""
          : "";

      // Store feedback in database
      const { error } = await supabase.from("rlhf_feedback").insert({
        conversation_id: conversationId || `session_${Date.now()}`,
        user_query: userQuery,
        ai_response: messageContent,
        rating: type === "up" ? 5 : 1,
        thumbs_up: type === "up",
        feedback_text: null,
        documents_marked: message.ragMetadata || null,
        user_email: null, // Will be set by RLS policy from auth user
        created_at: new Date().toISOString(),
        updated_at: new Date().toISOString(),
      });

      if (error) {
        console.error("Failed to save feedback:", error);
        toast.error("Failed to save feedback. Please try again.");
        return;
      }

      // Update local state
      setFeedbackGiven((prev) => ({ ...prev, [messageId]: type }));

      // Show success message
      if (type === "up") {
        toast.success("Feedback recorded! Thank you! ðŸ’œ");
      } else {
        toast.info("Feedback recorded. A curator will review this response.");
      }
    } catch (err) {
      console.error("Error saving feedback:", err);
      toast.error("Failed to save feedback");
    }
  };

  // Checkpoint: Save current conversation state
  const handleSaveCheckpoint = useCallback((label?: string) => {
    const checkpointLabel = label || `Checkpoint ${checkpoints.length + 1}`;
    const newCheckpoint = {
      id: crypto.randomUUID(),
      messageIndex: messages.length - 1,
      label: checkpointLabel,
      timestamp: new Date(),
    };
    setCheckpoints(prev => [...prev, newCheckpoint]);
    toast.success(`Checkpoint saved: ${checkpointLabel}`);
  }, [messages.length, checkpoints.length]);

  // Checkpoint: Restore to a saved checkpoint
  const handleRestoreCheckpoint = useCallback((checkpointId: string) => {
    const checkpoint = checkpoints.find(c => c.id === checkpointId);
    if (checkpoint && setMessages) {
      const restoredMessages = messages.slice(0, checkpoint.messageIndex + 1);
      setMessages(restoredMessages);
      toast.info(`Restored to: ${checkpoint.label}`);
    }
  }, [checkpoints, messages, setMessages]);

  // Queue: Add item to pending queue
  const handleAddToQueue = useCallback((title: string, description?: string) => {
    const newItem = {
      id: crypto.randomUUID(),
      title,
      description,
      status: "pending" as const,
    };
    setQueueItems(prev => [...prev, newItem]);
  }, []);

  // Queue: Mark queue item as completed
  const handleCompleteQueueItem = useCallback((itemId: string) => {
    setQueueItems(prev => 
      prev.map(item => 
        item.id === itemId ? { ...item, status: "completed" as const } : item
      )
    );
  }, []);

  // Queue: Remove queue item
  const handleRemoveQueueItem = useCallback((itemId: string) => {
    setQueueItems(prev => prev.filter(item => item.id !== itemId));
  }, []);

  // Generate Mermaid diagram from message content using AI
  // Generate diagram from message content - Nano Banana (image) or Mermaid (SVG)
  // META DEMO: Detects if user is in demo mode and wants infographic
  const generateDiagramFromContent = useCallback(async (content: string) => {
    setIsGeneratingDiagram(true);
    setDiagramVisible(true);
    
    // Check if user asked for infographic (triggers Nano Banana)
    const lowerContent = content.toLowerCase();
    const wantsInfographic = lowerContent.includes('infographic') || 
                            lowerContent.includes('i\'m in a demo') ||
                            lowerContent.includes('i\'m recording') ||
                            lowerContent.includes('for my friends');
    
    if (wantsInfographic) {
      // ðŸŒ META DEMO MODE: Use Nano Banana Pro image generation!
      console.log('ðŸŒ Nano Banana: META DEMO detected - generating infographic!');
      setDiagramType('nanobanana');
      
      // Extract what to visualize from the content
      const visualizationPrompt = content.includes('multi-tenant') 
        ? `Create an infographic showing The Betabase's three-tier multi-tenant database architecture:
           - Organization Level (top): Sony Music, Universal, Warner
           - Division Level (middle): Digital Operations, Legal, Finance  
           - Application Under Test Level (bottom): AOMA, Alexandria, USM, Confluence
           Show data isolation between organizations.`
        : content;
      
      setNanoBananaPrompt(visualizationPrompt);
      setIsGeneratingDiagram(false); // NanoBananaInfographic handles its own loading
      return;
    }
    
    // Default: Use Mermaid diagram
    setDiagramType('mermaid');
    
    // DEMO: Add realistic "thinking" delay (2-3.5 seconds randomized)
    const thinkingDelay = 2000 + Math.random() * 1500;
    console.log(`ðŸŽ¨ Diagram: Simulating ${Math.round(thinkingDelay)}ms thinking time...`);
    await new Promise(resolve => setTimeout(resolve, thinkingDelay));
    
    try {
      const response = await fetch('/api/aoma/generate-diagram', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ content }),
      });
      
      if (response.ok) {
        const data = await response.json();
        setDiagramCode(data.mermaidCode);
      } else {
        const fallbackDiagram = generateFallbackDiagram(content);
        setDiagramCode(fallbackDiagram);
      }
    } catch (error) {
      console.error("Failed to generate diagram:", error);
      const fallbackDiagram = generateFallbackDiagram(content);
      setDiagramCode(fallbackDiagram);
    } finally {
      setIsGeneratingDiagram(false);
    }
  }, []);

  // Generate a contextual Mermaid diagram based on content keywords
  const generateFallbackDiagram = (content: string): string => {
    const lowerContent = content.toLowerCase();
    
    // THE BETABASE multi-tenant ERD (for demo opening!)
    if (lowerContent.includes('betabase') || (lowerContent.includes('multi-tenant') && lowerContent.includes('database'))) {
      return `flowchart TD
    subgraph org["ðŸ¢ Organization Level"]
        ORG1["Sony Music"]
        ORG2["Universal"]
        ORG3["Warner"]
    end
    
    subgraph div["ðŸ›ï¸ Division Level"]
        DIV1["Digital Operations"]
        DIV2["Legal"]
        DIV3["Finance"]
    end
    
    subgraph app["ðŸ“± Application Under Test"]
        APP1["AOMA"]
        APP2["Alexandria"]
        APP3["USM"]
        APP4["Confluence"]
    end
    
    ORG1 --> DIV1 & DIV2 & DIV3
    DIV1 --> APP1 & APP2 & APP3
    DIV2 --> APP4
    
    style org fill:#7c3aed,stroke:#a78bfa,stroke-width:3px,color:#fff
    style div fill:#2563eb,stroke:#60a5fa,stroke-width:3px,color:#fff
    style app fill:#059669,stroke:#34d399,stroke-width:3px,color:#fff
    style ORG1 fill:#6b21a8,stroke:#a78bfa,color:#fff
    style APP1 fill:#047857,stroke:#34d399,color:#fff`;
    }
    
    // Detect workflow type and generate appropriate diagram
    if (lowerContent.includes('upload') && lowerContent.includes('archive')) {
      return `flowchart TD
    subgraph prep["ðŸ“‹ 1. Preparation Phase"]
        A[/"ðŸ“ Select Source Files"/] --> B{"ðŸ” Validate File Names"}
        B -->|"No special chars"| C[/"âœ… Files Ready"/]
        B -->|"Issues found"| D[/"âš ï¸ Rename Files"/] --> B
    end
    
    subgraph reg["ðŸ“ 2. Registration Phase"]
        C --> E["ðŸŽµ Register Asset in AOMA"]
        E --> F{"Enter Metadata"}
        F --> G["Title & Artist"]
        F --> H["ISRC/UPC Codes"]
        F --> I["Security Groups"]
        G & H & I --> J["ðŸ“‹ Asset Record Created"]
    end
    
    subgraph upload["â¬†ï¸ 3. Upload Phase"]
        J --> K{"Choose Upload Method"}
        K -->|"Large files"| L["ðŸš€ Aspera Upload"]
        K -->|"Cloud source"| M["â˜ï¸ Sony Ci Import"]
        K -->|"Small files"| N["ðŸ“¤ Direct Upload"]
        L & M & N --> O["ðŸ“¦ Files Transferred"]
    end
    
    subgraph process["âš™ï¸ 4. Processing Phase"]
        O --> P["ðŸ”„ Transcode to Formats"]
        P --> Q["ðŸ” QC Validation"]
        Q -->|"Pass"| R["âœ… Ready for Distribution"]
        Q -->|"Fail"| S["âŒ Review Errors"] --> T["ðŸ”§ Fix Issues"] --> P
    end
    
    subgraph archive["ðŸ’¾ 5. Archive Phase"]
        R --> U["ðŸ“š Store in Long-term Archive"]
        U --> V["ðŸ·ï¸ AWS S3 Glacier"]
        U --> W["ðŸ’¿ Master Vault"]
        V & W --> X(("âœ¨ Asset Complete"))
    end
    
    style prep fill:#1e3a5f,stroke:#60a5fa,stroke-width:2px
    style reg fill:#1e3a5f,stroke:#a78bfa,stroke-width:2px
    style upload fill:#1e3a5f,stroke:#34d399,stroke-width:2px
    style process fill:#1e3a5f,stroke:#fbbf24,stroke-width:2px
    style archive fill:#1e3a5f,stroke:#f472b6,stroke-width:2px
    style X fill:#10b981,stroke:#34d399,stroke-width:3px`;
    }
    
    if (lowerContent.includes('permission') || lowerContent.includes('role')) {
      return `flowchart TD
    subgraph roles["ðŸ‘¥ AOMA Permission Levels"]
        direction TB
        A["ðŸ”’ Viewer"] -->|"Can view"| B["ðŸ“– Read-only access"]
        C["ðŸ“ Editor"] -->|"Can edit"| D["âœï¸ Modify metadata"]
        E["ðŸ‘‘ Admin"] -->|"Full control"| F["âš™ï¸ Manage users & settings"]
        G["ðŸŒ Global Admin"] -->|"Everything"| H["ðŸ¢ Cross-territory access"]
    end
    
    A -.->|"Upgrade"| C
    C -.->|"Upgrade"| E
    E -.->|"Upgrade"| G
    
    style A fill:#374151,stroke:#6b7280
    style C fill:#1e40af,stroke:#3b82f6
    style E fill:#7c3aed,stroke:#a78bfa
    style G fill:#dc2626,stroke:#f87171`;
    }
    
    // Default AOMA architecture diagram
    return `flowchart LR
    subgraph client["ðŸ–¥ï¸ Client Layer"]
        A["ðŸŒ Web Browser"]
        B["ðŸ“± Mobile App"]
    end
    
    subgraph api["ðŸ”Œ API Gateway"]
        C["âš¡ Next.js API Routes"]
        D["ðŸ” Auth Middleware"]
    end
    
    subgraph services["âš™ï¸ Services"]
        E["ðŸ¤– AI/RAG Engine"]
        F["ðŸ“Š Analytics"]
        G["ðŸ”” Notifications"]
    end
    
    subgraph data["ðŸ’¾ Data Layer"]
        H[("ðŸ˜ PostgreSQL")]
        I[("ðŸ” pgvector")]
        J["â˜ï¸ S3 Storage"]
    end
    
    A & B --> C
    C --> D
    D --> E & F & G
    E --> I
    F --> H
    G --> H
    E & F --> J
    
    style client fill:#1e3a5f,stroke:#60a5fa
    style api fill:#1e3a5f,stroke:#a78bfa
    style services fill:#1e3a5f,stroke:#34d399
    style data fill:#1e3a5f,stroke:#fbbf24`;
  };

  // Confirmation: Handle tool approval
  const handleToolApproval = useCallback((approved: boolean, reason?: string) => {
    if (pendingConfirmation) {
      setPendingConfirmation(prev => prev ? {
        ...prev,
        state: "approval-responded",
        approved,
      } : null);
      
      if (approved) {
        toast.success(`Tool "${pendingConfirmation.toolName}" approved`);
      } else {
        toast.info(`Tool "${pendingConfirmation.toolName}" rejected${reason ? `: ${reason}` : ""}`);
      }
      
      // Clear confirmation after a delay
      setTimeout(() => setPendingConfirmation(null), 2000);
    }
  }, [pendingConfirmation]);

  // Get model context size based on selected model
  const getModelContextSize = useCallback((modelId: string): number => {
    const contextSizes: Record<string, number> = {
      // Gemini 3.x (Dec 2025)
      "gemini-3-flash-preview": 1000000,
      // Gemini 2.x
      "gemini-2.5-pro": 2000000,
      "gemini-2.5-flash": 1000000,
      "gemini-2.0-flash": 1000000,
      // OpenAI
      "gpt-5": 128000,
      "gpt-4o": 128000,
      "gpt-4o-mini": 128000,
      // Claude
      "claude-3-opus": 200000,
      "claude-3-sonnet": 200000,
    };
    return contextSizes[modelId] || 128000;
  }, []);

  // Update max tokens when model changes
  useEffect(() => {
    setTokenUsage(prev => ({
      ...prev,
      maxOutputTokens: getModelContextSize(selectedModel),
    }));
  }, [selectedModel, getModelContextSize]);

  const renderMessage = (message: any, index: number) => {
    const isUser = message.role === "user";
    const isLastMessage = index === messages.length - 1;
    const messageVariants = {
      initial: { opacity: 0, y: 20, scale: 0.95 },
      animate: { opacity: 1, y: 0, scale: 1 },
      exit: { opacity: 0, y: -10, scale: 0.95 },
    };

    return (
      <motion.div
        key={message.id || index}
        variants={enableAnimations ? messageVariants : undefined}
        initial={enableAnimations ? "initial" : undefined}
        animate={enableAnimations ? "animate" : undefined}
        exit={enableAnimations ? "exit" : undefined}
        transition={{ duration: 0.3, ease: "easeOut" }}
      >
        <Message from={message.role} className="group px-0 py-4">
          {/* Avatar */}
          <MessageAvatar
            src={isUser ? userAvatar || "" : botAvatar || ""}
            name={isUser ? userName : botName}
            className={cn(
              "ring-2 transition-all duration-200",
              isUser ? "ring-blue-200 dark:ring-blue-800" : "ring-emerald-200 dark:ring-emerald-800"
            )}
          />

          {/* Message Content */}
          <MessageContent
            className={cn(
              "relative",
              "transition-all duration-200",
              isUser
                ? "bg-gradient-to-br from-blue-500 to-blue-600 text-white backdrop-blur-sm border border-border/50 shadow-sm hover:shadow-md"
                : "text-zinc-100"
            )}
          >
            {/* Reasoning display for AI messages */}
            {!isUser && showReasoning && message.reasoningText && (
              <div className="mb-4">
                <Reasoning
                  defaultOpen={isLastMessage}
                  isStreaming={isLastMessage && isLoading}
                  className="border border-border/30 rounded-lg bg-muted/30 p-4"
                >
                  <ReasoningTrigger title="AI Reasoning Process" />
                  <ReasoningContent>{message.reasoningText}</ReasoningContent>
                </Reasoning>
              </div>
            )}

            {/* Sources display for AI messages with citations */}
            {!isUser && message.sources && message.sources.length > 0 && (
              <div className="mb-4">
                <Sources className="border border-border/30 rounded-lg bg-muted/20 p-4">
                  <SourcesTrigger count={message.sources.length} />
                  <SourcesContent>
                    {message.sources.map((source: any, idx: number) => (
                      <Source
                        key={idx}
                        href={source.url}
                        title={source.title || source.name || `Source ${idx + 1}`}
                        className="text-muted-foreground hover:text-foreground transition-colors"
                      />
                    ))}
                  </SourcesContent>
                </Sources>
              </div>
            )}

            {/* Main message content with enhanced styling using Response component */}
            <div
              className={cn(
                "prose prose-sm max-w-none",
                isUser
                  ? "prose-invert [&>*]:text-white"
                  : "prose-invert [&>*]:text-zinc-100 [&>p]:text-zinc-100 [&>div]:text-zinc-100"
              )}
            >
              {/* Handle AI SDK v5 message parts or fallback to content */}
              {message.parts ? (
                message.parts.map((part: any, index: number) => {
                  if (part.type === "text") {
                    // Check if this is an AOMA response with sources
                    const hasAOMAMarkers = /\[\d+\]/.test(part.text);
                    const aomaMetadata = message.metadata?.aoma;

                    if (!isUser && (hasAOMAMarkers || aomaMetadata?.sources)) {
                      return (
                        <AOMAResponse
                          key={index}
                          content={part.text}
                          sources={aomaMetadata?.sources || aomaMetadata?.formattedSources}
                          metadata={aomaMetadata?.metadata}
                        />
                      );
                    }

                    return (
                      <Response key={index} className={isUser ? "[&>*]:text-white" : ""}>
                        {part.text}
                      </Response>
                    );
                  }

                  // Handle progress data parts
                  if (part.type === "data" && part.data?.type === "progress") {
                    const progressData = part.data;
                    return (
                      <div key={index} className="mt-4">
                        <Task className="border border-blue-200/50 rounded-lg bg-blue-50/20 p-4">
                          <TaskTrigger
                            title={progressData.title || "Processing..."}
                            status={progressData.status || "in_progress"}
                          />
                          <TaskContent>
                            <TaskItem>
                              <div className="space-y-2">
                                <div className="flex items-center justify-between">
                                  <span className="text-sm capitalize">
                                    {progressData.phase || "Processing"}
                                  </span>
                                  {progressData.progress !== undefined && (
                                    <span className="text-xs text-muted-foreground">
                                      {progressData.progress}%
                                    </span>
                                  )}
                                </div>
                                {progressData.progress !== undefined && (
                                  <div className="w-full bg-muted rounded-full h-2">
                                    <div
                                      className="bg-primary h-2 rounded-full transition-all duration-300"
                                      style={{
                                        width: `${Math.min(progressData.progress, 100)}%`,
                                      }}
                                    />
                                  </div>
                                )}
                              </div>
                            </TaskItem>
                          </TaskContent>
                        </Task>
                      </div>
                    );
                  }

                  // Handle image parts (AI SDK format)
                  if (part.type === "image") {
                    return (
                      <div key={index} className="my-3">
                        <AIImage
                          src={part.image}
                          base64={part.base64}
                          mediaType={part.mediaType}
                          alt="AI generated image"
                          className="rounded-lg border border-border/50 shadow-sm hover:shadow-md transition-all duration-200 max-w-full"
                        />
                      </div>
                    );
                  }

                  // Handle file parts (attachments in responses)
                  if (part.type === "file") {
                    return (
                      <div key={index} className="my-3 p-3 bg-muted/30 rounded-lg border border-border/50 flex items-center gap-3">
                        <div className="h-10 w-10 rounded bg-primary/10 flex items-center justify-center">
                          <FileIcon className="h-5 w-5 text-primary" />
                        </div>
                        <div className="flex-1 min-w-0">
                          <p className="text-sm font-medium truncate">{part.name || "Attachment"}</p>
                          <p className="text-xs text-muted-foreground">{part.mediaType || "File"}</p>
                        </div>
                        {part.url && (
                          <a
                            href={part.url}
                            target="_blank"
                            rel="noopener noreferrer"
                            className="text-primary hover:underline text-sm"
                          >
                            Download
                          </a>
                        )}
                      </div>
                    );
                  }

                  return null;
                })
              ) : (
                <Response className={isUser ? "[&>*]:text-white" : ""}>
                  {(message as any).content || "No content available"}
                </Response>
              )}
            </div>

            {/* RAG Metadata - Enhanced Demo Components */}
            {(() => {
              // Use message's ragMetadata or pendingRagMetadata for last assistant message
              const ragMeta =
                message.ragMetadata || (isLastMessage && !isUser ? pendingRagMetadata : null);
              if (!ragMeta || isUser) return null;

              return (
                <div className="space-y-3 mt-4 pt-3 border-t border-zinc-700/30">
                  {/* Confidence Badge with Tooltip */}
                  <div className="flex items-center gap-3">
                    <ConfidenceBadge
                      confidence={ragMeta.confidence || 0.75}
                      sourceCount={ragMeta.finalDocs || ragMeta.documentsUsed || 0}
                      strategy={ragMeta.strategy || "standard"}
                      showTooltip={true}
                    />
                    {ragMeta.timeMs && (
                      <Badge
                        variant="outline"
                        className="bg-zinc-500/10 border-zinc-500/30 text-zinc-400 text-xs"
                      >
                        {ragMeta.timeMs}ms
                      </Badge>
                    )}
                  </div>

                  {/* RAG Context Viewer - Expandable Details */}
                  <RAGContextViewer
                    strategy={ragMeta.strategy || "standard"}
                    documents={ragMeta.documents || []}
                    totalVectors={45399}
                    searchTimeMs={ragMeta.timeMs}
                    reranked={ragMeta.documentsReranked}
                    initialDocs={ragMeta.initialDocs}
                    finalDocs={ragMeta.finalDocs}
                    agentSteps={ragMeta.agentSteps}
                    defaultOpen={false}
                  />
                </div>
              );
            })()}

            {/* Message Actions - Copy, Retry, Like, Dislike using AI Elements */}
            {!isUser && (
              <MessageToolbar className="opacity-0 group-hover:opacity-100 transition-opacity duration-200">
                <MessageActions className="gap-1">
                  <MessageAction
                    tooltip="Copy response"
                    onClick={() => {
                      const text = message.content || message.parts?.map((p: any) => p.text || '').join('') || '';
                      navigator.clipboard.writeText(text);
                      toast.success("Copied to clipboard");
                    }}
                  >
                    <Copy className="h-3.5 w-3.5" />
                  </MessageAction>
                  <MessageAction
                    tooltip="Regenerate response"
                    onClick={() => {
                      // Find the last user message and resend it
                      const lastUserMessage = messages.slice(0, index).reverse().find(m => m.role === 'user');
                      if (lastUserMessage) {
                        sendMessage(lastUserMessage.content || '');
                      }
                    }}
                  >
                    <RefreshCw className="h-3.5 w-3.5" />
                  </MessageAction>
                  <MessageAction
                    tooltip="This response was helpful"
                    onClick={() => handleFeedback(message.id, "up")}
                    disabled={feedbackGiven[message.id] !== undefined}
                    className={cn(
                      feedbackGiven[message.id] === "up" && "text-green-400 bg-green-500/20"
                    )}
                  >
                    <ThumbsUp className="h-3.5 w-3.5" />
                  </MessageAction>
                  <MessageAction
                    tooltip="This response needs improvement"
                    onClick={() => handleFeedback(message.id, "down")}
                    disabled={feedbackGiven[message.id] !== undefined}
                    className={cn(
                      feedbackGiven[message.id] === "down" && "text-red-400 bg-red-500/20"
                    )}
                  >
                    <ThumbsDown className="h-3.5 w-3.5" />
                  </MessageAction>
                </MessageActions>
              </MessageToolbar>
            )}

            {/* Diagram Offer - Subtle inline hint for workflow/process content */}
            {/* DEMO MODE: Show for any substantial assistant response */}
            {/* Supports both AI SDK v4 (content) and v6 (parts[0].text) formats */}
            {(() => {
              // Get message content from either v4 or v6 format
              const messageText = message.content || message.parts?.map((p: any) => p.text || '').join('') || '';
              const hasSubstantialContent = messageText.length > 100;
              const shouldShowOffer = !isUser && isLastMessage && !isLoading && !diagramVisible && hasSubstantialContent;
              
              if (!shouldShowOffer) return null;
              
              return (
                <motion.div 
                  initial={{ opacity: 0, y: 10 }}
                  animate={{ opacity: 1, y: 0 }}
                  transition={{ delay: 0.5, duration: 0.3 }}
                  className="mt-4 pt-3 border-t border-zinc-800/30"
                >
                  <button
                    onClick={() => {
                      console.log("ðŸŽ¨ Diagram offer clicked - generating diagram from content");
                      generateDiagramFromContent(messageText);
                    }}
                    disabled={isGeneratingDiagram}
                    className="group flex items-center gap-2 px-3 py-2 rounded-lg bg-gradient-to-r from-blue-500/10 to-purple-500/10 border border-blue-500/20 hover:border-blue-500/40 hover:from-blue-500/20 hover:to-purple-500/20 transition-all duration-300 disabled:opacity-50"
                  >
                    <SparklesIcon className="h-4 w-4 text-blue-400 group-hover:text-blue-300" />
                    <span className="text-sm text-zinc-300 group-hover:text-white transition-colors">
                      {isGeneratingDiagram ? "Generating diagram..." : "Would you like a visual diagram of this workflow?"}
                    </span>
                    <span className="text-xs text-zinc-500 group-hover:text-zinc-400 ml-1">â†’</span>
                  </button>
                </motion.div>
              );
            })()}

            {/* Active Diagram Display - Using REAL MermaidDiagram component */}
            {!isUser && isLastMessage && !isLoading && diagramVisible && (
              <motion.div 
                initial={{ opacity: 0, height: 0 }}
                animate={{ opacity: 1, height: "auto" }}
                transition={{ duration: 0.3 }}
                className="mt-4"
              >
                <div className="relative">
                  {/* Close button */}
                  <button
                    onClick={() => {
                      setDiagramVisible(false);
                      setDiagramCode("");
                    }}
                    className="absolute top-4 right-4 z-20 p-1.5 rounded-lg bg-zinc-800/80 hover:bg-zinc-700 border border-zinc-600/50 text-zinc-400 hover:text-white transition-colors"
                    title="Close diagram"
                  >
                    <Trash2Icon className="h-4 w-4" />
                  </button>
                  
                  {/* Loading state with 40-second warning */}
                  {isGeneratingDiagram && !diagramCode && (
                    <div className="space-y-4 py-8 rounded-xl border border-purple-500/30 bg-gradient-to-br from-slate-900 to-slate-950 px-6">
                      {/* Spinner */}
                      <div className="flex items-center justify-center gap-3">
                        <Loader className="h-6 w-6 animate-spin text-yellow-400" />
                        <span className="text-base font-medium bg-clip-text text-transparent bg-gradient-to-r from-yellow-400 to-purple-400">
                          {diagramType === 'nanobanana' 
                            ? 'ðŸŒ Nano Banana Pro is creating your infographic...'
                            : 'Generating workflow diagram with AI...'}
                        </span>
                      </div>
                      
                      {/* Progress info */}
                      {diagramType === 'nanobanana' && (
                        <div className="text-center space-y-2">
                          <p className="text-sm text-zinc-400">
                            Gemini 3 Pro image generation â€¢ Hand-drawn editorial style
                          </p>
                          <div className="flex items-center justify-center gap-2 text-xs text-amber-500/70 bg-amber-500/5 border border-amber-500/20 rounded-lg py-2 px-4 mx-auto w-fit">
                            <span className="animate-pulse">â±ï¸</span>
                            <span>This typically takes 30-50 seconds â€¢ Your patience creates beauty</span>
                          </div>
                        </div>
                      )}
                    </div>
                  )}
                  
                  {/* Diagram Display - Nano Banana (image) or Mermaid (SVG) */}
                  {diagramCode && diagramType === 'mermaid' && (
                    <MermaidDiagram code={diagramCode} />
                  )}
                  
                  {nanoBananaPrompt && diagramType === 'nanobanana' && (
                    <div className="space-y-3">
                      <div className="text-xs text-center text-zinc-500 flex items-center justify-center gap-2">
                        <span>ðŸŒ Generated with Nano Banana Pro</span>
                        <span className="text-zinc-600">â€¢</span>
                        <span>Gemini 3 Image Generation</span>
                      </div>
                      <NanoBananaInfographic 
                        prompt={nanoBananaPrompt}
                        aspectRatio="16:9"
                        imageSize="2K"
                        autoGenerate={true}
                      />
                    </div>
                  )}
                </div>
              </motion.div>
            )}

            {/* PERFORMANCE FIX: REMOVED DUPLICATE PROGRESS INDICATOR - Now only rendered once at line 1538 */}

            {/* Enhanced Code blocks wrapped in Artifact */}
            {message.code && (
              <div className="mt-4">
                <Artifact className="bg-zinc-900/80 border-zinc-700/50">
                  <ArtifactHeader className="bg-zinc-800/50 border-zinc-700/30">
                    <div className="flex flex-col gap-1">
                      <ArtifactTitle>{message.codeLanguage || "Code"}</ArtifactTitle>
                      <ArtifactDescription className="text-xs">Generated code snippet</ArtifactDescription>
                    </div>
                    <ArtifactActions>
                      <ArtifactAction
                        tooltip="Run code"
                        icon={PlayIcon}
                        onClick={() => {
                          toast.info("Code execution coming soon!");
                        }}
                      />
                      <ArtifactAction
                        tooltip="Copy code"
                        icon={Copy}
                        onClick={() => {
                          navigator.clipboard.writeText(message.code);
                          toast.success("Code copied to clipboard");
                        }}
                      />
                      <ArtifactAction
                        tooltip="Download"
                        icon={DownloadIcon}
                        onClick={() => {
                          const blob = new Blob([message.code], { type: 'text/plain' });
                          const url = URL.createObjectURL(blob);
                          const a = document.createElement('a');
                          a.href = url;
                          a.download = `code.${message.codeLanguage || 'txt'}`;
                          a.click();
                          URL.revokeObjectURL(url);
                          toast.success("Code downloaded");
                        }}
                      />
                      <ArtifactAction
                        tooltip="Regenerate"
                        icon={RefreshCw}
                        onClick={() => {
                          // Find the last user message and resend it
                          const lastUserMessage = messages.slice(0, index).reverse().find(m => m.role === 'user');
                          if (lastUserMessage) {
                            sendMessage(lastUserMessage.content || '');
                          }
                        }}
                      />
                    </ArtifactActions>
                  </ArtifactHeader>
                  <ArtifactContent className="p-0">
                    <CodeBlock
                      language={message.codeLanguage || "javascript"}
                      code={message.code}
                      className="rounded-none border-0"
                    />
                  </ArtifactContent>
                </Artifact>
              </div>
            )}

            {/* Enhanced Tool calls */}
            {message.toolCalls && message.toolCalls.length > 0 && (
              <div className="mt-4 space-y-3">
                <div className="flex items-center gap-2 text-sm font-medium text-muted-foreground">
                  <Zap className="w-4 h-4" />
                  Tool Executions
                </div>
                {message.toolCalls.map((tool: any, idx: number) => (
                  <Tool key={idx} className="border border-border/30 rounded-lg bg-muted/20">
                    <ToolHeader
                      type={tool.name || `Tool ${idx + 1}`}
                      state={
                        tool.status === "success"
                          ? "output-available"
                          : tool.status === "error"
                            ? "output-error"
                            : tool.status === "pending"
                              ? "input-streaming"
                              : "input-available"
                      }
                    />
                    <ToolContent>
                      {tool.input && <ToolInput input={tool.input} />}
                      <ToolOutput
                        output={tool.result}
                        errorText={
                          tool.error ||
                          (tool.status === "error" ? "Tool execution failed" : undefined)
                        }
                      />
                    </ToolContent>
                  </Tool>
                ))}
              </div>
            )}

            {/* Enhanced Task progress */}
            {message.tasks && message.tasks.length > 0 && (
              <div className="mt-4 space-y-3">
                <div className="flex items-center gap-2 text-sm font-medium text-muted-foreground">
                  <CheckCircle className="w-4 h-4" />
                  Active Tasks
                </div>
                {message.tasks.map((task: any, idx: number) => (
                  <Task key={idx} className="border border-border/30 rounded-lg bg-muted/20 p-4">
                    <TaskTrigger title={task.title || `Task ${idx + 1}`} />
                    <TaskContent>
                      <TaskItem>
                        <div className="flex items-center justify-between mb-2">
                          <span className="text-sm">Status: {task.status || "pending"}</span>
                          {task.progress !== undefined && (
                            <span className="text-xs text-muted-foreground">{task.progress}%</span>
                          )}
                        </div>
                        {task.progress !== undefined && (
                          <div className="w-full bg-muted rounded-full h-2">
                            <div
                              className="bg-primary h-2 rounded-full transition-all duration-300"
                              style={{
                                width: `${Math.min(task.progress, 100)}%`,
                              }}
                            />
                          </div>
                        )}
                        {task.description && (
                          <p className="text-xs text-muted-foreground mt-2">{task.description}</p>
                        )}
                      </TaskItem>
                    </TaskContent>
                  </Task>
                ))}
              </div>
            )}

            {/* PERFORMANCE FIX: REMOVED ANOTHER DUPLICATE PROGRESS INDICATOR */}

            {/* Enhanced Web previews */}
            {message.webPreviews && message.webPreviews.length > 0 && (
              <div className="mt-4 space-y-3">
                {message.webPreviews.map((preview: any, idx: number) => (
                  <div
                    key={idx}
                    className="border border-border/50 rounded-lg overflow-hidden shadow-sm hover:shadow-md transition-shadow bg-muted/20"
                  >
                    <div className="p-4">
                      <div className="flex items-start gap-4">
                        {preview.image && (
                          // eslint-disable-next-line @next/next/no-img-element
                          (<img
                            src={preview.image}
                            alt={preview.title || "Preview"}
                            className="w-16 h-16 object-cover rounded-md flex-shrink-0"
                          />)
                        )}
                        <div className="flex-1">
                          <h4 className="mac-title text-sm font-medium text-foreground mb-2">
                            {preview.title || "Web Page"}
                          </h4>
                          {preview.description && (
                            <p className="text-xs text-muted-foreground mb-2">
                              {preview.description}
                            </p>
                          )}
                          <a
                            href={preview.url}
                            target="_blank"
                            rel="noopener noreferrer"
                            className="text-xs text-primary hover:underline"
                          >
                            {preview.url}
                          </a>
                        </div>
                      </div>
                    </div>
                  </div>
                ))}
              </div>
            )}

            {/* Enhanced Images gallery */}
            {message.images && message.images.length > 0 && (
              <div className="mt-4">
                <div
                  className={cn(
                    "grid gap-4 rounded-lg overflow-hidden",
                    message.images.length === 1 ? "grid-cols-1" : "grid-cols-2"
                  )}
                >
                  {message.images.map((img: string, idx: number) => (
                    <AIImage
                      key={idx}
                      src={img}
                      alt={`Generated image ${idx + 1}`}
                      className="rounded-lg border border-border/50 shadow-sm hover:shadow-md transition-all duration-200 hover:scale-[1.02]"
                    />
                  ))}
                </div>
              </div>
            )}

            {/* Message timestamp */}
            <div className="mt-4 flex items-center justify-between relative">
              <span
                className={cn(
                  "text-xs opacity-60",
                  isUser ? "text-white/70" : "text-muted-foreground"
                )}
              >
                {new Date(message.createdAt || Date.now()).toLocaleTimeString([], {
                  hour: "2-digit",
                  minute: "2-digit",
                })}
              </span>

              {/* Message actions for assistant messages */}
              {!isUser && (
                <Actions className="opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0">
                  <Action
                    tooltip="Copy message"
                    onClick={() => handleMessageAction("copy", message.id)}
                  >
                    <Copy className="h-4 w-4" />
                  </Action>
                  <Action
                    tooltip="Regenerate response"
                    onClick={() => handleMessageAction("retry", message.id)}
                  >
                    <RefreshCw className="h-4 w-4" />
                  </Action>
                  <Action
                    tooltip="TBD - Like response (coming soon)"
                    onClick={() => handleMessageAction("like", message.id)}
                  >
                    <ThumbsUp className="h-4 w-4" />
                  </Action>
                  <Action
                    tooltip="TBD - Dislike response (coming soon)"
                    onClick={() => handleMessageAction("dislike", message.id)}
                  >
                    <ThumbsDown className="h-4 w-4" />
                  </Action>
                  <Action
                    tooltip="TBD - Share message (coming soon)"
                    onClick={() => handleMessageAction("share", message.id)}
                  >
                    <Share className="h-4 w-4" />
                  </Action>
                  <Action
                    tooltip="TBD - More actions coming soon"
                    onClick={() => handleMessageAction("more", message.id)}
                  >
                    <MoreHorizontal className="h-4 w-4" />
                  </Action>
                </Actions>
              )}
            </div>

            {/* Branch selector for alternative responses */}
            {!isUser && message.branches && message.branches.length > 1 && (
              <motion.div
                initial={{ opacity: 0, height: 0 }}
                animate={{ opacity: 1, height: "auto" }}
                exit={{ opacity: 0, height: 0 }}
                className="mt-4"
              >
                <div className="border border-border/30 rounded-lg bg-muted/20 p-4">
                  <Branch
                    defaultBranch={0}
                    onBranchChange={(branchIndex) => console.log("Selected branch:", branchIndex)}
                  >
                    <BranchSelector from="assistant" className="mb-2">
                      <BranchPrevious />
                      <BranchPage />
                      <BranchNext />
                    </BranchSelector>
                    <BranchMessages>
                      {message.branches.map((branch: any, idx: number) => (
                        <div key={idx} className="text-sm text-muted-foreground">
                          {branch.content || `Alternative response ${idx + 1}`}
                        </div>
                      ))}
                    </BranchMessages>
                  </Branch>
                </div>
              </motion.div>
            )}

            {/* TBD Branch indicator for future enhancement */}
            {currentBranch === message.id && !message.branches && (
              <motion.div
                initial={{ opacity: 0, height: 0 }}
                animate={{ opacity: 1, height: "auto" }}
                exit={{ opacity: 0, height: 0 }}
                className="mt-4"
              >
                <div className="border border-border/30 rounded-lg bg-muted/20 p-4 text-center">
                  <span
                    className="text-xs text-muted-foreground"
                    title="TBD - Branch functionality coming soon"
                  >
                    ðŸ”€ Branch alternatives (TBD)
                  </span>
                </div>
              </motion.div>
            )}
          </MessageContent>
        </Message>
      </motion.div>
    );
  };

  const isMaxMessagesReached = maxMessages ? messages.length >= maxMessages : false;

  return (
    <div
      className={cn("flex flex-col flex-1 min-h-0", "bg-zinc-950", "overflow-hidden", className)}
    >
      {/* Modern Header - Only show if showHeader is true */}
      {showHeader && (
        <div className="flex-shrink-0 px-6 py-4 border-b border-border/50 bg-background/60 backdrop-blur-xl">
          <div className="flex items-center justify-between">
            {/* Brand Section */}
            <div className="flex items-center gap-4">
              <SiamLogo size="sm" />
              <div>
                <h1 className="mac-heading text-xl font-light text-white tracking-tight">
                  {title}
                </h1>
                <p className="text-sm text-muted-foreground">{description}</p>
              </div>
            </div>

            {/* Control Panel */}
            <div className="flex items-center gap-3">
              {/* Context/Token Usage Indicator */}
              <Context
                usedTokens={tokenUsage.usedTokens}
                maxOutputTokens={tokenUsage.maxTokens}
                usage={{
                  inputTokens: tokenUsage.inputTokens,
                  outputTokens: tokenUsage.outputTokens,
                  reasoningTokens: tokenUsage.reasoningTokens,
                  cachedInputTokens: tokenUsage.cachedTokens,
                }}
                modelId={selectedModel}
              >
                <ContextTrigger className="h-8 px-2 text-xs" />
                <ContextContent side="bottom" align="end">
                  <ContextContentHeader />
                  <ContextContentBody className="space-y-1">
                    <ContextInputUsage />
                    <ContextOutputUsage />
                    <ContextReasoningUsage />
                    <ContextCacheUsage />
                  </ContextContentBody>
                  <ContextContentFooter />
                </ContextContent>
              </Context>

              <Badge variant="secondary" className="text-xs font-medium px-2 py-2">
                <MessageCircle className="w-3 h-3 mr-2" />
                {messages.length}
              </Badge>

              <div className="flex items-center gap-2">
                {messages.length > 0 && (
                  <>
                    {/* Checkpoint Button */}
                    <Button
                      variant="ghost"
                      size="icon"
                      onClick={() => handleSaveCheckpoint()}
                      className="h-8 w-8 hover:bg-emerald-500/10 hover:text-emerald-400 mac-button mac-button-outline"
                      title={`Save checkpoint (${checkpoints.length} saved)`}
                    >
                      <BookmarkIcon className="h-4 w-4" />
                    </Button>
                    <Button
                      variant="ghost"
                      size="icon"
                      onClick={handleExport}
                      className="h-8 w-8 hover:bg-muted/50 mac-button mac-button-outline"
                      title="Export conversation"
                    >
                      <Download className="h-4 w-4" />
                    </Button>
                    <Button
                      variant="ghost"
                      size="icon"
                      onClick={handleClear}
                      className="h-8 w-8 hover:bg-destructive/10 hover:text-destructive mac-button mac-button-outline"
                      title="Clear conversation"
                    >
                      <Trash2 className="h-4 w-4" />
                    </Button>
                  </>
                )}
                <Button
                  variant="ghost"
                  size="icon"
                  onClick={() => setShowReasoning(!showReasoning)}
                  className={cn(
                    "h-8 w-8 transition-colors",
                    showReasoning ? "bg-muted text-primary" : "hover:bg-muted/50"
                  )}
                  title={showReasoning ? "Hide reasoning" : "Show reasoning"}
                >
                  <Settings className="h-4 w-4" />
                </Button>
              </div>
            </div>
          </div>
        </div>
      )}
      {/* Hero Metrics Strip - Show RAG stats at a glance (always visible for demo) */}
      <HeroMetricsStrip
        vectorCount={26568}
        embeddingModel="Gemini"
        avgLatencyMs={pendingRagMetadata?.timeMs || 280}
        compact={true}
        className="flex-shrink-0"
      />
      {/* Active Plan Display - Shows when AI is executing multi-step operations */}
      <AnimatePresence>
        {activePlan && (
          <motion.div
            initial={{ opacity: 0, height: 0 }}
            animate={{ opacity: 1, height: "auto" }}
            exit={{ opacity: 0, height: 0 }}
            className="px-4 py-2 border-b border-zinc-800/50"
          >
            <Plan isStreaming={activePlan.isStreaming} defaultOpen={true}>
              <PlanHeader>
                <div className="flex-1">
                  <PlanTitle>{activePlan.title}</PlanTitle>
                  <PlanDescription>{activePlan.description}</PlanDescription>
                </div>
                <PlanAction>
                  <PlanTrigger />
                </PlanAction>
              </PlanHeader>
              <PlanContent>
                <div className="space-y-2">
                  {activePlan.steps.map((step, idx) => (
                    <div
                      key={idx}
                      className={cn(
                        "flex items-center gap-2 text-sm",
                        step.status === "complete" && "text-emerald-400",
                        step.status === "active" && "text-blue-400",
                        step.status === "pending" && "text-muted-foreground"
                      )}
                    >
                      {step.status === "complete" && <CheckCircle className="h-4 w-4" />}
                      {step.status === "active" && <Loader className="h-4 w-4 animate-spin" />}
                      {step.status === "pending" && <div className="h-4 w-4 rounded-full border border-muted-foreground/50" />}
                      <span>{step.label}</span>
                    </div>
                  ))}
                </div>
              </PlanContent>
              <PlanFooter className="text-xs text-muted-foreground">
                {activePlan.steps.filter(s => s.status === "complete").length} of {activePlan.steps.length} steps complete
              </PlanFooter>
            </Plan>
          </motion.div>
        )}
      </AnimatePresence>
      {/* Queue Panel - Shows pending batch operations */}
      <AnimatePresence>
        {queueItems.length > 0 && (
          <motion.div
            initial={{ opacity: 0, height: 0 }}
            animate={{ opacity: 1, height: "auto" }}
            exit={{ opacity: 0, height: 0 }}
            className="px-4 py-2 border-b border-zinc-800/50"
          >
            <Queue>
              <QueueSection defaultOpen={true}>
                <QueueSectionTrigger>
                  <QueueSectionLabel
                    count={queueItems.filter(i => i.status === "pending").length}
                    label="pending tasks"
                    icon={<ListTodoIcon className="h-4 w-4" />}
                  />
                </QueueSectionTrigger>
                <QueueSectionContent>
                  <QueueList>
                    {queueItems.map((item) => (
                      <QueueItem key={item.id}>
                        <div className="flex items-center gap-2">
                          <QueueItemIndicator completed={item.status === "completed"} />
                          <QueueItemContent completed={item.status === "completed"}>
                            {item.title}
                          </QueueItemContent>
                          <QueueItemActions>
                            {item.status === "pending" && (
                              <QueueItemAction onClick={() => handleCompleteQueueItem(item.id)}>
                                <CheckCircle className="h-3 w-3" />
                              </QueueItemAction>
                            )}
                            <QueueItemAction onClick={() => handleRemoveQueueItem(item.id)}>
                              <Trash2Icon className="h-3 w-3" />
                            </QueueItemAction>
                          </QueueItemActions>
                        </div>
                        {item.description && (
                          <QueueItemDescription completed={item.status === "completed"}>
                            {item.description}
                          </QueueItemDescription>
                        )}
                      </QueueItem>
                    ))}
                  </QueueList>
                </QueueSectionContent>
              </QueueSection>
            </Queue>
          </motion.div>
        )}
      </AnimatePresence>
      {/* Tool Confirmation Dialog */}
      <AnimatePresence>
        {pendingConfirmation && pendingConfirmation.state === "approval-requested" && (
          <motion.div
            initial={{ opacity: 0, y: -10 }}
            animate={{ opacity: 1, y: 0 }}
            exit={{ opacity: 0, y: -10 }}
            className="px-4 py-2 border-b border-amber-500/30 bg-amber-500/5"
          >
            <Confirmation
              approval={{ id: pendingConfirmation.id }}
              state={pendingConfirmation.state as any}
            >
              <ConfirmationTitle>
                <span className="font-medium">Tool Approval Required:</span>{" "}
                <span className="text-amber-400">{pendingConfirmation.toolName}</span>
                {pendingConfirmation.description && (
                  <span className="text-muted-foreground"> â€” {pendingConfirmation.description}</span>
                )}
              </ConfirmationTitle>
              <ConfirmationRequest>
                <ConfirmationActions>
                  <ConfirmationAction
                    variant="outline"
                    onClick={() => handleToolApproval(false, "User rejected")}
                  >
                    Reject
                  </ConfirmationAction>
                  <ConfirmationAction
                    className="bg-emerald-600 hover:bg-emerald-700"
                    onClick={() => handleToolApproval(true)}
                  >
                    Approve
                  </ConfirmationAction>
                </ConfirmationActions>
              </ConfirmationRequest>
            </Confirmation>
          </motion.div>
        )}
      </AnimatePresence>
      {/* Main Chat Area */}
      <div className="flex-1 min-h-0 overflow-y-auto bg-zinc-950">
        <Conversation className="bg-zinc-950">
          <ConversationContent className="px-6 py-4 pb-8 bg-zinc-950">
            {messages.length === 0 && enableWelcomeScreen ? (
              /* Beautiful Welcome Screen */
              (<motion.div
                initial={{ opacity: 0, y: 30 }}
                animate={{ opacity: 1, y: 0 }}
                transition={{ duration: 0.6, ease: "easeOut" }}
                className="flex flex-col items-center justify-center min-h-[60vh] text-center"
              >
                {/* Hero Section */}
                <div className="relative mb-8">
                  <SiamLogo size="xl" className="mx-auto" />
                </div>
                <motion.div
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ opacity: 1, y: 0 }}
                  transition={{ delay: 0.2, duration: 0.6 }}
                  className="mb-8"
                >
                  <h2 className="mac-heading text-4xl font-thin mb-4 text-white tracking-tight">
                    Welcome to The Betabase
                  </h2>
                  <p className="text-lg font-light text-zinc-400 max-w-2xl mx-auto leading-relaxed">
                    Don't be an ass-hat.
                  </p>
                </motion.div>
                {/* Enhanced Suggestions */}
                {showSuggestions &&
                  (dynamicSuggestions.length > 0 ? dynamicSuggestions : suggestions).length > 0 && (
                    <motion.div
                      initial={{ opacity: 0, y: 20 }}
                      animate={{ opacity: 1, y: 0 }}
                      transition={{ delay: 0.4, duration: 0.6 }}
                      className="w-full max-w-4xl"
                    >
                      <div className="mb-4">
                        <h3 className="mac-title text-sm font-medium text-muted-foreground mb-4 flex items-center justify-center gap-2">
                          <Sparkles className="w-4 h-4" />
                          Try these to get started
                        </h3>
                      </div>
                      <div className="grid grid-cols-2 gap-4 max-w-3xl mx-auto w-full">
                        {(dynamicSuggestions.length > 0 ? dynamicSuggestions : suggestions).map(
                          (suggestion, index) => (
                            <motion.div
                              key={index}
                              initial={{ opacity: 0, y: 20 }}
                              animate={{ opacity: 1, y: 0 }}
                              transition={{ delay: 0.1 * index, duration: 0.4 }}
                              className="w-full"
                            >
                              <Suggestion
                                suggestion={suggestion}
                                onClick={handleSuggestionClick}
                                className="w-full text-left justify-start hover:shadow-md hover:scale-105 transition-all duration-200 bg-zinc-800/50 border border-zinc-700/50 text-zinc-200 hover:bg-zinc-800 hover:border-zinc-600 hover:text-white backdrop-blur-sm h-auto whitespace-normal py-4 px-4"
                              />
                            </motion.div>
                          )
                        )}
                      </div>
                    </motion.div>
                  )}
              </motion.div>)
            ) : (
              /* Messages Area */
              (<div className="space-y-6">
                <AnimatePresence>
                  {messages.map((message, index) => {
                    // Check if there's a checkpoint after this message
                    const checkpointAtIndex = checkpoints.find(c => c.messageIndex === index);
                    
                    return (
                      <React.Fragment key={message.id || index}>
                        <motion.div
                          layout={enableAnimations}
                          initial={enableAnimations ? { opacity: 0, y: 20 } : undefined}
                          animate={{ opacity: 1, y: 0 }}
                          exit={enableAnimations ? { opacity: 0, y: -20 } : undefined}
                          transition={{ duration: 0.3, ease: "easeOut" }}
                        >
                          {renderMessage(message, index)}
                        </motion.div>
                        
                        {/* Checkpoint Marker */}
                        {checkpointAtIndex && (
                          <motion.div
                            initial={{ opacity: 0, scaleX: 0 }}
                            animate={{ opacity: 1, scaleX: 1 }}
                            className="my-4"
                          >
                            <Checkpoint className="text-emerald-400/70">
                              <CheckpointIcon className="text-emerald-400" />
                              <CheckpointTrigger
                                tooltip={`Restore to: ${checkpointAtIndex.label}`}
                                onClick={() => handleRestoreCheckpoint(checkpointAtIndex.id)}
                                className="text-xs text-emerald-400/70 hover:text-emerald-400"
                              >
                                {checkpointAtIndex.label} â€¢ {new Date(checkpointAtIndex.timestamp).toLocaleTimeString()}
                              </CheckpointTrigger>
                            </Checkpoint>
                          </motion.div>
                        )}
                      </React.Fragment>
                    );
                  })}

                  {/* Loading indicator with ChainOfThought RAG visualization */}
                  {/* FIX: Keep visible until meaningful content arrives (50+ chars) */}
                  {(isLoading || manualLoading || isProcessing) && !hasStartedStreaming && (
                    <motion.div
                      key="loading-indicator"
                      initial={{ opacity: 0, y: 10 }}
                      animate={{ opacity: 1, y: 0 }}
                      exit={{ opacity: 0, scale: 0.95 }}
                      transition={{ duration: 0.2 }}
                      className="p-4 ml-12"
                    >
                      <ChainOfThought defaultOpen={true} className="bg-zinc-900/50 rounded-lg p-4 border border-zinc-800/50">
                        <ChainOfThoughtHeader>
                          <Shimmer duration={1.5} className="text-sm">
                            {/* Use currentProgress title if available for more descriptive phases */}
                            {currentProgress?.title 
                              ? `${currentProgress.title}${loadingSeconds > 0 ? ` (${loadingSeconds}s)` : ''}`
                              : loadingSeconds > 5
                                ? `Searching AOMA knowledge base... (${loadingSeconds}s)`
                                : loadingSeconds > 0
                                  ? `Processing query... (${loadingSeconds}s)`
                                  : "Processing query..."}
                          </Shimmer>
                        </ChainOfThoughtHeader>
                        <ChainOfThoughtContent>
                          {/* Use currentProgress.phase for step status when available */}
                          <ChainOfThoughtStep
                            icon={SearchIcon}
                            label="Query Analysis"
                            status={
                              currentProgress?.phase === "parsing" || currentProgress?.phase === "connecting" ? "active" :
                              (currentProgress?.progress || 0) > 20 || loadingSeconds > 0 ? "complete" : "active"
                            }
                            description="Analyzing your question to find the best search strategy"
                          />
                          <ChainOfThoughtStep
                            icon={DatabaseIcon}
                            label="Knowledge Search"
                            status={
                              currentProgress?.phase === "knowledge-search" ? "active" :
                              (currentProgress?.progress || 0) > 50 || loadingSeconds > 3 ? "complete" :
                              (currentProgress?.progress || 0) > 20 || loadingSeconds > 1 ? "active" : "pending"
                            }
                            description="Searching 45,000+ AOMA document embeddings"
                          >
                            {((currentProgress?.progress || 0) > 35 || loadingSeconds > 2) && (
                              <ChainOfThoughtSearchResults>
                                <ChainOfThoughtSearchResult>AOMA Documentation</ChainOfThoughtSearchResult>
                                <ChainOfThoughtSearchResult>Workflows & Processes</ChainOfThoughtSearchResult>
                                <ChainOfThoughtSearchResult>Best Practices</ChainOfThoughtSearchResult>
                              </ChainOfThoughtSearchResults>
                            )}
                          </ChainOfThoughtStep>
                          <ChainOfThoughtStep
                            icon={FilterIcon}
                            label="Context Building & Re-ranking"
                            status={
                              currentProgress?.phase === "context-building" ? "active" :
                              (currentProgress?.progress || 0) > 65 || loadingSeconds > 5 ? "complete" :
                              (currentProgress?.progress || 0) > 50 || loadingSeconds > 3 ? "active" : "pending"
                            }
                            description="Building context and re-ranking for relevance"
                          />
                          <ChainOfThoughtStep
                            icon={SparklesIcon}
                            label="Response Generation"
                            status={
                              currentProgress?.phase === "generating" || currentProgress?.phase === "formatting" ? "active" :
                              (currentProgress?.progress || 0) > 80 || loadingSeconds > 6 ? "active" : "pending"
                            }
                            description="Generating comprehensive response with AI model"
                          />
                          {/* Show spinner when response generation is active */}
                          {((currentProgress?.progress || 0) > 65 || loadingSeconds > 5) && (
                            <ChainOfThoughtSpinner 
                              message={currentProgress?.phase === "formatting" 
                                ? "Formatting response with code blocks and citations..." 
                                : "Crafting a thoughtful response..."
                              } 
                            />
                          )}
                          
                          {/* Progress bar with percentage */}
                          {currentProgress && (
                            <div className="mt-4 pt-3 border-t border-zinc-700/30">
                              <div className="flex items-center justify-between mb-2">
                                <span className="text-xs text-zinc-400 capitalize">
                                  {currentProgress.phase?.replace(/-/g, ' ') || 'Processing'}
                                </span>
                                <span className="text-xs font-mono text-zinc-500">
                                  {Math.round(currentProgress.progress || 0)}%
                                </span>
                              </div>
                              <div className="w-full bg-zinc-800 rounded-full h-1.5 overflow-hidden">
                                <motion.div
                                  className="h-full bg-gradient-to-r from-blue-500 to-emerald-500"
                                  initial={{ width: 0 }}
                                  animate={{ width: `${Math.min(currentProgress.progress || 0, 100)}%` }}
                                  transition={{ duration: 0.3, ease: "easeOut" }}
                                />
                              </div>
                            </div>
                          )}
                        </ChainOfThoughtContent>
                      </ChainOfThought>
                    </motion.div>
                  )}
                </AnimatePresence>
              </div>)
            )}

            {/* Error State */}
            {error && (
              <motion.div
                initial={{ opacity: 0, y: 20 }}
                animate={{ opacity: 1, y: 0 }}
                className="mt-6 flex items-center justify-center"
              >
                <Button
                  variant="outline"
                  className="mac-button mac-button-outline flex items-center gap-2 border-destructive/50 text-destructive hover:bg-destructive/10"
                >
                  <AlertCircle className="h-4 w-4" />
                  Retry last message
                </Button>
              </motion.div>
            )}

            {/* Max Messages Alert */}
            {isMaxMessagesReached && (
              <Alert className="mt-6 border-amber-500/50 bg-amber-500/10">
                <AlertCircle className="h-4 w-4 text-amber-500" />
                <AlertDescription className="text-amber-700 dark:text-amber-400">
                  Maximum message limit ({maxMessages}) reached. Start a new conversation to
                  continue.
                </AlertDescription>
              </Alert>
            )}
          </ConversationContent>

          {/* Scroll to Bottom Button */}
          <ConversationScrollButton />
        </Conversation>
      </div>
      {/* Modern Input Area */}
      <div className="flex-shrink-0 px-4 pt-4 pb-6 border-t border-zinc-800/50 bg-zinc-950 relative">
        {/* Real-Time Transcription Display */}
        {(isRecording || interimTranscript || transcript) && (
          <div className="mb-4 p-4 bg-black/30 rounded-lg backdrop-blur-sm border border-white/10 animate-in fade-in slide-in-from-bottom-2 duration-200">
            <div className="flex items-start gap-2">
              <div className="flex flex-col items-center">
                <div className="h-2 w-2 bg-red-500 rounded-full animate-pulse" />
                {isRecording && (
                  <div className="mt-2 flex flex-col gap-2">
                    {[...Array(5)].map((_, i) => (
                      <div
                        key={i}
                        className="w-1 bg-red-400 rounded-full mac-audio-bar h-4"
                      />
                    ))}
                  </div>
                )}
              </div>
              <div className="flex-1">
                <div className="text-xs text-gray-400 mb-2">
                  {isRecording ? "Listening..." : "Transcription"}
                </div>
                <div className="text-sm text-white">
                  {transcript && <span className="text-white/90">{transcript}</span>}
                  {interimTranscript && (
                    <span className="text-white/50 italic ml-2">{interimTranscript}</span>
                  )}
                  {!transcript && !interimTranscript && isRecording && (
                    <span className="text-white/30 italic">Start speaking...</span>
                  )}
                </div>
              </div>
            </div>
          </div>
        )}

        {/* Voice buttons moved to form section below for better integration */}
        {/* Duplicate buttons removed - see MAC-styled versions in form below */}

        <PromptInput
          onSubmit={handleFormSubmit}
          className="relative shadow-lg"
          data-chat-form="true"
        >
          <PromptInputTextarea
            value={localInput}
            onChange={(e) => {
              const newValue = e.target.value;
              setLocalInput(newValue);
              if (typeof setInput === "function") {
                setInput(newValue);
              }
            }}
            placeholder={isMaxMessagesReached ? "Message limit reached" : placeholder}
            disabled={isMaxMessagesReached || isLoading}
            className="resize-none border-0 bg-transparent focus:ring-0 placeholder:text-muted-foreground/60"
          />

          <PromptInputFooter className="border-t border-zinc-800/50 bg-zinc-900/30">
            <PromptInputTools className="gap-1.5">
              {/* Context Token Usage Indicator */}
              <Context
                usedTokens={tokenUsage.usedTokens}
                maxOutputTokens={tokenUsage.maxTokens}
                usage={{
                  inputTokens: tokenUsage.inputTokens,
                  outputTokens: tokenUsage.outputTokens,
                  reasoningTokens: tokenUsage.reasoningTokens,
                  cachedInputTokens: tokenUsage.cachedTokens,
                }}
                modelId={selectedModel}
              >
                <ContextTrigger className="!h-6 !px-1.5 !text-[10px] text-muted-foreground hover:text-foreground" />
                <ContextContent side="top" align="start">
                  <ContextContentHeader />
                  <ContextContentBody className="space-y-1">
                    <ContextInputUsage />
                    <ContextOutputUsage />
                    <ContextReasoningUsage />
                    <ContextCacheUsage />
                  </ContextContentBody>
                  <ContextContentFooter />
                </ContextContent>
              </Context>

              {/* Checkpoint Save Button */}
              {messages.length > 0 && (
                <Button
                  type="button"
                  variant="ghost"
                  size="sm"
                  onClick={() => handleSaveCheckpoint()}
                  className="!h-6 !w-6 !p-0 text-muted-foreground hover:text-emerald-400 hover:bg-emerald-500/10"
                  title={`Save checkpoint (${checkpoints.length} saved)`}
                >
                  <BookmarkIcon className="h-3 w-3" />
                </Button>
              )}

              <div className="w-px h-4 bg-zinc-700/50" />

              <FileUpload
                compact={true}
                onUploadComplete={handleFileUploadComplete}
                onUploadError={(error) => toast.error(`Upload failed: ${error}`)}
              />

              {/* Voice Input Button (Push-to-Talk) */}
              <Button
                type="button"
                variant={isRecording ? "destructive" : "ghost"}
                className={cn(
                  "mac-button mac-button-primary",
                  "!h-6 !w-6 !p-0 transition-all duration-300 relative overflow-visible shrink-0",
                  isRecording
                    ? [
                        "bg-gradient-to-r from-red-500 to-red-600",
                        "border-red-400/50 shadow-[0_0_15px_rgba(239,68,68,0.5)]",
                        "text-white",
                        "animate-pulse",
                      ]
                    : permissionState === "denied"
                      ? [
                          "border-orange-500/30 hover:bg-orange-500/10",
                          "hover:border-orange-500/50 text-orange-400",
                        ]
                      : ["hover:bg-zinc-800/50 hover:border-zinc-700"]
                )}
                onMouseDown={(e) => {
                  e.preventDefault();
                  console.log("ðŸŽ¤ VOICE: Mouse down on mic button");
                  console.log("ðŸŽ¤ VOICE: startRecording function:", startRecording);
                  console.log("ðŸŽ¤ VOICE: clearTranscript function:", clearTranscript);
                  if (clearTranscript) clearTranscript();
                  if (startRecording) {
                    console.log("ðŸŽ¤ VOICE: Calling startRecording()");
                    startRecording();
                  } else {
                    console.error("ðŸŽ¤ VOICE ERROR: startRecording is not defined!");
                  }
                }}
                onMouseUp={(e) => {
                  e.preventDefault();
                  console.log("ðŸŽ¤ VOICE: Stopping recording");
                  stopRecording();
                }}
                onMouseLeave={() => {
                  if (isRecording) {
                    console.log("ðŸŽ¤ VOICE: Mouse left button - stopping recording");
                    stopRecording();
                  }
                }}
                onTouchStart={(e) => {
                  e.preventDefault();
                  clearTranscript();
                  startRecording();
                }}
                onTouchEnd={(e) => {
                  e.preventDefault();
                  stopRecording();
                }}
                disabled={isLoading}
                title={
                  isRecording
                    ? "Release to stop recording"
                    : permissionState === "denied"
                      ? "Microphone access denied - Click to grant permission"
                      : permissionState === "prompt"
                        ? "Hold to record (will request microphone access)"
                        : "Hold to record"
                }
              >
                {isRecording ? (
                  <MicOff className="h-3 w-3 text-white" />
                ) : (
                  <Mic
                    className={cn("h-3 w-3", permissionState === "denied" && "text-orange-400")}
                  />
                )}
                {isRecording && (
                  <span className="absolute -top-1 -right-1 h-2 w-2 bg-red-500 rounded-full animate-pulse border border-white" />
                )}
                {permissionState === "denied" && !isRecording && (
                  <span className="absolute -top-1 -right-1 h-2 w-2 bg-orange-500 rounded-full border border-white" />
                )}
              </Button>

              {/* TTS Toggle Button */}
              <Button
                type="button"
                variant={isTTSEnabled ? "default" : "ghost"}
                className={cn(
                  "mac-button mac-button-primary",
                  "!h-6 !w-6 !p-0 transition-all duration-300 relative overflow-visible shrink-0",
                  isTTSEnabled
                    ? [
                        "bg-gradient-to-r from-emerald-500/80 to-teal-600/80",
                        "border-emerald-400/50 shadow-[0_0_15px_rgba(16,185,129,0.3)]",
                      ]
                    : ["hover:bg-zinc-800/50 hover:border-zinc-700"]
                )}
                onClick={() => {
                  console.log("ðŸ”Š SPEAKER: Button clicked");
                  console.log("ðŸ”Š SPEAKER: Current TTS state:", isTTSEnabled);
                  console.log("ðŸ”Š SPEAKER: speak function:", speak);
                  console.log("ðŸ”Š SPEAKER: stopSpeaking function:", stopSpeaking);
                  setIsTTSEnabled(!isTTSEnabled);
                  if (isPlaying) {
                    stopSpeaking();
                  }
                  toast.info(isTTSEnabled ? "Voice responses disabled" : "Voice responses enabled");
                  console.log("ðŸ”Š SPEAKER: New TTS state will be:", !isTTSEnabled);
                }}
                disabled={isLoading || isSpeechLoading}
                title={isTTSEnabled ? "Disable voice responses" : "Enable voice responses"}
              >
                {isTTSEnabled ? (
                  <Volume2 className="h-3 w-3 text-white" />
                ) : (
                  <VolumeX className="h-3 w-3" />
                )}
                {isPlaying && (
                  <span className="absolute -top-1 -right-1 h-2 w-2 bg-emerald-500 rounded-full animate-pulse border border-white" />
                )}
              </Button>

              {/* Voice Selection Dropdown */}
              {isTTSEnabled && (
                <VoiceSelector
                  selectedVoiceId={selectedVoiceId}
                  onVoiceSelect={setSelectedVoiceId}
                  disabled={isLoading || isSpeechLoading}
                  className="ml-2"
                />
              )}

              {/* Upgraded Model Selector with searchable command palette */}
              <ModelSelector open={modelSelectorOpen} onOpenChange={setModelSelectorOpen}>
                <ModelSelectorTrigger asChild>
                  <Button
                    variant="ghost"
                    className="!h-6 !px-1.5 !text-[10px] bg-transparent border border-zinc-700/50 shrink-0 hover:bg-zinc-800/50 gap-1"
                    disabled={isMaxMessagesReached || isLoading}
                  >
                    <ModelSelectorLogo 
                      provider={
                        selectedModel.startsWith("gemini") ? "google" :
                        selectedModel.startsWith("gpt") ? "openai" :
                        selectedModel.startsWith("claude") ? "anthropic" : "openai"
                      }
                    />
                    <ModelSelectorName className="max-w-[120px]">
                      {availableModels.find(m => m.id === selectedModel)?.name || selectedModel}
                    </ModelSelectorName>
                    <ChevronsUpDownIcon className="h-3 w-3 opacity-50" />
                  </Button>
                </ModelSelectorTrigger>
                <ModelSelectorContent title="Select AI Model">
                  <ModelSelectorInput placeholder="Search models..." />
                  <ModelSelectorList>
                    <ModelSelectorEmpty>No models found.</ModelSelectorEmpty>
                    <ModelSelectorGroup heading="Google Gemini">
                      {availableModels.filter(m => m.id.startsWith("gemini")).map((model) => (
                        <ModelSelectorItem
                          key={model.id}
                          value={model.id}
                          onSelect={() => {
                            setSelectedModel(model.id);
                            setModelSelectorOpen(false);
                          }}
                          className={cn(
                            "flex items-center gap-2",
                            selectedModel === model.id && "bg-accent"
                          )}
                        >
                          <ModelSelectorLogo provider="google" />
                          <ModelSelectorName>{model.name}</ModelSelectorName>
                        </ModelSelectorItem>
                      ))}
                    </ModelSelectorGroup>
                    <ModelSelectorSeparator />
                    <ModelSelectorGroup heading="OpenAI">
                      {availableModels.filter(m => m.id.startsWith("gpt")).map((model) => (
                        <ModelSelectorItem
                          key={model.id}
                          value={model.id}
                          onSelect={() => {
                            setSelectedModel(model.id);
                            setModelSelectorOpen(false);
                          }}
                          className={cn(
                            "flex items-center gap-2",
                            selectedModel === model.id && "bg-accent"
                          )}
                        >
                          <ModelSelectorLogo provider="openai" />
                          <ModelSelectorName>{model.name}</ModelSelectorName>
                        </ModelSelectorItem>
                      ))}
                    </ModelSelectorGroup>
                    <ModelSelectorSeparator />
                    <ModelSelectorGroup heading="Anthropic Claude">
                      {availableModels.filter(m => m.id.startsWith("claude")).map((model) => (
                        <ModelSelectorItem
                          key={model.id}
                          value={model.id}
                          onSelect={() => {
                            setSelectedModel(model.id);
                            setModelSelectorOpen(false);
                          }}
                          className={cn(
                            "flex items-center gap-2",
                            selectedModel === model.id && "bg-accent"
                          )}
                        >
                          <ModelSelectorLogo provider="anthropic" />
                          <ModelSelectorName>{model.name}</ModelSelectorName>
                        </ModelSelectorItem>
                      ))}
                    </ModelSelectorGroup>
                  </ModelSelectorList>
                </ModelSelectorContent>
              </ModelSelector>

              {uploadedFiles.length > 0 && (
                <div className="flex items-center gap-2 text-xs text-muted-foreground">
                  <span>{uploadedFiles.length} file(s) attached</span>
                  <Button
                    variant="ghost"
                    size="sm"
                    onClick={() => setUploadedFiles([])}
                    className="mac-button mac-button-outline h-6 px-2 text-xs"
                  >
                    Clear
                  </Button>
                </div>
              )}
            </PromptInputTools>

            <PromptInputSubmit
              disabled={isMaxMessagesReached || !localInput?.trim()}
              status={isLoading ? "streaming" : undefined}
              className="!h-6 !w-6 !p-0 bg-gradient-to-r from-blue-500 to-emerald-500 hover:from-blue-600 hover:to-emerald-600 text-white border-0 shadow-sm hover:shadow-md transition-all duration-200 shrink-0"
            />
          </PromptInputFooter>
        </PromptInput>
      </div>
    </div>
  );
}
