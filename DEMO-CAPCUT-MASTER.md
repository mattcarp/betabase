# THREE-PILLAR DEMO - MASTER BULLETS
**CapCut Recording + Gemini Slides | 5:30 Total**

---

## ğŸ¯ STRUCTURE

1. **Multi-Tenant ERD** (Opening emphasis)
2. **Pillar 1: Chat** (RAG - 45,399 vectors)
3. **Pillar 2: Curate** (RLHF feedback loop)
4. **Pillar 3: Test** (Self-healing, 94% success)

---

## ğŸ“¹ SHOT 1: OPENING - Multi-Tenant ERD (0:00-0:45) ğŸŒ META DEMO

### Action (THE META MOMENT!)
1. Type: "Explain The Betabase's multi-tenant database architecture"
2. AI answers with text explanation
3. **Then you say:** "I'm recording a demo - can you create an infographic of that? Hand-drawn style, show the three tiers."
4. **NANO BANANA GENERATES IN REAL-TIME** (~3-5 seconds with spinner)
5. Beautiful hand-drawn ERD appears!
6. **You narrate:** "And THAT is the system creating its own demo slides while I'm demoing it. Meta, right?"

### What You'll Actually Say (Natural):
> "Okay, and I'm running a demo now. So for my friends, can you make an infographic of how the ERD works for the multi-tenant architecture of this system itself? Thanks!"

**(The system already knows the style from the template - you don't need to specify colors/aesthetic!)**

### Bullets (What to SAY while it generates)
- **THE BETABASE** = Our QA testing platform
- **AOMA** = One example AUT (Application Under Test)
- Three-tier isolation: ANY organization can use our platform
- Watch this - the system is making its OWN demo slide right now!
- This is Gemini 3 Pro image generation - hand-drawn infographics on demand

### Gemini Slide Prompt
```
Create a hand-drawn style infographic showing a three-tier hierarchy:
- Top tier: "Organization" (Sony Music)
- Middle tier: "Division" (Digital Ops, Legal, Finance)
- Bottom tier: "Apps Under Test" (AOMA, Alexandria)
Use connecting lines and annotations. Professional but approachable style.
```

---

## ğŸ“¹ SHOT 2: PILLAR 1 - CHAT (0:30-2:00)

### Query 1: Baseline
- Type: "What are the steps to link a product to a master in AOMA?"
- Show streaming response
- Point to inline citations

### Query 2: AOMA Workflow Diagram (â­ SHOWSTOPPER)
- **Type this exact question**: 
  ```
  How do I upload and archive digital assets in AOMA from preparation to storage?
  ```
- AI responds with detailed workflow explanation
- **Wait for subtle prompt**: "Would you like a visual diagram of this workflow?"
- **Click the prompt** â†’ 30-50 second Nano Banana generation (progress indicator)
- **Beautiful hand-drawn workflow diagram appears**:
  - ğŸ“‹ Preparation Phase (file selection, validation)
  - ğŸ“ Registration Phase (metadata, ISRC codes)
  - â¬†ï¸ Upload Phase (Aspera, Sony Ci, direct)
  - âš™ï¸ Processing Phase (transcode, QC)
  - ğŸ’¾ Archive Phase (S3 Glacier, Master Vault)
- Zoom/pan to show interactivity
- Download button works!

> **Technical Note**: Diagram is stored in `ai-sdk-chat-panel.tsx` function `generateFallbackDiagram()`. Triggers when response contains "upload" AND "archive".

### Bullets
- 45,399 AOMA domain vectors
- Inline source citations
- **Nano Banana diagram generation** - Beautiful hand-drawn visuals (NEW!)
- All queries scoped to app_under_test='aoma'
- **Intent Classification** - Smart source routing (NEW!)

> **Note**: Mermaid diagrams in this doc are for reference only - the actual system generates hand-drawn Nano Banana images.

### CapCut Overlays
- "45,399 vectors" badge
- Circle citations when hovering
- "Diagram generated" text
- "Intent: [jira, knowledge]" badge (when visible in logs)

### Gemini Slide Prompt
```
Create an infographic showing the Chat pillar with these elements:
- Large search icon in center
- "45,399 vectors" callout
- "Inline citations" feature bubble
- "Nano Banana diagrams" feature bubble
Use purple/blue color scheme, modern tech aesthetic.
```

### AOMA Upload Workflow Diagram (Reference)

This shows the **concept** that Nano Banana will visualize when you ask the upload/archive question.  
Nano Banana creates a beautiful hand-drawn version of this flow:

```mermaid
flowchart TD
    subgraph prep["ğŸ“‹ 1. Preparation Phase"]
        A[/"ğŸ“ Select Source Files"/] --> B{"ğŸ” Validate File Names"}
        B -->|"No special chars"| C[/"âœ… Files Ready"/]
        B -->|"Issues found"| D[/"âš ï¸ Rename Files"/] --> B
    end
    
    subgraph reg["ğŸ“ 2. Registration Phase"]
        C --> E["ğŸµ Register Asset in AOMA"]
        E --> F{"Enter Metadata"}
        F --> G["Title & Artist"]
        F --> H["ISRC/UPC Codes"]
        F --> I["Security Groups"]
        G & H & I --> J["ğŸ“‹ Asset Record Created"]
    end
    
    subgraph upload["â¬†ï¸ 3. Upload Phase"]
        J --> K{"Choose Upload Method"}
        K -->|"Large files"| L["ğŸš€ Aspera Upload"]
        K -->|"Cloud source"| M["â˜ï¸ Sony Ci Import"]
        K -->|"Small files"| N["ğŸ“¤ Direct Upload"]
        L & M & N --> O["ğŸ“¦ Files Transferred"]
    end
    
    subgraph process["âš™ï¸ 4. Processing Phase"]
        O --> P["ğŸ”„ Transcode to Formats"]
        P --> Q["ğŸ” QC Validation"]
        Q -->|"Pass"| R["âœ… Ready for Distribution"]
        Q -->|"Fail"| S["âŒ Review Errors"] --> T["ğŸ”§ Fix Issues"] --> P
    end
    
    subgraph archive["ğŸ’¾ 5. Archive Phase"]
        R --> U["ğŸ“š Store in Long-term Archive"]
        U --> V["ğŸ·ï¸ AWS S3 Glacier"]
        U --> W["ğŸ’¿ Master Vault"]
        V & W --> X(("âœ¨ Asset Complete"))
    end
```

> **Note**: This Mermaid diagram is for documentation reference. Nano Banana will generate a beautiful hand-drawn version of this workflow automatically.

---

## ğŸ“¹ SHOT 3: PILLAR 2 - CURATE (2:00-3:30)

### Action Sequence
1. Click "Curate" button in header
2. Show feedback queue (if populated)
3. Demo thumbs up/down on response
4. Show star rating (1-5)
5. Submit feedback â†’ success toast
6. Show accuracy chart updating

### Bullets
- Human experts curate AI quality
- Thumbs up/down + star ratings
- Feedback queue for review
- Corrections improve embeddings
- This is the RLHF loop
- Domain expertise scales

### CapCut Overlays
- "RLHF Feedback Loop" title
- Green checkmark on submit
- Arrow showing chart update

### Gemini Slide Prompt
```
Create a cyclical diagram showing the RLHF feedback loop:
1. "AI Response" â†’ 2. "Human Feedback" â†’ 3. "Embedding Re-weight" â†’ 4. "Better Retrieval" â†’ back to 1
Use circular arrows, hand-drawn style, with icons for each step.
```

### ğŸ”„ Deduplication Flow (Mermaid)

The Curate pillar includes intelligent deduplication to keep the knowledge base clean:

```mermaid
flowchart TD
    A[New Document] --> B{1. Source ID Check}
    B -->|"Found"| DUP[Duplicate - Skip/Update]
    B -->|"Not found"| C{2. Content Hash}
    C -->|"Match"| DUP
    C -->|"Not found"| D{3. URL Normalization}
    D -->|"Same URL"| DUP
    D -->|"Not found"| E{4. Semantic Similarity}
    E -->|"â‰¥85% Similar"| DUP
    E -->|"<85%"| F[âœ… INSERT NEW DOCUMENT]
    
    style A fill:#4CAF50,color:white
    style DUP fill:#f44336,color:white
    style F fill:#2196F3,color:white
    style B fill:#9C27B0,color:white
    style C fill:#9C27B0,color:white
    style D fill:#9C27B0,color:white
    style E fill:#9C27B0,color:white
```

**Deduplication Layers:**
- **Layer 1: Source ID** - Fastest check (unique identifier)
- **Layer 2: Content Hash** - MD5/SHA-256 exact match
- **Layer 3: URL Normalization** - Pattern matching for URLs
- **Layer 4: Semantic Similarity** - Embedding cosine similarity (85% threshold)

---

## ğŸ“¹ SHOT 4: PILLAR 3 - TEST (3:30-5:00) â­ SELF-HEALING

**ğŸ“‹ FULL SCRIPT**: See `DEMO-SELF-HEALING-SCRIPT.md` for complete step-by-step walkthrough

### Action Sequence
1. Click "Test" button in header
2. Show **Home Dashboard** stats:
   - Pass Rate: 80.4%
   - 12 tests auto-healed today
   - 5 pending human review
   - **MESSAGE**: "AI saved us 3 hours today"

3. Click **"Review Self-Heals"** button
4. Show self-healing queue (9 attempts visible)
5. **Tier 1 Example** (Upload Flow - 97% confidence):
   - Auto-approved instantly
   - Fixed 3 similar tests automatically
   - **MESSAGE**: "AI handles simple changes"

6. **Tier 2 Example** â­ **EXECUTIVE FAVORITE**:
   - Dashboard Project Card (84% confidence)
   - Status: "Pending Review"
   - **AI asks for human approval**
   - Show approve/reject buttons
   - Click "Approve & Apply Fix"
   - **MESSAGE**: "AI knows when it needs human judgment"

7. **Tier 3 Example** (Search Debounce - 62% confidence):
   - Low confidence - escalated to architect
   - Complex async/timing issue
   - **MESSAGE**: "AI knows when it's out of its depth"

8. Show **ROI Metrics**:
   - 94.2% success rate
   - 15 hours/week saved
   - **MESSAGE**: "QA engineers become architects, not maintainers"

### Bullets
- **9 healing attempts** (live data)
- **Three-tier system**: Auto / Human Review / Architect
- **94% auto-healed** by AI
- **AI asks for help** when uncertain (Tier 2-3)
- **80% reduction** in test maintenance
- **15 hrs/week saved** per QA engineer

### CapCut Overlays
- Stats appearing one by one
- "94.2% Success" highlight
- Color-code tiers (green/yellow/red)
- Before/after arrows on code diff

### Gemini Slide Prompt
```
Create a visual showing the self-healing workflow in 4 steps:
1. "Test Fails" (red X)
2. "AI Analyzes" (blue brain icon)
3. "Fix Applied" (purple wrench)
4. "Test Passes" (green checkmark)
Connect with arrows, include confidence scores (95%, 78%, 42%) for three tiers.
```

---

## ğŸ“¹ SHOT 5: CLOSING (5:00-5:30)

### Action
- Show all three tabs side-by-side (screenshot montage)
- Or return to Chat tab

### Bullets
- Chat: answers with real sources
- Curate: trains the AI
- Test: heals itself
- Three pillars working together
- AI that gets better every day

### CapCut Overlays
- Three checkmarks appearing
- Final stats overlay
- CTA: "Try thebetabase.com"

### Gemini Slide Prompt
```
Create a summary slide with three pillars side-by-side:
- Left: "Chat" with chat bubble icon and "45K vectors"
- Center: "Curate" with feedback icon and "RLHF Loop"
- Right: "Test" with shield icon and "94% Success"
Title: "Three Pillars Working Together"
```

---

## ğŸ¤ DEMO QUERIES (Exact Text)

Pre-warm these before recording:

```
Show me The Betabase multi-tenant database architecture
```

```
What are the steps to link a product to a master in AOMA?
```

```
How do I upload and archive digital assets in AOMA from preparation to storage?
```

Then for recording:

```
What are the steps to link a product to a master in AOMA?
```

```
How do I upload and archive digital assets in AOMA from preparation to storage?
```
â¬†ï¸ **This triggers the beautiful 5-phase workflow diagram!** Click the "Would you like a visual diagram?" prompt that appears.

```
What new features are in AOMA 2.116.0?
```

---

## ğŸ¨ CAPCUT EDITING CHECKLIST

### Import & Organize
- [ ] Import screen recording(s)
- [ ] Trim dead space between actions
- [ ] Mark shot boundaries (5 main shots)

### Text Overlays
- [ ] Add stats overlays (45,399 vectors, 94.2%, etc.)
- [ ] Add pillar titles (Chat / Curate / Test)
- [ ] Add key phrases at transitions

### Visual Enhancements
- [ ] Zoom 1.5-2x on key UI elements
- [ ] Circle/highlight citations, buttons
- [ ] Add color coding (green for success, yellow for review)
- [ ] Pan across stats grid

### Audio
- [ ] Add subtle background music (-20dB)
- [ ] Ensure voiceover is clear
- [ ] Remove long pauses/silence

### Export
- [ ] Resolution: 1080p minimum
- [ ] Frame rate: 30fps
- [ ] Format: H.264 MP4
- [ ] Bitrate: 10-15 Mbps

---

## ğŸ“Š GEMINI SLIDES - COMPLETE SET

### Slide 1: Title
```
Title slide for "The Betabase: Three-Pillar Demo"
Subtitle: "Chat, Curate, Test"
Dark gradient background, purple accent color, modern tech aesthetic
```

### Slide 2: Multi-Tenant Architecture
```
Hand-drawn infographic showing three-tier multi-tenant database:
- Organization level (Sony Music)
- Division level (Digital Ops, Legal, Finance)  
- App level (AOMA, Alexandria, Confluence)
Show data isolation between tiers with connecting lines
```

### Slide 3: Pillar 1 - Chat
```
Infographic for Chat pillar featuring:
- Large search/chat bubble icon in center
- "45,399 Domain Vectors" callout with database icon
- "Inline Citations" feature bubble with link icon
- "Nano Banana Diagrams" feature bubble with sparkle/banana icon
Purple/blue gradient, modern tech style
```

### Slide 4: Pillar 2 - Curate
```
Cyclical diagram showing RLHF feedback loop:
Step 1: "AI Response" (chat bubble)
Step 2: "Human Feedback" (thumbs up/down)
Step 3: "Embedding Re-weight" (brain + weights)
Step 4: "Better Retrieval" (improved search)
Circle back to Step 1 with arrow
Hand-drawn connecting arrows
```

### Slide 5: Pillar 3 - Test
```
4-step self-healing workflow diagram:
1. "Test Fails" - red X icon, example: "Selector not found"
2. "AI Analyzes" - blue brain icon, "DOM diff detected"  
3. "Fix Applied" - purple wrench icon, "Selector updated"
4. "Test Passes" - green checkmark, "95% confidence"
Include three confidence tiers below: Tier 1 (green), Tier 2 (yellow), Tier 3 (red)
```

### Slide 6: The Loop
```
Show how three pillars connect in a virtuous cycle:
"Better Chat" â†’ "Fewer Corrections" â†’ "Improved Retrieval" â†’ "Fewer Test Failures" â†’ back to "Better Chat"
Circular flow with arrows, hand-drawn style
```

### Slide 7: Summary/CTA
```
Three icons side-by-side with stats:
- Chat icon: "45K vectors"
- Curate icon: "RLHF Loop"
- Test icon: "94% Success"
Title: "Three Pillars Working Together"
Subtitle: "AI That Gets Better Every Day"
CTA: "thebetabase.com"
```

### Slide 8: Intent Classification (RAG Optimization)
```
Create a hand-drawn style infographic showing query routing:
- Left side: "User Query" bubble
- Center: "Intent Classifier" brain icon with Gemini logo
- Right side: 6 boxes for source types (JIRA, Docs, Git, Email, Web, Metrics)
- Show 2 boxes highlighted in green (selected), 4 grayed out (skipped)
- Arrow from query through classifier to selected sources only
- Caption: "Smart routing = Less noise, Better answers"
Use purple/blue tech aesthetic, clean lines
```

### Slide 9: Re-Ranker (Two-Stage Retrieval)
```
Create a visual showing two-stage retrieval:
- Stage 1: Large funnel labeled "Vector Search" with "200 docs â†’ 50 candidates"
- Stage 2: Smaller funnel labeled "Gemini Re-Ranker" with "50 â†’ 10 best"
- Show documents being reordered (arrows showing rank changes)
- Include small badge: "RLHF Boost" with thumbs-up icon
- Before/After comparison: scrambled order vs. clean ranked list
- Caption: "Right documents, right order"
Purple/blue gradient, modern tech style
```

### Slide 10: Full RAG Pipeline
```
Create a horizontal pipeline diagram showing the full RAG flow:
1. "Query" (green) â†’ 2. "Intent Classifier" (purple) â†’ 3. "Vector Search" (blue) â†’ 4. "Re-Ranker" (orange) â†’ 5. "Response" (green)
Show document count decreasing at each stage: 200 â†’ 50 â†’ 10 â†’ 1 response
Include timing: "50ms + 100ms + 300ms = <500ms total"
Add small icons for each stage
Caption: "Intelligent retrieval, every query"
```

---

## â±ï¸ TIMING BREAKDOWN

| Shot | Time | Pillar | Key Moment |
|------|------|--------|------------|
| 1 | 0:00-0:30 | Intro | Multi-tenant ERD |
| 2 | 0:30-2:00 | Chat | Query + diagram |
| 3 | 2:00-3:30 | Curate | Feedback + queue |
| 4 | 3:30-5:00 | Test | Self-healing workflow |
| 5 | 5:00-5:30 | Close | Three pillars summary |

---

## ğŸ”§ PRE-RECORDING CHECKLIST

### Environment
- [ ] Dev server: `cd ~/Documents/projects/mc-thebetabase && pnpm dev`
- [ ] URL: http://localhost:3000
- [ ] Auth bypass: `NEXT_PUBLIC_BYPASS_AUTH=true` in .env.local
- [ ] No console errors (check DevTools)

### Pre-Cache Queries
Run these before recording (warms cache):
- [ ] "Show me The Betabase multi-tenant database architecture"
- [ ] "What are the steps to link a product to a master in AOMA?"
- [ ] "How do I upload and archive digital assets in AOMA from preparation to storage?" â­ (triggers diagram)
- [ ] "What new features are in AOMA 2.116.0?"

### UI Check
- [ ] Navigate to Test tab (loads data)
- [ ] Navigate to Curate tab (loads data)
- [ ] Return to Chat tab
- [ ] All tabs render without errors

### Recording Setup
- [ ] Screen resolution: 1920x1080 or higher
- [ ] Browser fullscreen mode
- [ ] Hide bookmarks bar
- [ ] Close DevTools
- [ ] CapCut ready for import

---

## ğŸ’¡ KEY PHRASES (For Bullets)

### Multi-Tenant
- Three-tier isolation
- Organization â†’ Division â†’ App
- Data segregation by design

### Chat Pillar
- 45,399 AOMA vectors
- Inline source citations
- Nano Banana diagrams on demand (30-50 sec generation)
- Real proprietary knowledge
- **Intent Classification** - AI routes queries to relevant sources only

### Intent Classification (NEW!)
- Gemini Flash analyzes query BEFORE vector search
- Routes to relevant tables only (knowledge, jira, git, email)
- Prevents noise from irrelevant sources
- Example: "project status" â†’ routes to JIRA + email (skips git, docs)
- Result: cleaner context = better answers

### Curate Pillar
- Human-in-the-loop feedback
- Thumbs + stars + text
- Curator review queue
- Corrections re-weight embeddings
- RLHF virtuous cycle

### Test Pillar
- 1,247 tests monitored
- 94% auto-healed
- 4 second avg heal time
- Three-tier confidence system
- Tier 1: auto-apply (high)
- Tier 2: QA review (medium)
- Tier 3: architect review (low)

---

## ğŸš¨ IF THINGS BREAK

### Chat Query Slow
- Use pre-cached query
- Or: "Processing..." then trim in CapCut

### Diagram Doesn't Render
- Skip diagram, mention "available on demand"
- Or use screenshot from earlier run

### Test Dashboard Empty
- Mock data should be there
- If not, mention "in production, 1,247 tests"

### Console Error Visible
- Fix before recording
- Or crop screen to hide console

---

## ğŸ“ POST-RECORDING

### CapCut Edit Steps
1. Import recording
2. Trim dead space
3. Add text overlays at marked times
4. Zoom on key UI (1.5-2x)
5. Add transitions (simple cuts)
6. Background music (-20dB)
7. Color grade: +5 brightness, +10 contrast
8. Export: 1080p, 30fps, H.264

### Gemini Slides Creation
1. Use all 7 prompts above in Gemini
2. Download as PNG or PDF
3. Import into CapCut as B-roll
4. Insert between live demo sections

---

## âœ… SUCCESS CRITERIA

- [ ] All three pillars demonstrated clearly
- [ ] Multi-tenant ERD shown first
- [ ] Each pillar < 90 seconds
- [ ] Total runtime 5:00-5:30
- [ ] No visible errors
- [ ] Smooth transitions in CapCut
- [ ] Gemini slides enhance, not distract

---

**Target Audience:** Technical decision-makers
**Tone:** Professional but warm
**Pace:** Medium - let diagrams render
**Format:** Screen recording + CapCut overlays + Gemini slides

---

---

## ğŸ§  INTENT CLASSIFICATION (Technical Deep-Dive)

**The Problem It Solves:**
More data â‰  better answers. With 45K+ vectors across multiple source types (JIRA, docs, git, email), fan-out queries retrieve noise that degrades response quality.

### Intent Classification Flow (Mermaid)

```mermaid
flowchart LR
    A["ğŸ” User Query"] --> B{"ğŸ§  Intent\nClassifier\n(Gemini Flash)"}
    
    B --> C["Query Type:\nstatus"]
    B --> D["Sources:\njira, email"]
    B --> E["Confidence:\n92%"]
    
    C --> F{"ğŸ“Š Targeted\nVector Search"}
    D --> F
    
    F --> G["âœ… JIRA\nTickets"]
    F --> H["âœ… Email\nComms"]
    F --> I["âŒ Skip:\ngit, docs"]
    
    G --> J["ğŸ¯ 50 Focused\nCandidates"]
    H --> J
    
    style A fill:#4CAF50,color:white
    style B fill:#9C27B0,color:white
    style F fill:#2196F3,color:white
    style J fill:#FF9800,color:white
    style I fill:#f44336,color:white
```

**Source Type Routing:**

| Query Type | Routes To | Skips |
|------------|-----------|-------|
| Status/Project | jira, email | git, knowledge |
| Technical/How-to | knowledge, firecrawl | email, metrics |
| Code/Implementation | git, knowledge | email, jira |
| Communication | email, jira | git, metrics |
| Troubleshooting | jira, knowledge, git | email |

**Key Files:**
- `src/services/intentClassifier.ts` - The classifier service
- Uses AI SDK v6 `generateObject()` with Zod schema
- Falls back to keyword heuristics if LLM fails
- 5-minute cache prevents repeated classifications

**Demo Talking Point:**
"When you ask about project status, the AI doesn't search everywhere blindly. It classifies your intent and routes to the relevant sourcesâ€”JIRA tickets and stakeholder emailsâ€”skipping code commits and technical docs. Less noise, better answers."

### Gemini Slide Prompt (Intent Classification)
```
Create a hand-drawn style infographic showing query routing:
- Left side: "User Query" bubble
- Center: "Intent Classifier" brain icon with Gemini logo
- Right side: 6 boxes for source types (JIRA, Docs, Git, Email, Web, Metrics)
- Show 2 boxes highlighted in green (selected), 4 grayed out (skipped)
- Arrow from query through classifier to selected sources only
- Caption: "Smart routing = Less noise, Better answers"
Use purple/blue tech aesthetic, clean lines
```

---

## ğŸ”„ RE-RANKER (Two-Stage Retrieval)

**The Problem It Solves:**
Vector similarity scores aren't calibrated across source types. A 0.85 in JIRA â‰  0.85 in docs. Raw retrieval returns results ordered by embedding similarity, which doesn't always reflect actual query relevance.

### Re-Ranker Flow (Mermaid)

```mermaid
flowchart TD
    A["ğŸ“š 200 Raw\nVector Results"] --> B{"ğŸ”€ Stage 1:\nInitial Retrieval\n(pgvector)"}
    
    B --> C["Top 50 by\nSimilarity Score"]
    
    C --> D{"ğŸ§  Stage 2:\nGemini Re-Ranker"}
    
    D --> E["Score each doc\n0-100 relevance"]
    D --> F["Consider:\nâ€¢ Semantic match\nâ€¢ Specificity\nâ€¢ Recency"]
    
    E --> G["Apply RLHF\nBoosts"]
    
    G --> H["ğŸ“Š Final Top 10\nRe-ranked Results"]
    
    subgraph "Before Re-ranking"
        I1["Doc A: 0.89"] 
        I2["Doc B: 0.87"]
        I3["Doc C: 0.85"]
    end
    
    subgraph "After Re-ranking"
        O1["Doc C: 95/100 â¬†ï¸"]
        O2["Doc A: 72/100 â¬‡ï¸"]
        O3["Doc B: 68/100 â¬‡ï¸"]
    end
    
    H --> O1
    
    style A fill:#f44336,color:white
    style D fill:#9C27B0,color:white
    style H fill:#4CAF50,color:white
    style O1 fill:#4CAF50,color:white
```

### Re-Ranking Process Detail

```mermaid
sequenceDiagram
    participant Q as Query
    participant V as Vector Search
    participant R as Gemini Re-Ranker
    participant RLHF as RLHF Signals
    participant LLM as Final LLM
    
    Q->>V: "How does auth work?"
    V->>V: pgvector similarity search
    V->>R: Top 50 candidates (0.5-0.9 similarity)
    
    R->>R: Prompt: "Rate relevance 0-100"
    R->>R: Doc 1: 95 (direct answer)
    R->>R: Doc 2: 42 (mentions auth, wrong context)
    R->>R: Doc 3: 78 (related but partial)
    
    R->>RLHF: Check curator feedback
    RLHF->>R: +15% boost for Doc 1 (verified)
    
    R->>LLM: Top 10 re-ranked docs
    LLM->>Q: High-quality response
```

**Key Files:**
- `src/services/geminiReranker.ts` - Two-stage retrieval with Gemini
- `src/services/twoStageRetrieval.ts` - Orchestrates initial + rerank
- Uses batch processing (10 docs at a time) for efficiency
- RLHF feedback boosts curator-verified content

**Performance Impact:**

| Metric | Without Re-ranking | With Re-ranking |
|--------|-------------------|-----------------|
| Top-1 Accuracy | ~60% | ~85% |
| Relevant in Top 5 | 3/5 avg | 4.5/5 avg |
| Noise in context | High | Low |
| Added latency | 0ms | 200-400ms |

**Demo Talking Point:**
"The first search finds candidates by embedding similarity. But similar embeddings don't always mean relevant answers. Our re-ranker uses Gemini to score each document on actual query relevanceâ€”and it learns from curator feedback. The result: the best documents float to the top."

### Gemini Slide Prompt (Re-Ranker)
```
Create a visual showing two-stage retrieval:
- Stage 1: Large funnel labeled "Vector Search" with "200 docs â†’ 50 candidates"
- Stage 2: Smaller funnel labeled "Gemini Re-Ranker" with "50 â†’ 10 best"
- Show documents being reordered (arrows showing rank changes)
- Include small badge: "RLHF Boost" with thumbs-up icon
- Before/After comparison: scrambled order vs. clean ranked list
- Caption: "Right documents, right order"
Purple/blue gradient, modern tech style
```

---

## ğŸ” CODE AS HIDDEN KNOWLEDGE (Technical Deep-Dive)

### The Innovation: Intelligent Code Awareness

```mermaid
graph LR
    A[User Query: 'Why am I getting this error?'] --> B{AI with Code Knowledge}
    B --> C{Is it a 500 error?}
    C -- Yes --> D[Backend Issue - Not in indexed UI code]
    C -- No --> E[Check Angular Components]
    E --> F[Find Error Handler in Code]
    F --> G[Explain in Plain English]
    G --> H[User-Friendly Answer]
    
    I[Code Indexed] -.-> B
    J[Line Numbers Tracked] -.-> B
    
    style B fill:#BB86FC,stroke:#333,stroke-width:2px,color:#fff
    style G fill:#03DAC6,stroke:#333,stroke-width:2px,color:#000
    style H fill:#6200EE,stroke:#333,stroke-width:2px,color:#fff
```

### The Problem: Support Without Developer Access
- Technical support users need accurate answers about app behavior
- They don't want to see raw codeâ€”they're not developers
- But code is the ultimate source of truth for "how things really work"

### The Solution: Code as Hidden Knowledge
We index the actual source code (4,247+ vectors with line numbers!) but teach the AI to use it *invisibly*:

1. **CODE IS HIDDEN** - Never shown unless user asks "show me the code"
2. **ANSWERS ARE SMARTER** - AI can verify facts against actual implementation
3. **TROUBLESHOOTING IS PRECISE** - 500 error? AI knows that's backend, not UI
4. **TRANSLATION TO HUMAN** - "The system validates the product ID" not "validateProductId() in line 234..."

### What Gets Indexed
| Content | Metadata | Purpose |
|---------|----------|---------|
| Angular components | File path, line numbers | Locate UI logic |
| Services & modules | Functions, classes | Understand data flow |
| Error handlers | Line ranges | Troubleshooting |
| Comments & docs | In-code context | Intent & rationale |

### Key System Prompt Instructions
The AI is explicitly told:
- "CODE IS HIDDEN KNOWLEDGE - Don't show code snippets unless specifically asked"
- "If user mentions a 500 error â†’ That's a BACKEND/API error, not the UI"
- "Say 'Looking at how this works internally...' without showing the code"
- "Only mention file locations if the user asks 'where in the code'"

### ğŸ¨ Beautiful Code Artifact Display
When the AI reveals code (on user request), it uses a gorgeous artifact format:
- **Traffic Light Header** - Red/yellow/green dots like a real IDE
- **File Path Display** - Full path shown in monospace
- **Language Badge** - TYPESCRIPT, JAVASCRIPT, etc.
- **Line Numbers** - Every line numbered for reference
- **Copy Button** - One-click copy to clipboard

**AI Format**: The AI uses `typescript:path/to/file.ts` in code blocks to trigger this display.

### Key Files
- `src/app/api/chat/route.ts` - System prompt with code knowledge + formatting instructions
- `src/components/ai-elements/response.tsx` - Code artifact renderer with line numbers
- `src/components/ai-elements/code-block.tsx` - CodeBlock component
- `src/services/intentClassifier.ts` - Routes queries to `git` source for code questions
- `src/services/multiRepoIndexer.ts` - Indexes code with line numbers
- `src/services/aomaOrchestrator.ts` - Enhanced code query preprocessing

### Technical Enhancement: Code Query Optimization
When users ask for code, the system enhances the query for better vector matches:

```
User query: "Show me the reducer code for dolby uploads"
Enhanced query: "ngrx reducer reducer dolby uploads .sort createReducer on"
```

This boosted match scores from **57.5%** (GraphQL code) to **73.1%** (actual reducer code)!

### Demo Talking Point
"We've indexed the entire AOMA frontend codebaseâ€”every component, every service, every error handler. But the AI doesn't dump code at users. Instead, it uses code as hidden knowledge to give *more accurate* answers. Ask about an error, and the AI knows exactly where it comes fromâ€”without making you read TypeScript."

### Example Dialogue
**User:** "I'm getting an error when trying to link a product. It says 'Invalid product ID format.'"

**Without Code Knowledge:**
> "That error usually means the product ID doesn't match the expected format. Try checking the ID."

**With Code Knowledge (Hidden):**
> "That error comes from the product validation step before linking. The system expects a 10-character alphanumeric ID starting with 'P'. If you're copying from a spreadsheet, check for hidden spaces or special characters. Would you like me to show you the exact validation rules?"

---

## ğŸ”— FULL RAG PIPELINE (Combined View)

### Complete RAG Flow (Mermaid)

```mermaid
flowchart TD
    A["ğŸ‘¤ User Query"] --> B["ğŸ§  Intent Classifier\n(~50ms)"]
    
    B --> C{"Route to\nRelevant Sources"}
    
    C -->|"status query"| D["JIRA + Email"]
    C -->|"technical query"| E["Docs + Firecrawl"]
    C -->|"code query"| F["Git + Docs"]
    
    D --> G["ğŸ“Š Vector Search\n(pgvector)"]
    E --> G
    F --> G
    
    G --> H["Top 50 Candidates"]
    
    H --> I["ğŸ”„ Gemini Re-Ranker\n(~300ms)"]
    
    I --> J["Apply RLHF Boosts"]
    
    J --> K["ğŸ“ Top 10 Re-ranked"]
    
    K --> L["ğŸ§  Context Synthesis\n(Gemini Flash)"]
    
    L --> M["âœ¨ Final LLM Response\n(Gemini Pro)"]
    
    style A fill:#4CAF50,color:white
    style B fill:#9C27B0,color:white
    style I fill:#FF9800,color:white
    style M fill:#2196F3,color:white
```

### Gemini Slide Prompt (Full Pipeline)
```
Create a horizontal pipeline diagram showing the full RAG flow:
1. "Query" (green) â†’ 2. "Intent Classifier" (purple) â†’ 3. "Vector Search" (blue) â†’ 4. "Re-Ranker" (orange) â†’ 5. "Response" (green)
Show document count decreasing at each stage: 200 â†’ 50 â†’ 10 â†’ 1 response
Include timing: "50ms + 100ms + 300ms = <500ms total"
Add small icons for each stage
Caption: "Intelligent retrieval, every query"
```

---

---

## ğŸ¯ REAL DEMO SCENARIOS: Hidden Code Knowledge in Action

These are **REAL examples** from the database where indexed code explains user issues.

### ğŸ”¥ SCENARIO 1: "Asset Upload Sorting Failed" (ğŸ† GOLDEN DEMO QUERY)

**Real JIRA Tickets Found:**
- ITSM-55968: EydÃ­s Evensen - Oceanic Mirror
- ITSM-56940: Les EnfoirÃ©s - 2025 Au pays de
- ITSM-71656: Eefje de Visser - Vlijmscherp
- ITSM-74175: Tobias Rahim - VulkanÃ¸

**Code Location:** `ust-cc-ttml.reducers.ts` lines 96-183
**Key Functions:** `handleAssetUploadIdList`, `updateUploadIdList`

#### Demo Script

**USER (ğŸ† GOLDEN QUERY):** "I'm getting an 'Asset Upload Sorting Failed' error when uploading files. What's going on?"

**AI RESPONSE (With Hidden Code Knowledge):**
> I found multiple related tickets for this issueâ€”it's a known problem!
>
> ğŸ“‹ **Related Tickets:** ITSM-55968, ITSM-56940, ITSM-71656
>
> This error occurs in the **Unified Submission Tool (UST)** when the upload state machine can't properly sequence the files before processing.
>
> **Root Cause:** The `handleAssetUploadIdList` function expects files to be sorted by sequence and side before processing begins. When files arrive out of order, it triggers this error.
>
> **Quick Fixes:**
> 1. Refresh the page and try again
> 2. Upload files in smaller batches (5-10 at a time)
> 3. Ensure filenames don't contain special characters (like Ã¸, Ã©, etc.)
>
> Would you like me to show you the exact code location?

**USER (if they ask):** "Yeah, show me where this happens."

**AI REVEALS CODE (BEAUTIFUL ARTIFACT DISPLAY!):**

The AI outputs code using the special `typescript:filepath` format, which triggers our gorgeous code artifact renderer:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”´ ğŸŸ¡ ğŸŸ¢  src/app/.../reducers/ust-dolby.reducers.ts    TYPESCRIPT  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1 â”‚ // This is the ACTUAL indexed code from the AOMA codebase     â”‚
â”‚  2 â”‚ on(UstDolbyActions.setUstDolbyData, (state, { dolbyDataItem })â”‚
â”‚  3 â”‚   let dolbyData = [...state.dolbyData];                       â”‚
â”‚  4 â”‚                                                                â”‚
â”‚  5 â”‚   dolbyData.push(dolbyDataItem);                              â”‚
â”‚  6 â”‚   dolbyData = dolbyData                                       â”‚
â”‚  7 â”‚     .sort((a, b) => a.sequence - b.sequence)  // PRIMARY      â”‚
â”‚  8 â”‚     .sort((a, b) => a.side - b.side);          // SECONDARY   â”‚
â”‚  9 â”‚                                                                â”‚
â”‚ 10 â”‚   return { ...state, dolbyData };                             â”‚
â”‚ 11 â”‚ }),                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        [ğŸ“‹ Copy]
```

**What the Audience Sees:**
- ğŸ”´ğŸŸ¡ğŸŸ¢ **Traffic light dots** (macOS-style window header)
- ğŸ“ **Full file path** in monospace font
- ğŸ·ï¸ **Language badge** (TYPESCRIPT)
- ğŸ”¢ **Line numbers** on every line
- ğŸ“‹ **Copy button** for instant clipboard copy

**Narration:** "And if you want to see exactly where this is happening in the codebase, I can show you the actual codeâ€”with file path and line numbers. Notice how it's beautifully formatted, not just raw text."

**Why This Matters:** When files arrive faster than they can be sorted, or when filenames contain special characters that affect sequence parsing, the state becomes inconsistent and throws the "Sorting Failed" error.

**âœ… VERIFIED:** This scenario works! The AI finds:
- JIRA tickets with 62%+ similarity
- Reducer code with 73%+ similarity
- Line numbers and file paths for code reveal

---

### ğŸ“¦ SCENARIO 2: "Aspera Disk Write Failed"

**JIRA Ticket:** DPSA-29600
**Code Location:** `ust-cc-ttml-aspera.reducers.ts` lines 1-79

**USER:** "I got an Aspera error code 36 - disk write failed. What does this mean?"

**AI RESPONSE:**
> I found a ticket about this: **DPSA-29600**
>
> This is an Aspera transfer error, not an AOMA UI issue. Error code 36 means the destination server ran out of disk space.
>
> Based on how the code handles Aspera transfers:
> - The `uploadUstCCTTMLItemAsperaError` state is set
> - The transfer is marked as failed
> - **Your files are still safe locally**
>
> **What to do:**
> 1. Wait 10-15 minutes and retry
> 2. Contact IT if it persists
> 3. Try a smaller file set to confirm it's a space issue

---

### ğŸµ SCENARIO 3: "360RA UploadPublishFailed"

**JIRA Ticket:** DPSA-30187
**Code Location:** `ust-ra360.reducers.ts` lines 1-109
**Key Functions:** `handle360State`, `handleAssetUploadIdList`

**USER:** "I'm trying to register a 360 Reality Audio track and getting 'UploadPublishFailed'. Help!"

**AI RESPONSE:**
> Found it! **DPSA-30187** documents this exact issue.
>
> 360RA registrations go through a special workflow. "UploadPublishFailed" means:
> 1. âœ… The file uploaded successfully
> 2. âŒ The publish step failed
>
> Looking at the code, `UstRa360State` tracks separate statuses:
> - `ra360Statuses: { assetUploadId: number, status: string }[]`
>
> **Next Steps:**
> 1. Check if the asset appears in "Pending" status
> 2. If yes, manually complete the registration
> 3. If no, contact DPSA support with your ISRC code

---

### â° SCENARIO 4: "TUS Upload Inactive Timeout"

**JIRA Ticket:** DPSA-30683
**Error:** "TUS upload failed: Upload was inactive during last [6] hours"

**USER:** "I got a weird error saying my upload was inactive for 6 hours and now it failed."

**AI RESPONSE:**
> That's ticket **DPSA-30683** â€” the TUS (resumable upload) timeout.
>
> This happens when:
> 1. You started an upload
> 2. Your connection dropped or browser closed
> 3. 6+ hours passed without resumption
> 4. The server cleaned up the partial upload
>
> **The file is NOT on the server** - you'll need to re-upload.
>
> **Pro tip:** The UST uses `resumable.js` for chunked uploads. For large uploads:
> - Keep the browser tab open and active
> - Avoid putting your laptop to sleep
> - Consider uploading during off-peak hours

---

### ğŸ“Š Real Scenarios Summary

| # | Error | JIRA | Code File | Best For |
|---|-------|------|-----------|----------|
| 1 | Asset Upload Sorting Failed | ITSM-55968+ | ust-cc-ttml.reducers.ts | **Primary demo** |
| 2 | Aspera Disk Write Failed | DPSA-29600 | ust-cc-ttml-aspera.reducers.ts | Infrastructure |
| 3 | 360RA UploadPublishFailed | DPSA-30187 | ust-ra360.reducers.ts | Niche workflow |
| 4 | TUS Inactive Timeout | DPSA-30683 | resumable.js | User behavior |

### ğŸ’¡ Demo Talking Points

1. "Notice how it found multiple related tickets? That's because we indexed your entire JIRA history."
2. "The AI knows this is a UI issue because we indexed the Angular code."
3. "Code is hidden knowledgeâ€”it makes the answer smarter without being overwhelming."
4. "The user didn't have to know *where* to lookâ€”the system figured it out."
5. "And look at this beautiful code displayâ€”traffic lights, file path, line numbers, copy button!"

---

## ğŸ¬ CAPCUT FILMING CHECKLIST

### Pre-Recording Setup
- [ ] Dev server running: `infisical run --env=dev -- pnpm dev`
- [ ] Clear browser cache / use incognito
- [ ] Test API is responding: `curl http://localhost:3000/api/chat`
- [ ] Screen recording software ready (ScreenFlow / OBS / QuickTime)
- [ ] Microphone test

### Demo Queries to Record

| Scene | Query | Expected Features |
|-------|-------|-------------------|
| **1. JIRA Discovery** | "I'm getting Asset Upload Sorting Failed error. Any tickets?" | Shows ITSM-55968, ITSM-56940, explains code logic |
| **2. Code Reveal** | "Show me where this happens in the code" | Beautiful artifact with ğŸ”´ğŸŸ¡ğŸŸ¢, filepath, line numbers |
| **3. Curate Demo** | Navigate to Curate pillar, upload document | Shows knowledge ingestion flow |
| **4. Test Demo** | Navigate to Test pillar | Shows test orchestration |

### Key Visual Moments to Capture
1. ğŸ“‹ AI mentioning specific JIRA ticket numbers (ITSM-55968)
2. ğŸ’» Beautiful code artifact appearing with traffic lights
3. ğŸ”¢ Line numbers visible in code display
4. ğŸ“ File path visible in code header
5. âš¡ Intent classifier working (visible in dev console if desired)

### Post-Recording Notes
- Clips will be edited together in CapCut
- Add Gemini-generated infographics as b-roll
- Consider adding zooms on key UI elements
- Music: Keep it subtle and professional

---

---

## ğŸ¨ DIAGRAM SYSTEM (Technical)

### ğŸŒ Nano Banana - Single Unified System

**We simplified!** The system now uses **ONLY Nano Banana** for all diagrams. No more switching between systems or HTML syntax issues.

#### How It Works
- **Where**: Generated as beautiful images in chat interface
- **Tech**: Gemini 3 Pro image generation API
- **File**: `ai-sdk-chat-panel.tsx` (simplified logic)
- **Triggered by**: ANY diagram request - Nano Banana figures out the visualization
- **Display**: Hand-drawn style PNG/JPEG images
- **Generation Time**: 30-50 seconds (with progress indicator)

#### Example Queries (All Use Nano Banana)
```
"Show me the upload workflow"
â†’ Nano Banana creates workflow diagram

"Explain the multi-tenant architecture"  
â†’ Nano Banana creates ERD diagram

"How does validation work?"
â†’ Nano Banana creates process flow

"Create an infographic of this for my demo"
â†’ Nano Banana creates presentation slide
```

#### Why We Switched
âœ… **Simpler logic** - One system, no conditionals  
âœ… **No syntax errors** - Gemini handles all formatting  
âœ… **Better visuals** - Hand-drawn style looks professional  
âœ… **Smarter** - Gemini chooses the best diagram type automatically  
âœ… **Consistent** - Every diagram has the same beautiful aesthetic

---

*Created: December 15, 2025*
*Updated: December 18, 2025 (added Intent Classification, Re-Ranker diagrams, Real Demo Scenarios, Code Artifact Display, Filming Checklist; **Simplified to Nano Banana only - removed Mermaid**)*
*For: Mattie (called by Claudette)*
