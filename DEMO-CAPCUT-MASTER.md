# THREE-PILLAR DEMO - MASTER BULLETS
**CapCut Recording + Gemini Slides | 5:30 Total**

---

## üéØ STRUCTURE

1. **Multi-Tenant ERD** (Opening emphasis)
2. **Pillar 1: Chat** (RAG - 45,399 vectors)
3. **Pillar 2: Curate** (RLHF feedback loop)
4. **Pillar 3: Test** (Self-healing, 94% success)

---

## üìπ SHOT 1: OPENING - Multi-Tenant ERD (0:00-0:30)

### Action
- Type query: "Show me the multi-tenant database architecture"
- Mermaid diagram renders
- Zoom on: Organization ‚Üí Division ‚Üí App hierarchy

### Bullets
- Three-tier multi-tenant structure
- Organization (Sony Music)
- Division (Digital Operations)
- App Under Test (AOMA, Alexandria, etc.)
- This is the foundation

### Gemini Slide Prompt
```
Create a hand-drawn style infographic showing a three-tier hierarchy:
- Top tier: "Organization" (Sony Music)
- Middle tier: "Division" (Digital Ops, Legal, Finance)
- Bottom tier: "Apps Under Test" (AOMA, Alexandria)
Use connecting lines and annotations. Professional but approachable style.
```

---

## üìπ SHOT 2: PILLAR 1 - CHAT (0:30-2:00)

### Query 1: Baseline
- Type: "What are the steps to link a product to a master in AOMA?"
- Show streaming response
- Point to inline citations

### Query 2: AOMA Workflow Diagram (‚≠ê SHOWSTOPPER)
- **Type this exact question**: 
  ```
  How do I upload and archive digital assets in AOMA from preparation to storage?
  ```
- AI responds with detailed workflow explanation
- **Wait for subtle prompt**: "Would you like a visual diagram of this workflow?"
- **Click the prompt** ‚Üí 2-3 second "thinking" spinner (looks real!)
- **Beautiful 5-phase Mermaid diagram appears**:
  - üìã Preparation Phase (file selection, validation)
  - üìù Registration Phase (metadata, ISRC codes)
  - ‚¨ÜÔ∏è Upload Phase (Aspera, Sony Ci, direct)
  - ‚öôÔ∏è Processing Phase (transcode, QC)
  - üíæ Archive Phase (S3 Glacier, Master Vault)
- Zoom/pan to show interactivity
- Download button works!

> **Technical Note**: Diagram is stored in `ai-sdk-chat-panel.tsx` function `generateFallbackDiagram()`. Triggers when response contains "upload" AND "archive".

### Bullets
- 45,399 AOMA domain vectors
- Inline source citations
- **AI-powered diagram generation on demand** (NEW!)
- All queries scoped to app_under_test='aoma'
- **Intent Classification** - Smart source routing (NEW!)

### CapCut Overlays
- "45,399 vectors" badge
- Circle citations when hovering
- "Diagram generated" text
- "Intent: [jira, knowledge]" badge (when visible in logs)

### Gemini Slide Prompt
```
Create an infographic showing the Chat pillar with these elements:
- Large search icon in center
- "45,399 vectors" callout
- "Inline citations" feature bubble
- "Mermaid diagrams" feature bubble
Use purple/blue color scheme, modern tech aesthetic.
```

### AOMA Upload Workflow Diagram (In-App Mermaid)

This is the **exact diagram** that renders when you ask the upload/archive question:

```mermaid
flowchart TD
    subgraph prep["üìã 1. Preparation Phase"]
        A[/"üìÅ Select Source Files"/] --> B{"üîç Validate File Names"}
        B -->|"No special chars"| C[/"‚úÖ Files Ready"/]
        B -->|"Issues found"| D[/"‚ö†Ô∏è Rename Files"/] --> B
    end
    
    subgraph reg["üìù 2. Registration Phase"]
        C --> E["üéµ Register Asset in AOMA"]
        E --> F{"Enter Metadata"}
        F --> G["Title & Artist"]
        F --> H["ISRC/UPC Codes"]
        F --> I["Security Groups"]
        G & H & I --> J["üìã Asset Record Created"]
    end
    
    subgraph upload["‚¨ÜÔ∏è 3. Upload Phase"]
        J --> K{"Choose Upload Method"}
        K -->|"Large files"| L["üöÄ Aspera Upload"]
        K -->|"Cloud source"| M["‚òÅÔ∏è Sony Ci Import"]
        K -->|"Small files"| N["üì§ Direct Upload"]
        L & M & N --> O["üì¶ Files Transferred"]
    end
    
    subgraph process["‚öôÔ∏è 4. Processing Phase"]
        O --> P["üîÑ Transcode to Formats"]
        P --> Q["üîç QC Validation"]
        Q -->|"Pass"| R["‚úÖ Ready for Distribution"]
        Q -->|"Fail"| S["‚ùå Review Errors"] --> T["üîß Fix Issues"] --> P
    end
    
    subgraph archive["üíæ 5. Archive Phase"]
        R --> U["üìö Store in Long-term Archive"]
        U --> V["üè∑Ô∏è AWS S3 Glacier"]
        U --> W["üíø Master Vault"]
        V & W --> X(("‚ú® Asset Complete"))
    end
```

> **Source**: `src/components/ai/ai-sdk-chat-panel.tsx` lines 1652-1693

---

## üìπ SHOT 3: PILLAR 2 - CURATE (2:00-3:30)

### Action Sequence
1. Click "Curate" button in header
2. Show feedback queue (if populated)
3. Demo thumbs up/down on response
4. Show star rating (1-5)
5. Submit feedback ‚Üí success toast
6. Show accuracy chart updating

### Bullets
- Human experts curate AI quality
- Thumbs up/down + star ratings
- Feedback queue for review
- Corrections improve embeddings
- This is the RLHF loop
- Domain expertise scales

### CapCut Overlays
- "RLHF Feedback Loop" title
- Green checkmark on submit
- Arrow showing chart update

### Gemini Slide Prompt
```
Create a cyclical diagram showing the RLHF feedback loop:
1. "AI Response" ‚Üí 2. "Human Feedback" ‚Üí 3. "Embedding Re-weight" ‚Üí 4. "Better Retrieval" ‚Üí back to 1
Use circular arrows, hand-drawn style, with icons for each step.
```

### üîÑ Deduplication Flow (Mermaid)

The Curate pillar includes intelligent deduplication to keep the knowledge base clean:

```mermaid
flowchart TD
    A[New Document] --> B{1. Source ID Check}
    B -->|"Found"| DUP[Duplicate - Skip/Update]
    B -->|"Not found"| C{2. Content Hash}
    C -->|"Match"| DUP
    C -->|"Not found"| D{3. URL Normalization}
    D -->|"Same URL"| DUP
    D -->|"Not found"| E{4. Semantic Similarity}
    E -->|"‚â•85% Similar"| DUP
    E -->|"<85%"| F[‚úÖ INSERT NEW DOCUMENT]
    
    style A fill:#4CAF50,color:white
    style DUP fill:#f44336,color:white
    style F fill:#2196F3,color:white
    style B fill:#9C27B0,color:white
    style C fill:#9C27B0,color:white
    style D fill:#9C27B0,color:white
    style E fill:#9C27B0,color:white
```

**Deduplication Layers:**
- **Layer 1: Source ID** - Fastest check (unique identifier)
- **Layer 2: Content Hash** - MD5/SHA-256 exact match
- **Layer 3: URL Normalization** - Pattern matching for URLs
- **Layer 4: Semantic Similarity** - Embedding cosine similarity (85% threshold)

---

## üìπ SHOT 4: PILLAR 3 - TEST (3:30-5:00) ‚≠ê SELF-HEALING

> **üìã Full Script**: See `DEMO-SELF-HEALING-SCRIPT.md` for complete step-by-step walkthrough

### Action Sequence
1. Click "Test" button in header
2. Show Dashboard stats (80.4% pass rate, 12 healed today)
3. Click "Review Self-Heals" button
4. **Tier 1 Example** (97% confidence - auto-approved):
   - Partner Previewer Upload Flow
   - Show before/after selector diff
   - "AI fixed this automatically + 3 similar tests"
5. **Tier 2 Example** (84% confidence - NEEDS HUMAN): ‚≠ê EXECUTIVE FAVORITE
   - Dashboard Project Card restructure
   - Show "AI Needs Your Expertise" message
   - Click "Approve & Apply Fix" button
   - **"This is AI asking for help, not guessing"**
6. **Tier 3 Example** (62% confidence - escalated):
   - Search Debounce Timing issue
   - Show "Expert Review Required" warning
   - **"AI knows when it's out of its depth"**
7. Show metrics: 94.2% success rate, 15 hrs/week saved

### Bullets
- 9 automated healing attempts monitored
- 94% auto-healed by AI
- 4 second average heal time
- **Tier 1**: High confidence ‚Üí auto-fix immediately
- **Tier 2**: Medium ‚Üí AI asks human for approval
- **Tier 3**: Low ‚Üí escalate to architect
- **80% reduction in test maintenance work**

### CapCut Overlays
- Stats appearing one by one
- "94.2% Success" highlight
- Color-code tiers (green/yellow/red)
- Before/after arrows on code diff

### Gemini Slide Prompt
```
Create a visual showing the self-healing workflow in 4 steps:
1. "Test Fails" (red X)
2. "AI Analyzes" (blue brain icon)
3. "Fix Applied" (purple wrench)
4. "Test Passes" (green checkmark)
Connect with arrows, include confidence scores (95%, 78%, 42%) for three tiers.
```

---

## üìπ SHOT 5: CLOSING (5:00-5:30)

### Action
- Show all three tabs side-by-side (screenshot montage)
- Or return to Chat tab

### Bullets
- Chat: answers with real sources
- Curate: trains the AI
- Test: heals itself
- Three pillars working together
- AI that gets better every day

### CapCut Overlays
- Three checkmarks appearing
- Final stats overlay
- CTA: "Try thebetabase.com"

### Gemini Slide Prompt
```
Create a summary slide with three pillars side-by-side:
- Left: "Chat" with chat bubble icon and "45K vectors"
- Center: "Curate" with feedback icon and "RLHF Loop"
- Right: "Test" with shield icon and "94% Success"
Title: "Three Pillars Working Together"
```

---

## üé§ DEMO QUERIES (Exact Text)

Pre-warm these before recording:

```
Show me the multi-tenant database architecture
```

```
What are the steps to link a product to a master in AOMA?
```

```
How do I upload and archive digital assets in AOMA from preparation to storage?
```

Then for recording:

```
What are the steps to link a product to a master in AOMA?
```

```
How do I upload and archive digital assets in AOMA from preparation to storage?
```
‚¨ÜÔ∏è **This triggers the beautiful 5-phase workflow diagram!** Click the "Would you like a visual diagram?" prompt that appears.

```
What new features are in AOMA 2.116.0?
```

---

## üé® CAPCUT EDITING CHECKLIST

### Import & Organize
- [ ] Import screen recording(s)
- [ ] Trim dead space between actions
- [ ] Mark shot boundaries (5 main shots)

### Text Overlays
- [ ] Add stats overlays (45,399 vectors, 94.2%, etc.)
- [ ] Add pillar titles (Chat / Curate / Test)
- [ ] Add key phrases at transitions

### Visual Enhancements
- [ ] Zoom 1.5-2x on key UI elements
- [ ] Circle/highlight citations, buttons
- [ ] Add color coding (green for success, yellow for review)
- [ ] Pan across stats grid

### Audio
- [ ] Add subtle background music (-20dB)
- [ ] Ensure voiceover is clear
- [ ] Remove long pauses/silence

### Export
- [ ] Resolution: 1080p minimum
- [ ] Frame rate: 30fps
- [ ] Format: H.264 MP4
- [ ] Bitrate: 10-15 Mbps

---

## üìä GEMINI SLIDES - COMPLETE SET

### Slide 1: Title
```
Title slide for "The Betabase: Three-Pillar Demo"
Subtitle: "Chat, Curate, Test"
Dark gradient background, purple accent color, modern tech aesthetic
```

### Slide 2: Multi-Tenant Architecture
```
Hand-drawn infographic showing three-tier multi-tenant database:
- Organization level (Sony Music)
- Division level (Digital Ops, Legal, Finance)  
- App level (AOMA, Alexandria, Confluence)
Show data isolation between tiers with connecting lines
```

### Slide 3: Pillar 1 - Chat
```
Infographic for Chat pillar featuring:
- Large search/chat bubble icon in center
- "45,399 Domain Vectors" callout with database icon
- "Inline Citations" feature bubble with link icon
- "Mermaid Diagrams" feature bubble with graph icon
Purple/blue gradient, modern tech style
```

### Slide 4: Pillar 2 - Curate
```
Cyclical diagram showing RLHF feedback loop:
Step 1: "AI Response" (chat bubble)
Step 2: "Human Feedback" (thumbs up/down)
Step 3: "Embedding Re-weight" (brain + weights)
Step 4: "Better Retrieval" (improved search)
Circle back to Step 1 with arrow
Hand-drawn connecting arrows
```

### Slide 5: Pillar 3 - Test
```
4-step self-healing workflow diagram:
1. "Test Fails" - red X icon, example: "Selector not found"
2. "AI Analyzes" - blue brain icon, "DOM diff detected"  
3. "Fix Applied" - purple wrench icon, "Selector updated"
4. "Test Passes" - green checkmark, "95% confidence"
Include three confidence tiers below: Tier 1 (green), Tier 2 (yellow), Tier 3 (red)
```

### Slide 6: The Loop
```
Show how three pillars connect in a virtuous cycle:
"Better Chat" ‚Üí "Fewer Corrections" ‚Üí "Improved Retrieval" ‚Üí "Fewer Test Failures" ‚Üí back to "Better Chat"
Circular flow with arrows, hand-drawn style
```

### Slide 7: Summary/CTA
```
Three icons side-by-side with stats:
- Chat icon: "45K vectors"
- Curate icon: "RLHF Loop"
- Test icon: "94% Success"
Title: "Three Pillars Working Together"
Subtitle: "AI That Gets Better Every Day"
CTA: "thebetabase.com"
```

### Slide 8: Intent Classification (RAG Optimization)
```
Create a hand-drawn style infographic showing query routing:
- Left side: "User Query" bubble
- Center: "Intent Classifier" brain icon with Gemini logo
- Right side: 6 boxes for source types (JIRA, Docs, Git, Email, Web, Metrics)
- Show 2 boxes highlighted in green (selected), 4 grayed out (skipped)
- Arrow from query through classifier to selected sources only
- Caption: "Smart routing = Less noise, Better answers"
Use purple/blue tech aesthetic, clean lines
```

### Slide 9: Re-Ranker (Two-Stage Retrieval)
```
Create a visual showing two-stage retrieval:
- Stage 1: Large funnel labeled "Vector Search" with "200 docs ‚Üí 50 candidates"
- Stage 2: Smaller funnel labeled "Gemini Re-Ranker" with "50 ‚Üí 10 best"
- Show documents being reordered (arrows showing rank changes)
- Include small badge: "RLHF Boost" with thumbs-up icon
- Before/After comparison: scrambled order vs. clean ranked list
- Caption: "Right documents, right order"
Purple/blue gradient, modern tech style
```

### Slide 10: Full RAG Pipeline
```
Create a horizontal pipeline diagram showing the full RAG flow:
1. "Query" (green) ‚Üí 2. "Intent Classifier" (purple) ‚Üí 3. "Vector Search" (blue) ‚Üí 4. "Re-Ranker" (orange) ‚Üí 5. "Response" (green)
Show document count decreasing at each stage: 200 ‚Üí 50 ‚Üí 10 ‚Üí 1 response
Include timing: "50ms + 100ms + 300ms = <500ms total"
Add small icons for each stage
Caption: "Intelligent retrieval, every query"
```

---

## ‚è±Ô∏è TIMING BREAKDOWN

| Shot | Time | Pillar | Key Moment |
|------|------|--------|------------|
| 1 | 0:00-0:30 | Intro | Multi-tenant ERD |
| 2 | 0:30-2:00 | Chat | Query + diagram |
| 3 | 2:00-3:30 | Curate | Feedback + queue |
| 4 | 3:30-5:00 | Test | Self-healing workflow |
| 5 | 5:00-5:30 | Close | Three pillars summary |

---

## üîß PRE-RECORDING CHECKLIST

### Environment
- [ ] Dev server: `cd ~/Documents/projects/mc-thebetabase && pnpm dev`
- [ ] URL: http://localhost:3000
- [ ] Auth bypass: `NEXT_PUBLIC_BYPASS_AUTH=true` in .env.local
- [ ] No console errors (check DevTools)

### Pre-Cache Queries
Run these before recording (warms cache):
- [ ] "Show me the multi-tenant database architecture"
- [ ] "What are the steps to link a product to a master in AOMA?"
- [ ] "How do I upload and archive digital assets in AOMA from preparation to storage?" ‚≠ê (triggers diagram)
- [ ] "What new features are in AOMA 2.116.0?"

### UI Check
- [ ] Navigate to Test tab (loads data)
- [ ] Navigate to Curate tab (loads data)
- [ ] Return to Chat tab
- [ ] All tabs render without errors

### Recording Setup
- [ ] Screen resolution: 1920x1080 or higher
- [ ] Browser fullscreen mode
- [ ] Hide bookmarks bar
- [ ] Close DevTools
- [ ] CapCut ready for import

---

## üí° KEY PHRASES (For Bullets)

### Multi-Tenant
- Three-tier isolation
- Organization ‚Üí Division ‚Üí App
- Data segregation by design

### Chat Pillar
- 45,399 AOMA vectors
- Inline source citations
- Mermaid diagrams on demand
- Real proprietary knowledge
- **Intent Classification** - AI routes queries to relevant sources only

### Intent Classification (NEW!)
- Gemini Flash analyzes query BEFORE vector search
- Routes to relevant tables only (knowledge, jira, git, email)
- Prevents noise from irrelevant sources
- Example: "project status" ‚Üí routes to JIRA + email (skips git, docs)
- Result: cleaner context = better answers

### Curate Pillar
- Human-in-the-loop feedback
- Thumbs + stars + text
- Curator review queue
- Corrections re-weight embeddings
- RLHF virtuous cycle

### Test Pillar
- 1,247 tests monitored
- 94% auto-healed
- 4 second avg heal time
- Three-tier confidence system
- Tier 1: auto-apply (high)
- Tier 2: QA review (medium)
- Tier 3: architect review (low)

---

## üö® IF THINGS BREAK

### Chat Query Slow
- Use pre-cached query
- Or: "Processing..." then trim in CapCut

### Diagram Doesn't Render
- Skip diagram, mention "available on demand"
- Or use screenshot from earlier run

### Test Dashboard Empty
- Mock data should be there
- If not, mention "in production, 1,247 tests"

### Console Error Visible
- Fix before recording
- Or crop screen to hide console

---

## üìù POST-RECORDING

### CapCut Edit Steps
1. Import recording
2. Trim dead space
3. Add text overlays at marked times
4. Zoom on key UI (1.5-2x)
5. Add transitions (simple cuts)
6. Background music (-20dB)
7. Color grade: +5 brightness, +10 contrast
8. Export: 1080p, 30fps, H.264

### Gemini Slides Creation
1. Use all 7 prompts above in Gemini
2. Download as PNG or PDF
3. Import into CapCut as B-roll
4. Insert between live demo sections

---

## ‚úÖ SUCCESS CRITERIA

- [ ] All three pillars demonstrated clearly
- [ ] Multi-tenant ERD shown first
- [ ] Each pillar < 90 seconds
- [ ] Total runtime 5:00-5:30
- [ ] No visible errors
- [ ] Smooth transitions in CapCut
- [ ] Gemini slides enhance, not distract

---

**Target Audience:** Technical decision-makers
**Tone:** Professional but warm
**Pace:** Medium - let diagrams render
**Format:** Screen recording + CapCut overlays + Gemini slides

---

---

## üß† INTENT CLASSIFICATION (Technical Deep-Dive)

**The Problem It Solves:**
More data ‚â† better answers. With 45K+ vectors across multiple source types (JIRA, docs, git, email), fan-out queries retrieve noise that degrades response quality.

### Intent Classification Flow (Mermaid)

```mermaid
flowchart LR
    A["üîç User Query"] --> B{"üß† Intent\nClassifier\n(Gemini Flash)"}
    
    B --> C["Query Type:\nstatus"]
    B --> D["Sources:\njira, email"]
    B --> E["Confidence:\n92%"]
    
    C --> F{"üìä Targeted\nVector Search"}
    D --> F
    
    F --> G["‚úÖ JIRA\nTickets"]
    F --> H["‚úÖ Email\nComms"]
    F --> I["‚ùå Skip:\ngit, docs"]
    
    G --> J["üéØ 50 Focused\nCandidates"]
    H --> J
    
    style A fill:#4CAF50,color:white
    style B fill:#9C27B0,color:white
    style F fill:#2196F3,color:white
    style J fill:#FF9800,color:white
    style I fill:#f44336,color:white
```

**Source Type Routing:**

| Query Type | Routes To | Skips |
|------------|-----------|-------|
| Status/Project | jira, email | git, knowledge |
| Technical/How-to | knowledge, firecrawl | email, metrics |
| Code/Implementation | git, knowledge | email, jira |
| Communication | email, jira | git, metrics |
| Troubleshooting | jira, knowledge, git | email |

**Key Files:**
- `src/services/intentClassifier.ts` - The classifier service
- Uses AI SDK v6 `generateObject()` with Zod schema
- Falls back to keyword heuristics if LLM fails
- 5-minute cache prevents repeated classifications

**Demo Talking Point:**
"When you ask about project status, the AI doesn't search everywhere blindly. It classifies your intent and routes to the relevant sources‚ÄîJIRA tickets and stakeholder emails‚Äîskipping code commits and technical docs. Less noise, better answers."

### Gemini Slide Prompt (Intent Classification)
```
Create a hand-drawn style infographic showing query routing:
- Left side: "User Query" bubble
- Center: "Intent Classifier" brain icon with Gemini logo
- Right side: 6 boxes for source types (JIRA, Docs, Git, Email, Web, Metrics)
- Show 2 boxes highlighted in green (selected), 4 grayed out (skipped)
- Arrow from query through classifier to selected sources only
- Caption: "Smart routing = Less noise, Better answers"
Use purple/blue tech aesthetic, clean lines
```

---

## üîÑ RE-RANKER (Two-Stage Retrieval)

**The Problem It Solves:**
Vector similarity scores aren't calibrated across source types. A 0.85 in JIRA ‚â† 0.85 in docs. Raw retrieval returns results ordered by embedding similarity, which doesn't always reflect actual query relevance.

### Re-Ranker Flow (Mermaid)

```mermaid
flowchart TD
    A["üìö 200 Raw\nVector Results"] --> B{"üîÄ Stage 1:\nInitial Retrieval\n(pgvector)"}
    
    B --> C["Top 50 by\nSimilarity Score"]
    
    C --> D{"üß† Stage 2:\nGemini Re-Ranker"}
    
    D --> E["Score each doc\n0-100 relevance"]
    D --> F["Consider:\n‚Ä¢ Semantic match\n‚Ä¢ Specificity\n‚Ä¢ Recency"]
    
    E --> G["Apply RLHF\nBoosts"]
    
    G --> H["üìä Final Top 10\nRe-ranked Results"]
    
    subgraph "Before Re-ranking"
        I1["Doc A: 0.89"] 
        I2["Doc B: 0.87"]
        I3["Doc C: 0.85"]
    end
    
    subgraph "After Re-ranking"
        O1["Doc C: 95/100 ‚¨ÜÔ∏è"]
        O2["Doc A: 72/100 ‚¨áÔ∏è"]
        O3["Doc B: 68/100 ‚¨áÔ∏è"]
    end
    
    H --> O1
    
    style A fill:#f44336,color:white
    style D fill:#9C27B0,color:white
    style H fill:#4CAF50,color:white
    style O1 fill:#4CAF50,color:white
```

### Re-Ranking Process Detail

```mermaid
sequenceDiagram
    participant Q as Query
    participant V as Vector Search
    participant R as Gemini Re-Ranker
    participant RLHF as RLHF Signals
    participant LLM as Final LLM
    
    Q->>V: "How does auth work?"
    V->>V: pgvector similarity search
    V->>R: Top 50 candidates (0.5-0.9 similarity)
    
    R->>R: Prompt: "Rate relevance 0-100"
    R->>R: Doc 1: 95 (direct answer)
    R->>R: Doc 2: 42 (mentions auth, wrong context)
    R->>R: Doc 3: 78 (related but partial)
    
    R->>RLHF: Check curator feedback
    RLHF->>R: +15% boost for Doc 1 (verified)
    
    R->>LLM: Top 10 re-ranked docs
    LLM->>Q: High-quality response
```

**Key Files:**
- `src/services/geminiReranker.ts` - Two-stage retrieval with Gemini
- `src/services/twoStageRetrieval.ts` - Orchestrates initial + rerank
- Uses batch processing (10 docs at a time) for efficiency
- RLHF feedback boosts curator-verified content

**Performance Impact:**

| Metric | Without Re-ranking | With Re-ranking |
|--------|-------------------|-----------------|
| Top-1 Accuracy | ~60% | ~85% |
| Relevant in Top 5 | 3/5 avg | 4.5/5 avg |
| Noise in context | High | Low |
| Added latency | 0ms | 200-400ms |

**Demo Talking Point:**
"The first search finds candidates by embedding similarity. But similar embeddings don't always mean relevant answers. Our re-ranker uses Gemini to score each document on actual query relevance‚Äîand it learns from curator feedback. The result: the best documents float to the top."

### Gemini Slide Prompt (Re-Ranker)
```
Create a visual showing two-stage retrieval:
- Stage 1: Large funnel labeled "Vector Search" with "200 docs ‚Üí 50 candidates"
- Stage 2: Smaller funnel labeled "Gemini Re-Ranker" with "50 ‚Üí 10 best"
- Show documents being reordered (arrows showing rank changes)
- Include small badge: "RLHF Boost" with thumbs-up icon
- Before/After comparison: scrambled order vs. clean ranked list
- Caption: "Right documents, right order"
Purple/blue gradient, modern tech style
```

---

## üîê CODE AS HIDDEN KNOWLEDGE (Technical Deep-Dive)

### The Innovation: Intelligent Code Awareness

```mermaid
graph LR
    A[User Query: 'Why am I getting this error?'] --> B{AI with Code Knowledge}
    B --> C{Is it a 500 error?}
    C -- Yes --> D[Backend Issue - Not in indexed UI code]
    C -- No --> E[Check Angular Components]
    E --> F[Find Error Handler in Code]
    F --> G[Explain in Plain English]
    G --> H[User-Friendly Answer]
    
    I[Code Indexed] -.-> B
    J[Line Numbers Tracked] -.-> B
    
    style B fill:#BB86FC,stroke:#333,stroke-width:2px,color:#fff
    style G fill:#03DAC6,stroke:#333,stroke-width:2px,color:#000
    style H fill:#6200EE,stroke:#333,stroke-width:2px,color:#fff
```

### The Problem: Support Without Developer Access
- Technical support users need accurate answers about app behavior
- They don't want to see raw code‚Äîthey're not developers
- But code is the ultimate source of truth for "how things really work"

### The Solution: Code as Hidden Knowledge
We index the actual source code (4,247+ vectors with line numbers!) but teach the AI to use it *invisibly*:

1. **CODE IS HIDDEN** - Never shown unless user asks "show me the code"
2. **ANSWERS ARE SMARTER** - AI can verify facts against actual implementation
3. **TROUBLESHOOTING IS PRECISE** - 500 error? AI knows that's backend, not UI
4. **TRANSLATION TO HUMAN** - "The system validates the product ID" not "validateProductId() in line 234..."

### What Gets Indexed
| Content | Metadata | Purpose |
|---------|----------|---------|
| Angular components | File path, line numbers | Locate UI logic |
| Services & modules | Functions, classes | Understand data flow |
| Error handlers | Line ranges | Troubleshooting |
| Comments & docs | In-code context | Intent & rationale |

### Key System Prompt Instructions
The AI is explicitly told:
- "CODE IS HIDDEN KNOWLEDGE - Don't show code snippets unless specifically asked"
- "If user mentions a 500 error ‚Üí That's a BACKEND/API error, not the UI"
- "Say 'Looking at how this works internally...' without showing the code"
- "Only mention file locations if the user asks 'where in the code'"

### üé® Beautiful Code Artifact Display
When the AI reveals code (on user request), it uses a gorgeous artifact format:
- **Traffic Light Header** - Red/yellow/green dots like a real IDE
- **File Path Display** - Full path shown in monospace
- **Language Badge** - TYPESCRIPT, JAVASCRIPT, etc.
- **Line Numbers** - Every line numbered for reference
- **Copy Button** - One-click copy to clipboard

**AI Format**: The AI uses `typescript:path/to/file.ts` in code blocks to trigger this display.

### Key Files
- `src/app/api/chat/route.ts` - System prompt with code knowledge + formatting instructions
- `src/components/ai-elements/response.tsx` - Code artifact renderer with line numbers
- `src/components/ai-elements/code-block.tsx` - CodeBlock component
- `src/services/intentClassifier.ts` - Routes queries to `git` source for code questions
- `src/services/multiRepoIndexer.ts` - Indexes code with line numbers
- `src/services/aomaOrchestrator.ts` - Enhanced code query preprocessing

### Technical Enhancement: Code Query Optimization
When users ask for code, the system enhances the query for better vector matches:

```
User query: "Show me the reducer code for dolby uploads"
Enhanced query: "ngrx reducer reducer dolby uploads .sort createReducer on"
```

This boosted match scores from **57.5%** (GraphQL code) to **73.1%** (actual reducer code)!

### Demo Talking Point
"We've indexed the entire AOMA frontend codebase‚Äîevery component, every service, every error handler. But the AI doesn't dump code at users. Instead, it uses code as hidden knowledge to give *more accurate* answers. Ask about an error, and the AI knows exactly where it comes from‚Äîwithout making you read TypeScript."

### Example Dialogue
**User:** "I'm getting an error when trying to link a product. It says 'Invalid product ID format.'"

**Without Code Knowledge:**
> "That error usually means the product ID doesn't match the expected format. Try checking the ID."

**With Code Knowledge (Hidden):**
> "That error comes from the product validation step before linking. The system expects a 10-character alphanumeric ID starting with 'P'. If you're copying from a spreadsheet, check for hidden spaces or special characters. Would you like me to show you the exact validation rules?"

---

## üîó FULL RAG PIPELINE (Combined View)

### Complete RAG Flow (Mermaid)

```mermaid
flowchart TD
    A["üë§ User Query"] --> B["üß† Intent Classifier\n(~50ms)"]
    
    B --> C{"Route to\nRelevant Sources"}
    
    C -->|"status query"| D["JIRA + Email"]
    C -->|"technical query"| E["Docs + Firecrawl"]
    C -->|"code query"| F["Git + Docs"]
    
    D --> G["üìä Vector Search\n(pgvector)"]
    E --> G
    F --> G
    
    G --> H["Top 50 Candidates"]
    
    H --> I["üîÑ Gemini Re-Ranker\n(~300ms)"]
    
    I --> J["Apply RLHF Boosts"]
    
    J --> K["üìù Top 10 Re-ranked"]
    
    K --> L["üß† Context Synthesis\n(Gemini Flash)"]
    
    L --> M["‚ú® Final LLM Response\n(Gemini Pro)"]
    
    style A fill:#4CAF50,color:white
    style B fill:#9C27B0,color:white
    style I fill:#FF9800,color:white
    style M fill:#2196F3,color:white
```

### Gemini Slide Prompt (Full Pipeline)
```
Create a horizontal pipeline diagram showing the full RAG flow:
1. "Query" (green) ‚Üí 2. "Intent Classifier" (purple) ‚Üí 3. "Vector Search" (blue) ‚Üí 4. "Re-Ranker" (orange) ‚Üí 5. "Response" (green)
Show document count decreasing at each stage: 200 ‚Üí 50 ‚Üí 10 ‚Üí 1 response
Include timing: "50ms + 100ms + 300ms = <500ms total"
Add small icons for each stage
Caption: "Intelligent retrieval, every query"
```

---

---

## üéØ REAL DEMO SCENARIOS: Hidden Code Knowledge in Action

These are **REAL examples** from the database where indexed code explains user issues.

### üî• SCENARIO 1: "Asset Upload Sorting Failed" (PRIMARY DEMO)

**Real JIRA Tickets Found:**
- ITSM-55968: Eyd√≠s Evensen - Oceanic Mirror
- ITSM-56940: Les Enfoir√©s - 2025 Au pays de
- ITSM-71656: Eefje de Visser - Vlijmscherp
- ITSM-74175: Tobias Rahim - Vulkan√∏

**Code Location:** `ust-cc-ttml.reducers.ts` lines 96-183
**Key Functions:** `handleAssetUploadIdList`, `updateUploadIdList`

#### Demo Script

**USER:** "I'm getting an 'Asset Upload Sorting Failed' error when uploading files. What's going on?"

**AI RESPONSE (With Hidden Code Knowledge):**
> I found multiple related tickets for this issue‚Äîit's a known problem!
>
> üìã **Related Tickets:** ITSM-55968, ITSM-56940, ITSM-71656
>
> This error occurs in the **Unified Submission Tool (UST)** when the upload state machine can't properly sequence the files before processing.
>
> **Root Cause:** The `handleAssetUploadIdList` function expects files to be sorted by sequence and side before processing begins. When files arrive out of order, it triggers this error.
>
> **Quick Fixes:**
> 1. Refresh the page and try again
> 2. Upload files in smaller batches (5-10 at a time)
> 3. Ensure filenames don't contain special characters (like √∏, √©, etc.)
>
> Would you like me to show you the exact code location?

**USER (if they ask):** "Yeah, show me where this happens."

**AI REVEALS CODE (BEAUTIFUL ARTIFACT DISPLAY!):**

The AI outputs code using the special `typescript:filepath` format, which triggers our gorgeous code artifact renderer:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üî¥ üü° üü¢  src/app/.../reducers/ust-dolby.reducers.ts    TYPESCRIPT  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1 ‚îÇ // This is the ACTUAL indexed code from the AOMA codebase     ‚îÇ
‚îÇ  2 ‚îÇ on(UstDolbyActions.setUstDolbyData, (state, { dolbyDataItem })‚îÇ
‚îÇ  3 ‚îÇ   let dolbyData = [...state.dolbyData];                       ‚îÇ
‚îÇ  4 ‚îÇ                                                                ‚îÇ
‚îÇ  5 ‚îÇ   dolbyData.push(dolbyDataItem);                              ‚îÇ
‚îÇ  6 ‚îÇ   dolbyData = dolbyData                                       ‚îÇ
‚îÇ  7 ‚îÇ     .sort((a, b) => a.sequence - b.sequence)  // PRIMARY      ‚îÇ
‚îÇ  8 ‚îÇ     .sort((a, b) => a.side - b.side);          // SECONDARY   ‚îÇ
‚îÇ  9 ‚îÇ                                                                ‚îÇ
‚îÇ 10 ‚îÇ   return { ...state, dolbyData };                             ‚îÇ
‚îÇ 11 ‚îÇ }),                                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                        [üìã Copy]
```

**What the Audience Sees:**
- üî¥üü°üü¢ **Traffic light dots** (macOS-style window header)
- üìÅ **Full file path** in monospace font
- üè∑Ô∏è **Language badge** (TYPESCRIPT)
- üî¢ **Line numbers** on every line
- üìã **Copy button** for instant clipboard copy

**Narration:** "And if you want to see exactly where this is happening in the codebase, I can show you the actual code‚Äîwith file path and line numbers. Notice how it's beautifully formatted, not just raw text."

**Why This Matters:** When files arrive faster than they can be sorted, or when filenames contain special characters that affect sequence parsing, the state becomes inconsistent and throws the "Sorting Failed" error.

**‚úÖ VERIFIED:** This scenario works! The AI finds:
- JIRA tickets with 62%+ similarity
- Reducer code with 73%+ similarity
- Line numbers and file paths for code reveal

---

### üì¶ SCENARIO 2: "Aspera Disk Write Failed"

**JIRA Ticket:** DPSA-29600
**Code Location:** `ust-cc-ttml-aspera.reducers.ts` lines 1-79

**USER:** "I got an Aspera error code 36 - disk write failed. What does this mean?"

**AI RESPONSE:**
> I found a ticket about this: **DPSA-29600**
>
> This is an Aspera transfer error, not an AOMA UI issue. Error code 36 means the destination server ran out of disk space.
>
> Based on how the code handles Aspera transfers:
> - The `uploadUstCCTTMLItemAsperaError` state is set
> - The transfer is marked as failed
> - **Your files are still safe locally**
>
> **What to do:**
> 1. Wait 10-15 minutes and retry
> 2. Contact IT if it persists
> 3. Try a smaller file set to confirm it's a space issue

---

### üéµ SCENARIO 3: "360RA UploadPublishFailed"

**JIRA Ticket:** DPSA-30187
**Code Location:** `ust-ra360.reducers.ts` lines 1-109
**Key Functions:** `handle360State`, `handleAssetUploadIdList`

**USER:** "I'm trying to register a 360 Reality Audio track and getting 'UploadPublishFailed'. Help!"

**AI RESPONSE:**
> Found it! **DPSA-30187** documents this exact issue.
>
> 360RA registrations go through a special workflow. "UploadPublishFailed" means:
> 1. ‚úÖ The file uploaded successfully
> 2. ‚ùå The publish step failed
>
> Looking at the code, `UstRa360State` tracks separate statuses:
> - `ra360Statuses: { assetUploadId: number, status: string }[]`
>
> **Next Steps:**
> 1. Check if the asset appears in "Pending" status
> 2. If yes, manually complete the registration
> 3. If no, contact DPSA support with your ISRC code

---

### ‚è∞ SCENARIO 4: "TUS Upload Inactive Timeout"

**JIRA Ticket:** DPSA-30683
**Error:** "TUS upload failed: Upload was inactive during last [6] hours"

**USER:** "I got a weird error saying my upload was inactive for 6 hours and now it failed."

**AI RESPONSE:**
> That's ticket **DPSA-30683** ‚Äî the TUS (resumable upload) timeout.
>
> This happens when:
> 1. You started an upload
> 2. Your connection dropped or browser closed
> 3. 6+ hours passed without resumption
> 4. The server cleaned up the partial upload
>
> **The file is NOT on the server** - you'll need to re-upload.
>
> **Pro tip:** The UST uses `resumable.js` for chunked uploads. For large uploads:
> - Keep the browser tab open and active
> - Avoid putting your laptop to sleep
> - Consider uploading during off-peak hours

---

### üìä Real Scenarios Summary

| # | Error | JIRA | Code File | Best For |
|---|-------|------|-----------|----------|
| 1 | Asset Upload Sorting Failed | ITSM-55968+ | ust-cc-ttml.reducers.ts | **Primary demo** |
| 2 | Aspera Disk Write Failed | DPSA-29600 | ust-cc-ttml-aspera.reducers.ts | Infrastructure |
| 3 | 360RA UploadPublishFailed | DPSA-30187 | ust-ra360.reducers.ts | Niche workflow |
| 4 | TUS Inactive Timeout | DPSA-30683 | resumable.js | User behavior |

### üí° Demo Talking Points

1. "Notice how it found multiple related tickets? That's because we indexed your entire JIRA history."
2. "The AI knows this is a UI issue because we indexed the Angular code."
3. "Code is hidden knowledge‚Äîit makes the answer smarter without being overwhelming."
4. "The user didn't have to know *where* to look‚Äîthe system figured it out."
5. "And look at this beautiful code display‚Äîtraffic lights, file path, line numbers, copy button!"

---

## üé¨ CAPCUT FILMING CHECKLIST

### Pre-Recording Setup
- [ ] Dev server running: `infisical run --env=dev -- pnpm dev`
- [ ] Clear browser cache / use incognito
- [ ] Test API is responding: `curl http://localhost:3000/api/chat`
- [ ] Screen recording software ready (ScreenFlow / OBS / QuickTime)
- [ ] Microphone test

### Demo Queries to Record

| Scene | Query | Expected Features |
|-------|-------|-------------------|
| **1. JIRA Discovery** | "I'm getting Asset Upload Sorting Failed error. Any tickets?" | Shows ITSM-55968, ITSM-56940, explains code logic |
| **2. Code Reveal** | "Show me where this happens in the code" | Beautiful artifact with üî¥üü°üü¢, filepath, line numbers |
| **3. Curate Demo** | Navigate to Curate pillar, upload document | Shows knowledge ingestion flow |
| **4. Test Demo** | Navigate to Test pillar | Shows test orchestration |

### Key Visual Moments to Capture
1. üìã AI mentioning specific JIRA ticket numbers (ITSM-55968)
2. üíª Beautiful code artifact appearing with traffic lights
3. üî¢ Line numbers visible in code display
4. üìÅ File path visible in code header
5. ‚ö° Intent classifier working (visible in dev console if desired)

### Post-Recording Notes
- Clips will be edited together in CapCut
- Add Gemini-generated infographics as b-roll
- Consider adding zooms on key UI elements
- Music: Keep it subtle and professional

---

*Created: December 15, 2025*
*Updated: December 17, 2025 (added Intent Classification, Re-Ranker diagrams, Real Demo Scenarios, Code Artifact Display, Filming Checklist)*
*For: Mattie (called by Claudette)*
