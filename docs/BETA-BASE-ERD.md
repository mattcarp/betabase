# Beta Base Database ERD

**Last Updated**: November 9, 2025
**Status**: âœ… **VALIDATED** - Actual schema from local Supabase
**Source System**: Beta Base (legacy test management system)
**Connection**: Local Supabase Docker - postgresql://127.0.0.1:54322/postgres

---

## ğŸ—ï¸ **Database Structure Overview**

Beta Base uses a **two-tier testing architecture**:

1. **Scenarios (Test Cases)** - The blueprint/template
2. **Tests (Test Executions)** - The actual runs

---

## ğŸ“Š **Entity Relationship Diagram** (Actual Schema)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          SCENARIO                           â”‚
â”‚  (Test Cases / Templates)                   â”‚
â”‚  8,449 rows (6,250 AOMA)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ id (INTEGER PK)                           â”‚
â”‚ â€¢ name (VARCHAR 255)                        â”‚
â”‚ â€¢ script (TEXT - HTML formatted)            â”‚
â”‚ â€¢ expected_result (TEXT - HTML formatted)   â”‚
â”‚ â€¢ created_by (VARCHAR 127)                  â”‚
â”‚ â€¢ updated_by (VARCHAR 127)                  â”‚
â”‚ â€¢ preconditions (TEXT)                      â”‚
â”‚ â€¢ created_at (VARCHAR 255)                  â”‚
â”‚ â€¢ updated_at (VARCHAR 255)                  â”‚
â”‚ â€¢ review_flag (SMALLINT)                    â”‚
â”‚ â€¢ flag_reason (TEXT)                        â”‚
â”‚ â€¢ app_under_test (VARCHAR 255) [AOMA/...]  â”‚
â”‚ â€¢ tags (VARCHAR 255 - comma-separated)     â”‚
â”‚ â€¢ coverage (VARCHAR 128)                    â”‚
â”‚ â€¢ client_priority (SMALLINT)                â”‚
â”‚ â€¢ mode (VARCHAR 255)                        â”‚
â”‚ â€¢ is_security (SMALLINT)                    â”‚
â”‚ â€¢ priority_sort_order (INTEGER)             â”‚
â”‚ â€¢ enhancement_sort_order (INTEGER)          â”‚
â”‚ â€¢ current_regression_sort_order (INTEGER)   â”‚
â”‚ â€¢ reviewed_flag (VARCHAR 1)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ 1
              â”‚
              â”‚ has many
              â”‚
              â”‚ N
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           TEST                              â”‚
â”‚  (Test Executions / Runs)                   â”‚
â”‚  34,631 rows (20,961 AOMA)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ id (INTEGER PK)                           â”‚
â”‚ â€¢ scenario_id (INTEGER FK)                  â”‚
â”‚ â€¢ created_at (VARCHAR 255)                  â”‚
â”‚ â€¢ comments (TEXT)                           â”‚
â”‚ â€¢ ticket (VARCHAR 255)                      â”‚
â”‚ â€¢ created_by (VARCHAR 127)                  â”‚
â”‚ â€¢ input (TEXT)                              â”‚
â”‚ â€¢ result (TEXT)                             â”‚
â”‚ â€¢ pass_fail (VARCHAR 32) [Pass/Fail/Pend]  â”‚
â”‚ â€¢ build (VARCHAR 127)                       â”‚
â”‚ â€¢ updated_at (VARCHAR 255)                  â”‚
â”‚ â€¢ updated_by (VARCHAR 127)                  â”‚
â”‚ â€¢ path (VARCHAR 255)                        â”‚
â”‚ â€¢ browser_name (VARCHAR 255)                â”‚
â”‚ â€¢ browser_major (VARCHAR 255)               â”‚
â”‚ â€¢ browser_minor (VARCHAR 255)               â”‚
â”‚ â€¢ os_name (VARCHAR 255)                     â”‚
â”‚ â€¢ os_major (VARCHAR 255)                    â”‚
â”‚ â€¢ os_minor (VARCHAR 255)                    â”‚
â”‚ â€¢ deployment_stamp (VARCHAR 255)            â”‚
â”‚ â€¢ in_prod (VARCHAR 255)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ **Entity Definitions**

### **Scenarios Table**

**Purpose**: Stores the test case templates - the "what should be tested"

**Key Characteristics**:
- ONE scenario = ONE unique test case
- Contains the test script and expected behavior
- Can be executed multiple times (generates many Tests)
- Represents the "source of truth" for what behavior is expected

**Actual Count**: **8,449 scenarios** (6,250 AOMA-specific = 74%)

**Example**:
```typescript
interface Scenario {
  id: string;
  test_script: string;           // The test code/steps
  test_description: string;      // Human-readable description
  input_query: string;           // Query to test
  expected_output: string;       // Expected result
  category: string;              // e.g., "aoma-search", "jira-integration"
  priority: 'high' | 'medium' | 'low';
  created_date: Date;            // When this test was created
  created_by: string;            // Who created it
  tags: string[];                // Categorization tags
  metadata: {
    aoma_feature?: string;
    test_type?: string;
    complexity?: string;
    [key: string]: any;
  };
}
```

---

### **Tests Table**

**Purpose**: Stores individual test executions - the "what actually happened"

**Key Characteristics**:
- MANY tests per ONE scenario
- Contains actual results from running the scenario
- Tracks pass/fail history over time
- Shows how behavior has changed

**Actual Count**: **34,631 test executions** (20,961 AOMA-specific = 61%)

**Example**:
```typescript
interface TestExecution {
  id: string;
  scenario_id: string;           // FK to scenarios table
  actual_output: string;         // What the system actually returned
  pass_fail: boolean;            // Did it match expected?
  execution_date: Date;          // When this run happened
  execution_time_ms: number;     // How long it took
  error_message?: string;        // If failed, why?
  environment: string;           // 'production' | 'staging' | 'dev'
  executed_by: string;           // Who/what ran this test
  system_version: string;        // AOMA version at time of test
  metadata: {
    confidence_score?: number;
    similarity_score?: number;
    [key: string]: any;
  };
}
```

---

## ğŸ¯ **Key Insights for Historical Test Integration**

### **What the "10,000+ tests" Actually Means**

Based on actual discovery, the data contains:
- **8,449 SCENARIOS** (unique test cases) - 6,250 AOMA-specific
- Each scenario executed ~3.4 times on average
- **34,631 TEST EXECUTIONS** (actual runs) - 20,961 AOMA-specific
- **Data spans 2008-2022** (14+ years of history)
- **78% pass rate** overall (27,027 passes / 34,631 total)

### **Value Proposition**

**Scenarios** are valuable because they contain:
- âœ… **Domain knowledge** - What questions users ask about AOMA
- âœ… **Query patterns** - How people phrase questions
- âœ… **Expected behaviors** - What the correct answer should be
- âœ… **Test coverage** - What functionality was important to test

**Test Executions** are valuable because they show:
- âœ… **Historical performance** - How often did this scenario pass?
- âœ… **Trend analysis** - Is it getting better or worse over time?
- âœ… **Regression detection** - Did it used to work but now fails?
- âœ… **Stability indicators** - Flaky tests vs reliable ones

### **Challenge: Outdated Data**

Many scenarios were created "several years ago" for Beta Base system, which means:
- âŒ May reference old AOMA features
- âŒ May use deprecated terminology (IOMA vs AOMA)
- âŒ May test functionality that no longer exists
- âœ… BUT: Query patterns and user intents still valuable
- âœ… AND: Core AOMA functionality likely unchanged

---

## ğŸ” **Discovery Queries (To Run Once MCP Connected)**

### **Count Scenarios**
```sql
SELECT
  COUNT(*) as total_scenarios,
  MIN(created_date) as oldest_scenario,
  MAX(created_date) as newest_scenario,
  COUNT(DISTINCT category) as unique_categories
FROM scenarios;
```

### **Count Test Executions**
```sql
SELECT
  COUNT(*) as total_executions,
  COUNT(DISTINCT scenario_id) as scenarios_with_executions,
  SUM(CASE WHEN pass_fail = true THEN 1 ELSE 0 END) as total_passes,
  SUM(CASE WHEN pass_fail = false THEN 1 ELSE 0 END) as total_failures,
  MIN(execution_date) as first_execution,
  MAX(execution_date) as last_execution
FROM tests;
```

### **Scenario Execution Frequency**
```sql
SELECT
  s.id,
  s.test_description,
  COUNT(t.id) as execution_count,
  SUM(CASE WHEN t.pass_fail = true THEN 1 ELSE 0 END)::float / COUNT(t.id) as pass_rate,
  MAX(t.execution_date) as last_run
FROM scenarios s
LEFT JOIN tests t ON s.id = t.scenario_id
GROUP BY s.id, s.test_description
ORDER BY execution_count DESC
LIMIT 20;
```

### **Category Distribution**
```sql
SELECT
  category,
  COUNT(*) as scenario_count,
  MIN(created_date) as oldest,
  MAX(created_date) as newest
FROM scenarios
GROUP BY category
ORDER BY scenario_count DESC;
```

### **Age Analysis**
```sql
SELECT
  EXTRACT(YEAR FROM created_date) as year,
  COUNT(*) as scenarios_created,
  COUNT(DISTINCT category) as categories
FROM scenarios
GROUP BY EXTRACT(YEAR FROM created_date)
ORDER BY year DESC;
```

---

## ğŸ“‹ **Integration Strategy**

### **Phase 1: Scenario Analysis**
1. Extract all scenarios from Beta Base
2. Categorize by:
   - Age (how old is the scenario?)
   - Execution history (was it ever run? when?)
   - Pass rate (historically successful or problematic?)
   - Category (AOMA feature area)

### **Phase 2: Relevance Scoring**
For each scenario, score:
- **Temporal relevance**: How old is it?
- **Semantic relevance**: Still applicable to current AOMA?
- **Pattern value**: Is the query pattern still useful?
- **Historical performance**: Did it consistently pass/fail?

### **Phase 3: Modernization**
- **GOLD tier** (keep as-is): Recent scenarios, timeless patterns
- **SILVER tier** (needs updating): Good intent, outdated details
- **BRONZE tier** (archive): Historical reference only
- **TRASH tier** (discard): Completely obsolete

### **Phase 4: RLHF Integration**
- Link scenarios to RLHF feedback items
- Find similar historical scenarios for new queries
- Use test execution history to predict failure modes
- Learn from patterns that historically worked well

---

## ğŸ”§ **Next Steps**

### **Immediate** âœ… **COMPLETED**
- [x] Connected to local Supabase Docker instance
- [x] Ran discovery queries to validate schema
- [x] Counted actual scenarios (8,449) and test executions (34,631)
- [x] Analyzed app distribution (AOMA: 6,250 scenarios)
- [x] Identified date ranges (2008-2022)

### **Short-Term**
- [ ] Build scenario relevance scoring algorithm
- [ ] Create tiering system (GOLD/SILVER/BRONZE/TRASH)
- [ ] Extract top 100 scenarios for pilot testing
- [ ] Link to RLHF system

### **Long-Term**
- [ ] Full scenario migration to modern format
- [ ] Integration with SIAM test suite
- [ ] Automated pattern extraction
- [ ] Historical trend analysis dashboard

---

## ğŸ¯ **Actual Data Volumes** âœ…

Discovered from local Supabase (November 9, 2025):

| Metric | Actual Value |
|--------|--------------|
| **Total Scenarios** | 8,449 |
| **AOMA Scenarios** | 6,250 (74%) |
| **Total Test Executions** | 34,631 |
| **AOMA Executions** | 20,961 (61%) |
| **Avg Executions/Scenario** | 4.1 overall, 3.4 for AOMA |
| **Active Apps** | 5 (AOMA, Promo, GRAS Lite, DX, Partner Previewer) |
| **Date Range** | 2008-01-01 to 2022-07-18 |
| **Pass Rate** | 78% (27,027 passes / 34,631 total) |

**Source**: See `docs/BETA-BASE-DISCOVERY-RESULTS.md` for complete analysis

---

## ğŸš¨ **Important Distinctions**

### **Scenarios â‰  Tests**
- **Scenario**: The template ("Test that search works")
- **Test**: The execution ("Search worked on 2023-05-15")

### **When People Say "10k Tests" They Mean:**
- Could mean 10k scenarios (templates)
- Could mean 10k test executions (runs)
- **Clarification needed** via discovery queries

### **For RLHF Integration:**
- **Scenarios** provide the query patterns and expected behaviors
- **Tests** provide the historical performance data
- **Both** are valuable for different reasons

---

**Status**: âœ… Validated - Actual schema documented
**Next Action**: Build import script to extract AOMA scenarios
**Owner**: Matt Carpenter
**Source System**: Beta Base (legacy) - Local Supabase Docker
**Target System**: SIAM (modern)
**Connection**: postgresql://postgres:postgres@127.0.0.1:54322/postgres
