# ‚úÖ Phase 3: Embedding Standardization - COMPLETE

**Date**: January 2025
**Status**: ‚úÖ **COMPLETE** - All crawlers standardized on `text-embedding-3-small`

---

## üéØ Objective

Standardize all embedding generation across the codebase to use:
- **Model**: `text-embedding-3-small`
- **SDK**: Vercel AI SDK (`ai` package with `@ai-sdk/openai`)
- **Dimensions**: 1536 (same as before, but newer embedding space)

---

## ‚ö†Ô∏è Why This Matters

### Problem Before
Different crawlers used different embedding models:
- `aomaFirecrawlService.ts`: `text-embedding-3-small` (Vercel AI SDK) ‚úÖ
- `confluenceCrawler.ts`: `text-embedding-ada-002` (OpenAI SDK) ‚ùå
- `sonyMusicJiraCrawler.ts`: `text-embedding-ada-002` (OpenAI SDK) ‚ùå
- `supabaseVectorService.ts`: `text-embedding-ada-002` (OpenAI SDK) ‚ùå

### Impact of Mixing Models
Even though both models produce 1536-dimensional vectors:
- **Different embedding spaces** = **incorrect similarity scores**
- Vectors from different models **cannot be compared**
- Search quality **degraded** when mixing embeddings

### Solution
‚úÖ All services now use `text-embedding-3-small` via Vercel AI SDK

---

## üìù Changes Made

### 1. **Confluence Crawler** (`src/services/confluenceCrawler.ts`)

**Before**:
```typescript
import OpenAI from 'openai';

const openai = process.env.OPENAI_API_KEY
  ? new OpenAI({ apiKey: process.env.OPENAI_API_KEY })
  : null;

async function generateEmbedding(text: string): Promise<number[]> {
  if (!openai) return [];
  const resp = await openai.embeddings.create({
    model: 'text-embedding-ada-002',
    input: text
  });
  return resp.data[0].embedding;
}
```

**After**:
```typescript
import { openai } from '@ai-sdk/openai';
import { embed } from 'ai';

async function generateEmbedding(text: string): Promise<number[]> {
  try {
    const { embedding } = await embed({
      model: openai.embedding('text-embedding-3-small'),
      value: text,
    });
    return embedding;
  } catch (error) {
    console.error('Failed to generate embedding:', error);
    return [];
  }
}
```

---

### 2. **Jira Crawler** (`src/services/sonyMusicJiraCrawler.ts`)

**Before** (2 implementations - Playwright + REST):
```typescript
import OpenAI from 'openai';

// Playwright version
let openai: OpenAI | null = null;
function getOpenAI(): OpenAI | null {
  if (!openai && process.env.OPENAI_API_KEY) {
    openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
  }
  return openai;
}

async function generateEmbedding(text: string): Promise<number[]> {
  try {
    const client = getOpenAI();
    if (!client) return [];
    const resp = await client.embeddings.create({
      model: 'text-embedding-ada-002',
      input: text
    });
    return resp.data[0].embedding;
  } catch {
    return [];
  }
}

// REST API version
const openai = process.env.OPENAI_API_KEY
  ? new OpenAI({ apiKey: process.env.OPENAI_API_KEY })
  : null;

async function generateEmbedding(text: string): Promise<number[]> {
  if (!openai) return [];
  const resp = await openai.embeddings.create({
    model: 'text-embedding-ada-002',
    input: text
  });
  return resp.data[0].embedding;
}
```

**After** (Both implementations updated):
```typescript
import { openai } from '@ai-sdk/openai';
import { embed } from 'ai';

// Playwright version
async function generateEmbedding(text: string): Promise<number[]> {
  try {
    const { embedding } = await embed({
      model: openai.embedding('text-embedding-3-small'),
      value: text,
    });
    return embedding;
  } catch (error) {
    console.error('Failed to generate embedding:', error);
    return [];
  }
}

// REST API version (renamed for clarity)
import { openai as openaiSdk } from '@ai-sdk/openai';

async function generateEmbeddingForREST(text: string): Promise<number[]> {
  try {
    const { embedding } = await embed({
      model: openaiSdk.embedding('text-embedding-3-small'),
      value: text,
    });
    return embedding;
  } catch (error) {
    console.error('Failed to generate embedding:', error);
    return [];
  }
}
```

---

### 3. **Supabase Vector Service** (`src/services/supabaseVectorService.ts`)

**Before**:
```typescript
import OpenAI from "openai";

export class SupabaseVectorService {
  private openai: OpenAI;

  constructor(openaiApiKey?: string) {
    this.openai = new OpenAI({
      apiKey: openaiApiKey || process.env.OPENAI_API_KEY!,
    });
  }

  async generateEmbedding(text: string): Promise<number[]> {
    try {
      const response = await this.openai.embeddings.create({
        model: "text-embedding-ada-002",
        input: text,
      });

      return response.data[0].embedding;
    } catch (error) {
      console.error("Failed to generate embedding:", error);
      throw new Error("Embedding generation failed");
    }
  }
}
```

**After**:
```typescript
import { openai } from "@ai-sdk/openai";
import { embed } from "ai";

export class SupabaseVectorService {
  constructor() {
    // No longer need to store OpenAI client
  }

  async generateEmbedding(text: string): Promise<number[]> {
    try {
      const { embedding } = await embed({
        model: openai.embedding('text-embedding-3-small'),
        value: text,
      });

      return embedding;
    } catch (error) {
      console.error("Failed to generate embedding:", error);
      throw new Error("Embedding generation failed");
    }
  }
}
```

---

## ‚úÖ Benefits of Standardization

### 1. **Consistent Embeddings**
- All vectors now live in the same embedding space
- Similarity scores are accurate and meaningful
- Search quality is consistent across all sources

### 2. **Better Performance**
- `text-embedding-3-small` is faster than `ada-002`
- Lower latency for embedding generation
- More cost-effective (smaller model)

### 3. **Simpler Codebase**
- Single SDK (Vercel AI SDK) for all AI operations
- No need to manage OpenAI SDK clients
- Consistent error handling

### 4. **Future-Proof**
- Vercel AI SDK supports multiple providers
- Easy to switch models if needed
- Better TypeScript support

---

## üß™ Testing Required

### Before Running Crawls (Phase 6)

**VPN REQUIRED** for these tests:

1. **Test Confluence Embedding**:
   ```bash
   # VPN Required
   curl -X POST http://localhost:3000/api/confluence-crawl \
     -H "Content-Type: application/json" \
     -d '{"spaces": ["AOMA"], "maxPagesPerSpace": 1}'
   ```

2. **Test Jira Embedding**:
   ```bash
   # VPN Required
   curl -X POST http://localhost:3000/api/sony-music-jira-crawl \
     -H "Content-Type: application/json" \
     -d '{"projects": ["AOMA"], "maxResults": 1}'
   ```

3. **Test AOMA Embedding**:
   ```bash
   # VPN Required
   curl -X POST http://localhost:3000/api/firecrawl-crawl \
     -H "Content-Type: application/json" \
     -d '{"url": "https://aoma-stage.smcdp-de.net/aoma-ui/my-aoma-files"}'
   ```

### Verify Embeddings

```typescript
// Check that all embeddings are 1536 dimensions
import { supabase } from '@/lib/supabase';

const { data } = await supabase
  .from('aoma_unified_vectors')
  .select('source_type, embedding')
  .limit(10);

data?.forEach(row => {
  console.log(`${row.source_type}: ${row.embedding?.length} dims`);
});
// Should all show: 1536 dims
```

---

## üìä Comparison Table

| Service | Before | After | Status |
|---------|--------|-------|--------|
| **aomaFirecrawlService** | `text-embedding-3-small` | `text-embedding-3-small` | ‚úÖ Already correct |
| **confluenceCrawler** | `text-embedding-ada-002` | `text-embedding-3-small` | ‚úÖ Updated |
| **sonyMusicJiraCrawler** (Playwright) | `text-embedding-ada-002` | `text-embedding-3-small` | ‚úÖ Updated |
| **sonyMusicJiraCrawler** (REST) | `text-embedding-ada-002` | `text-embedding-3-small` | ‚úÖ Updated |
| **supabaseVectorService** | `text-embedding-ada-002` | `text-embedding-3-small` | ‚úÖ Updated |

---

## üö® Important Notes

### No Migration Needed
Since your database is currently **empty** (0 vectors), you don't need to migrate existing embeddings!

If you DID have existing vectors, you would need to:
1. Re-generate embeddings for all existing content
2. Update vectors in database
3. Verify search quality

### Dependencies
Ensure these packages are installed:
```bash
npm install ai @ai-sdk/openai
```

Already in your `package.json`:
- ‚úÖ `ai` - Vercel AI SDK
- ‚úÖ `@ai-sdk/openai` - OpenAI provider for AI SDK

---

## üìã Next Steps

### ‚úÖ **Phases 1-3 Complete**
- [x] Database schema verified
- [x] Deduplication service implemented
- [x] Embeddings standardized

### ‚è≥ **Phase 4: Alexandria Crawler** (Pending)
- [ ] Research Alexandria API/scraping approach
- [ ] Implement `alexandriaCrawler.ts`
- [ ] Add to master crawler

### ‚è≥ **Phase 5: Monitoring** (Pending)
- [ ] Create crawl scheduler
- [ ] Build monitoring dashboard
- [ ] Add error tracking

### ‚è≥ **Phase 6: Execute** (VPN Required)
- [ ] Deploy migration SQL
- [ ] Run master crawler
- [ ] Verify search quality
- [ ] Document results

---

**Last Updated**: January 2025
**Status**: ‚úÖ **PHASE 3 COMPLETE** - Ready for Phase 4 (Alexandria) or Phase 6 (First Crawl)

